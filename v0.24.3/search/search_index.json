{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location": "/assets/js/application.js", "text": "function e t for var n in t e n t n window function e function t r if n r return n r exports var i n r i r l 1 exports return e r call i exports i i exports t i l 0 i exports var n return t m e t c n t d function e n r t o e n object defineproperty e n configurable 1 enumerable 0 get r t n function e var n e e esmodule function return e default function return e return t d n a n n t o function e t return object prototype hasownproperty call e t t p t t s 6 function e t n use strict t esmodule 0 t default createelement function e t var n document createelement e t array prototype foreach call object keys t function e n setattribute e t e for var r arguments length i array r 2 r 2 0 o 2 o pre pre code array prototype foreach call n function t n var r code n i e createelement button class md clipboard title h clipboard copy data clipboard target r pre r code e createelement span class md clipboard message o t parentnode o id r o insertbefore i t new c default md clipboard on success function e var t e trigger queryselector md clipboard message if t instanceof htmlelement throw new referenceerror e clearselection t dataset mdtimer cleartimeout parseint t dataset mdtimer 10 t classlist add md clipboard message active t innerhtml h clipboard copied t dataset mdtimer settimeout function t classlist remove md clipboard message active t dataset mdtimer 2e3 tostring if modernizr details var r document queryselectorall details summary array prototype foreach call r function e e addeventlistener click function e var t e target parentnode t hasattribute open t removeattribute open t setattribute open var i function if document location hash var e document getelementbyid document location hash substring 1 if e return for var t e parentnode t t instanceof htmldetailselement t t parentnode if t t open t open 0 var n location hash location hash location hash n if window addeventlistener hashchange i i modernizr ios var o document queryselectorall data md scrollfix array prototype foreach call o function e e addeventlistener touchstart function var t e scrolltop 0 t e scrolltop 1 t e offsetheight e scrollheight e scrolltop t 1 listen new f default event listener window scroll resize orientationchange new f default header shadow data md component container data md component header listen new f default event listener window scroll resize orientationchange new f default header title data md component title md typeset h1 listen document queryselector data md component hero new f default event listener window scroll resize orientationchange new f default tabs toggle data md component hero listen document queryselector data md component tabs new f default event listener window scroll resize orientationchange new f default tabs toggle data md component tabs listen new f default event matchmedia min width 1220px new f default event listener window scroll resize orientationchange new f default sidebar position data md component navigation data md component header document queryselector data md component toc new f default event matchmedia min width 960px new f default event listener window scroll resize orientationchange new f default sidebar position data md component toc data md component header new f default event matchmedia min width 960px new f default event listener window scroll new f default nav blur data md component toc href var n document queryselectorall data md component collapsible array prototype foreach call n function e new f default event matchmedia min width 1220px new f default event listener e previouselementsibling click new f default nav collapse e new f default event matchmedia max width 1219px new f default event listener data md component navigation data md toggle change new f default nav scrolling data md component navigation nav document queryselector data md component search new f default event matchmedia max width 959px new f default event listener data md toggle search change new f default search lock data md toggle search new f default event listener data md component query focus keyup change new f default search result data md component result function return fetch t url base search search index json credentials same origin then function e return e json then function e return e docs map function e return e location t url base e location e listen new f default event listener data md component reset click function settimeout function var e document queryselector data md component query if e instanceof htmlinputelement throw new referenceerror e focus 10 listen new f default event listener data md toggle search change function e settimeout function e if e instanceof htmlinputelement throw new referenceerror if e checked var t document queryselector data md component query if t instanceof htmlinputelement throw new referenceerror t focus 400 e target listen new f default event matchmedia min width 960px new f default event listener data md component query focus function var e document queryselector data md toggle search if e instanceof htmlinputelement throw new referenceerror e checked e checked 0 e dispatchevent new customevent change new f default event listener window keydown function e var t document queryselector data md toggle search if t instanceof htmlinputelement throw new referenceerror var n document queryselector data md component query if n instanceof htmlinputelement throw new referenceerror if e metakey e ctrlkey if t checked if 13 e keycode if n document activeelement e preventdefault var r document queryselector data md component search href data md state active r instanceof htmllinkelement window location r getattribute href t checked 1 t dispatchevent new customevent change n blur else if 9 e keycode 27 e keycode t checked 1 t dispatchevent new customevent change n blur else if 1 8 37 39 indexof e keycode n document activeelement n focus else if 1 38 40 indexof e keycode var i e keycode o array prototype slice call document queryselectorall data md component query data md component search href a o find function e if e instanceof htmlelement throw new referenceerror return active e dataset mdstate a a dataset mdstate var s math max 0 o indexof a o length 38 i 1 1 o length return o s o s dataset mdstate active o s focus e preventdefault e stoppropagation 1 else document activeelement document activeelement form 70 e keycode 83 e keycode n focus e preventdefault listen new f default event listener window keypress function var e document queryselector data md toggle search if e instanceof htmlinputelement throw new referenceerror if e checked var t document queryselector data md component query if t instanceof htmlinputelement throw new referenceerror t document activeelement t focus listen new f default event listener document body keydown function e if 9 e keycode var t document queryselectorall data md component navigation md nav link for not tabindex array prototype foreach call t function e e offsetheight e tabindex 0 listen new f default event listener document body mousedown function var e document queryselectorall data md component navigation md nav link tabindex array prototype foreach call e function e e removeattribute tabindex listen document body addeventlistener click function tabbing document body dataset mdstate document body dataset mdstate new f default event matchmedia max width 959px new f default event listener data md component navigation href click function var e document queryselector data md toggle drawer if e instanceof htmlinputelement throw new referenceerror e checked e checked 1 e dispatchevent new customevent change function var e document queryselector data md source if e return a default resolve if e instanceof htmlanchorelement throw new referenceerror switch e dataset mdsource case github return new f default source adapter github e fetch default return a default resolve then function e var t document queryselectorall data md source array prototype foreach call t function t new f default source repository t initialize e t esmodule 0 t app void 0 n 7 n 8 n 9 n 10 n 11 n 12 n 13 var o n 14 a r o s n 19 c r s u n 20 l r u d n 21 f r d window promise window promise a default var h function e var t document getelementsbyname lang e 0 if t instanceof htmlmetaelement throw new referenceerror return t content p initialize i t app p call t n 0 function e t n e exports n p assets images icons bitbucket 1b09e088 svg function e t n e exports n p assets images icons github f0b8504a svg function e t n e exports n p assets images icons gitlab 6dd19c00 svg function e t function e t function e t try var n new window customevent test if n preventdefault 0 n defaultprevented throw new error could not prevent default catch e var r function e t var n r return t t bubbles 1 cancelable 1 detail void 0 n document createevent customevent n initcustomevent e t bubbles t cancelable t detail r n preventdefault n preventdefault function r call this try object defineproperty this defaultprevented get function return 0 catch e this defaultprevented 0 n r prototype window event prototype window customevent r function e t n window fetch window fetch n 2 default n 2 function e t n use strict object defineproperty t esmodule value 0 function e function r function i e t return function e apply t arguments function o e if this instanceof o throw new typeerror promises must be constructed via new if function typeof e throw new typeerror not a function this state 0 this handled 1 this value void 0 this deferreds d e this function a e t for 3 e state e e value if 0 e state return void e deferreds push t e handled 0 o immediatefn function var n 1 e state t onfulfilled t onrejected if null n return void 1 e state s c t promise e value var r try r n e value catch e return void c t promise e s t promise r function s e t try if t e throw new typeerror a promise cannot be resolved with itself if t object typeof t function typeof t var n t then if t instanceof o return e state 3 e value t void u e if function typeof n return void d i n t e e state 1 e value t u e catch t c e t function c e t e state 2 e value t u e function u e 2 e state 0 e deferreds length o immediatefn function e handled o unhandledrejectionfn e value for var t 0 n e deferreds length t 0 e idletimeoutid settimeout function e ontimeout e ontimeout t n 16 t setimmediate undefined typeof self self setimmediate void 0 e e setimmediate this this setimmediate t clearimmediate undefined typeof self self clearimmediate void 0 e e clearimmediate this this clearimmediate call t n 1 function e t n function e t function e n use strict function r e function typeof e e new function e for var t new array arguments length 1 n 0 n 1 for var n 1 n 0 void 0 arguments 0 arguments 0 this action e action this container e container this emitter e emitter this target e target this text e text this trigger e trigger this selectedtext key initselection value function this text this selectfake this target this selecttarget key selectfake value function var e this t rtl document documentelement getattribute dir this removefake this fakehandlercallback function return e removefake this fakehandler this container addeventlistener click this fakehandlercallback 0 this fakeelem document createelement textarea this fakeelem style fontsize 12pt this fakeelem style border 0 this fakeelem style padding 0 this fakeelem style margin 0 this fakeelem style position absolute this fakeelem style t right left 9999px var n window pageyoffset document documentelement scrolltop this fakeelem style top n px this fakeelem setattribute readonly this fakeelem value this text this container appendchild this fakeelem this selectedtext 0 r default this fakeelem this copytext key removefake value function this fakehandler this container removeeventlistener click this fakehandlercallback this fakehandler null this fakehandlercallback null this fakeelem this container removechild this fakeelem this fakeelem null key selecttarget value function this selectedtext 0 r default this target this copytext key copytext value function var e void 0 try e document execcommand this action catch t e 1 this handleresult e key handleresult value function e this emitter emit e success error action this action text this selectedtext trigger this trigger clearselection this clearselection bind this key clearselection value function this trigger this trigger focus window getselection removeallranges key destroy value function this removefake key action set function var e arguments length 0 void 0 arguments 0 arguments 0 copy if this action e copy this action cut this action throw new error invalid action value use either copy or cut get function return this action key target set function e if void 0 e if e object void 0 e undefined i e 1 e nodetype throw new error invalid target value use a valid element if copy this action e hasattribute disabled throw new error invalid target attribute please use readonly instead of disabled attribute if cut this action e hasattribute readonly e hasattribute disabled throw new error invalid target attribute you can t cut text from elements with readonly or disabled attributes this target e get function return this target e e exports a function e t n function r e t n if e t n throw new error missing required arguments if s string t throw new typeerror second argument must be a string if s fn n throw new typeerror third argument must be a function if s node e return i e t n if s nodelist e return o e t n if s string e return a e t n throw new typeerror first argument must be a string htmlelement htmlcollection or nodelist function i e t n return e addeventlistener t n destroy function e removeeventlistener t n function o e t n return array prototype foreach call e function e e addeventlistener t n destroy function array prototype foreach call e function e e removeeventlistener t n function a e t n return c document body e t n var s n 6 c n 5 e exports r function e t function n n prototype on function e t n var r this e this e return r e r e push fn t ctx n this once function e t n function r i off e r t apply n arguments var i this return r t this on e r n emit function e var t slice call arguments 1 n this e this e e slice r 0 i n length for r r 0 void 0 arguments 0 arguments 0 this action function typeof e action e action this defaultaction this target function typeof e target e target this defaulttarget this text function typeof e text e text this defaulttext this container object f e container e container document body key listenclick value function e var t this this listener 0 d default e click function e return t onclick e key onclick value function e var t e delegatetarget e currenttarget this clipboardaction this clipboardaction null this clipboardaction new u default action this action t target this target t text this text t container this container trigger t emitter this key defaultaction value function e return c action e key defaulttarget value function e var t c target e if t return document queryselector t key defaulttext value function e return c text e key destroy value function this listener destroy this clipboardaction this clipboardaction destroy this clipboardaction null key issupported value function var e arguments length 0 void 0 arguments 0 arguments 0 copy cut t string typeof e e e n document querycommandsupported return t foreach function e n n document querycommandsupported e n t l default e exports p function e t function n e t for e e nodetype r if function typeof e matches e matches t return e e e parentnode var r 9 if undefined typeof element element prototype matches var i element prototype i matches i matchesselector i mozmatchesselector i msmatchesselector i omatchesselector i webkitmatchesselector e exports n function e t n function r e t n r i var a o apply this arguments return e addeventlistener n a i destroy function e removeeventlistener n a i function i e t n i o return function typeof e addeventlistener r apply null arguments function typeof n r bind null document apply null arguments string typeof e e document queryselectorall e array prototype map call e function e return r e t n i o function o e t n r return function n n delegatetarget a n target t n delegatetarget r call e n var a n 4 e exports i function e t t node function e return void 0 e e instanceof htmlelement 1 e nodetype t nodelist function e var n object prototype tostring call e return void 0 e object nodelist n object htmlcollection n length in e 0 e length t node e 0 t string function e return string typeof e e instanceof string t fn function e return object function object prototype tostring call e function e t function n e var t if select e nodename e focus t e value else if input e nodename textarea e nodename var n e hasattribute readonly n e setattribute readonly e select e setselectionrange 0 e value length n e removeattribute readonly t e value else e hasattribute contenteditable e focus var r window getselection i document createrange i selectnodecontents e r removeallranges r addrange i t r tostring return t e exports n function e t n var r function use strict function i e t var n if t t this trackingclick 1 this trackingclickstart 0 this targetelement null this touchstartx 0 this touchstarty 0 this lasttouchidentifier 0 this touchboundary t touchboundary 10 this layer e this tapdelay t tapdelay 200 this taptimeout t taptimeout 700 i notneeded e for var r onmouse onclick ontouchstart ontouchmove ontouchend ontouchcancel o this s 0 c r length s 0 a navigator useragent indexof android 0 o s ip ad hone od test navigator useragent o c s os 4 d d test navigator useragent u s os 6 7 d test navigator useragent l navigator useragent indexof bb10 0 i prototype needsclick function e switch e nodename tolowercase case button case select case textarea if e disabled return 0 break case input if s file e type e disabled return 0 break case label case iframe case video return 0 return bneedsclick b test e classname i prototype needsfocus function e switch e nodename tolowercase case textarea return 0 case select return a case input switch e type case button case checkbox case file case image case radio case submit return 1 return e disabled e readonly default return bneedsfocus b test e classname i prototype sendclick function e t var n r document activeelement document activeelement e document activeelement blur r t changedtouches 0 n document createevent mouseevents n initmouseevent this determineeventtype e 0 0 window 1 r screenx r screeny r clientx r clienty 1 1 1 1 0 null n forwardedtouchevent 0 e dispatchevent n i prototype determineeventtype function e return a select e tagname tolowercase mousedown click i prototype focus function e var t s e setselectionrange 0 e type indexof date time e type month e type t e value length e setselectionrange t t e focus i prototype updatescrollparent function e var t n if t e fastclickscrollparent t contains e n e do if n scrollheight n offsetheight t n e fastclickscrollparent n break n n parentelement while n t t fastclicklastscrolltop t scrolltop i prototype gettargetelementfromeventtarget function e return e nodetype node text node e parentnode e i prototype ontouchstart function e var t n r if e targettouches length 1 return 0 if t this gettargetelementfromeventtarget e target n e targettouches 0 s if r window getselection r rangecount r iscollapsed return 0 if c if n identifier n identifier this lasttouchidentifier return e preventdefault 1 this lasttouchidentifier n identifier this updatescrollparent t return this trackingclick 0 this trackingclickstart e timestamp this targetelement t this touchstartx n pagex this touchstarty n pagey e timestamp this lastclicktime n math abs t pagey this touchstarty n i prototype ontouchmove function e return this trackingclick this targetelement this gettargetelementfromeventtarget e target this touchhasmoved e this trackingclick 1 this targetelement null 0 i prototype findcontrol function e return void 0 e control e control e htmlfor document getelementbyid e htmlfor e queryselector button input not type hidden keygen meter output progress select textarea i prototype ontouchend function e var t n r i o l this targetelement if this trackingclick return 0 if e timestamp this lastclicktime this taptimeout return 0 if this cancelnextclick 1 this lastclicktime e timestamp n this trackingclickstart this trackingclick 1 this trackingclickstart 0 u o e changedtouches 0 l document elementfrompoint o pagex window pagexoffset o pagey window pageyoffset l l fastclickscrollparent this targetelement fastclickscrollparent label r l tagname tolowercase if t this findcontrol l if this focus l a return 1 l t else if this needsfocus l return e timestamp n 100 s window top window input r this targetelement null 1 this focus l this sendclick l e s select r this targetelement null e preventdefault 1 return s c i l fastclickscrollparent i fastclicklastscrolltop i scrolltop this needsclick l e preventdefault this sendclick l e 1 i prototype ontouchcancel function this trackingclick 1 this targetelement null i prototype onmouse function e return this targetelement e forwardedtouchevent e cancelable this needsclick this targetelement this cancelnextclick e stopimmediatepropagation e stopimmediatepropagation e propagationstopped 0 e stoppropagation e preventdefault 1 i prototype onclick function e var t return this trackingclick this targetelement null this trackingclick 1 0 submit e target type 0 e detail t this onmouse e t this targetelement null t i prototype destroy function var e this layer a e removeeventlistener mouseover this onmouse 0 e removeeventlistener mousedown this onmouse 0 e removeeventlistener mouseup this onmouse 0 e removeeventlistener click this onclick 0 e removeeventlistener touchstart this ontouchstart 1 e removeeventlistener touchmove this ontouchmove 1 e removeeventlistener touchend this ontouchend 1 e removeeventlistener touchcancel this ontouchcancel 1 i notneeded function e var t n r if void 0 window ontouchstart return 0 if n chrome 0 9 exec navigator useragent 0 1 if a return 0 if t document queryselector meta name viewport if 1 t content indexof user scalable no return 0 if n 31 document documentelement scrollwidth 10 r 2 3 t document queryselector meta name viewport if 1 t content indexof user scalable no return 0 if document documentelement scrollwidth 27 t document queryselector meta name viewport 1 t content indexof user scalable no document documentelement scrollwidth this height t this active this header dataset mdstate this active t shadow else this height 0 this setup e prototype reset function this header dataset mdstate this height 0 this active 1 e t default i function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i function function e t n r this e var i string typeof t document queryselector t t if i instanceof htmlelement throw new referenceerror if this el i i string typeof n document queryselector n n instanceof htmlheadingelement throw new referenceerror this header i this active 1 return e prototype setup function var e this array prototype foreach call this el children function t t style width e el offsetwidth 20 px e prototype update function e var t this n window pageyoffset this header offsettop n this active this el dataset mdstate this active n active resize e type orientationchange e type array prototype foreach call this el children function e e style width t el offsetwidth 20 px e prototype reset function this el dataset mdstate this el style width this active 1 e t default i function e t n use strict function r e return e e esmodule e default e t esmodule 0 var i n 28 o r i a n 29 s r a c n 30 u r c t default blur o default collapse s default scrolling u default function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i function function e t r this e this els string typeof t document queryselectorall t t this index 0 this offset window pageyoffset this dir 1 this anchors reduce call this els function e t return e concat document getelementbyid t hash substring 1 return e prototype setup function this update e prototype update function var e window pageyoffset t this offset e 0 this els n 1 dataset mdstate blur this index n else for var r this index r 0 r if this anchors r offsettop 80 e this index r break r 0 this els r 1 dataset mdstate this offset e this dir t e prototype reset function array prototype foreach call this els function e e dataset mdstate this index 0 this offset window pageyoffset e t default i function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i function function e t r this e var n string typeof t document queryselector t t if n instanceof htmlelement throw new referenceerror this el n return e prototype setup function var e this el getboundingclientrect height this el style display e block none this el style overflow e visible hidden e prototype update function var e this t this el getboundingclientrect height if this el style display block this el style overflow t this el style maxheight t px requestanimationframe function e el setattribute data md state animate e el style maxheight 0px else this el setattribute data md state expand this el style maxheight var n this el getboundingclientrect height this el removeattribute data md state this el style maxheight 0px requestanimationframe function e el setattribute data md state animate e el style maxheight n px var r function e n var r n target if r instanceof htmlelement throw new referenceerror r removeattribute data md state r style maxheight r style display t none block r style overflow t hidden visible r removeeventlistener transitionend e this el addeventlistener transitionend r 1 e prototype reset function this el dataset mdstate this el style maxheight this el style display this el style overflow e t default i function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i function function e t r this e var n string typeof t document queryselector t t if n instanceof htmlelement throw new referenceerror this el n return e prototype setup function this el children this el children length 1 style webkitoverflowscrolling touch var e this el queryselectorall data md toggle array prototype foreach call e function e if e instanceof htmlinputelement throw new referenceerror if e checked var t e nextelementsibling if t instanceof htmlelement throw new referenceerror for nav t tagname t nextelementsibling t t nextelementsibling if e parentnode instanceof htmlelement e parentnode parentnode instanceof htmlelement throw new referenceerror var n e parentnode parentnode r t children t children length 1 n style webkitoverflowscrolling r style webkitoverflowscrolling touch e prototype update function e var t e target if t instanceof htmlelement throw new referenceerror var n t nextelementsibling if n instanceof htmlelement throw new referenceerror for nav n tagname n nextelementsibling n n nextelementsibling if t parentnode instanceof htmlelement t parentnode parentnode instanceof htmlelement throw new referenceerror var r t parentnode parentnode i n children n children length 1 if r style webkitoverflowscrolling i style webkitoverflowscrolling t checked var o function e n instanceof htmlelement r style webkitoverflowscrolling touch n removeeventlistener transitionend e n addeventlistener transitionend o 1 if t checked var a function e n instanceof htmlelement i style webkitoverflowscrolling touch n removeeventlistener transitionend e n addeventlistener transitionend a 1 e prototype reset function this el children 1 style webkitoverflowscrolling var e this el queryselectorall data md toggle array prototype foreach call e function e if e instanceof htmlinputelement throw new referenceerror if e checked var t e nextelementsibling if t instanceof htmlelement throw new referenceerror for nav t tagname t nextelementsibling t t nextelementsibling if e parentnode instanceof htmlelement e parentnode parentnode instanceof htmlelement throw new referenceerror var n e parentnode parentnode r t children t children length 1 n style webkitoverflowscrolling r style webkitoverflowscrolling e t default i function e t n use strict function r e return e e esmodule e default e t esmodule 0 var i n 32 o r i a n 33 s r a t default lock o default result s default function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i function function e t r this e var n string typeof t document queryselector t t if n instanceof htmlinputelement throw new referenceerror if this el n document body throw new referenceerror this lock document body return e prototype setup function this update e prototype update function var e this this el checked this offset window pageyoffset settimeout function window scrollto 0 0 e el checked e lock dataset mdstate lock 400 this lock dataset mdstate settimeout function void 0 e offset window scrollto 0 e offset 100 e prototype reset function lock this lock dataset mdstate window scrollto 0 this offset this lock dataset mdstate e t default i function e t n use strict function e function r e return e e esmodule e default e function i e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var o n 34 a r o s n 35 c r s u function e t var n t if e length n for e n n 0 return e substring 0 n return e l function e var t document getelementsbyname lang e 0 if t instanceof htmlmetaelement throw new referenceerror return t content d function function t e n i this t var r string typeof e document queryselector e e if r instanceof htmlelement throw new referenceerror this el r var o array prototype slice call this el children a o 0 s o 1 this data n this meta a this list s this message placeholder this meta textcontent none l search result none one l search result one other l search result other var u l search tokenizer u length c default tokenizer separator u this lang l search language split filter boolean map function e return e trim return t prototype update function t var n this if focus t type this index if focus t type keyup t type var r t target if r instanceof htmlinputelement throw new referenceerror if this index r value this value return for this list firstchild this list removechild this list firstchild if this value r value 0 this value length return void this meta textcontent this message placeholder var i this index query function e n value tolowercase split filter boolean foreach function t e term t wildcard c default query wildcard trailing reduce function e t var r n docs get t ref if r parent var i r parent location e set i e get i concat t else var o r location e set o e get o return e new map o 0 a default this value trim replace new regexp c default tokenizer separator img s new regexp c default tokenizer separator o img d function e t n return t n this stack i foreach function t r var i o n docs get r a e createelement li class md search result item e createelement a href o location title o title class md search result link tabindex 1 e createelement article class md search result article md search result article document e createelement h1 class md search result title html o title replace s d o text length e createelement p class md search result teaser html o text replace s d c t map function t return function var r n docs get t ref a appendchild e createelement a href r location title r title class md search result link data md rel anchor tabindex 1 e createelement article class md search result article e createelement h1 class md search result title html r title replace s d r text length e createelement p class md search result teaser html u r text replace s d 400 i n stack push apply i function return n list appendchild a concat c var f this el parentnode if f instanceof htmlelement throw new referenceerror for this stack length f offsetheight f scrollheight 16 this stack shift var h this list queryselectorall data md rel anchor switch array prototype foreach call h function e click keydown foreach function t e addeventlistener t function n if keydown t 13 n keycode var r document queryselector data md toggle search if r instanceof htmlinputelement throw new referenceerror r checked r checked 1 r dispatchevent new customevent change n preventdefault settimeout function document location href e href 100 i size case 0 this meta textcontent this message none break case 1 this meta textcontent this message one break default this meta textcontent this message other replace i size else var p function e n docs e reduce function e t var n t location split r n 0 return n 1 t parent e get r t parent t parent done t parent title t title t parent text t text t parent done 0 t text t text replace n g replace s g replace s g function e t return t t parent t parent title t title e set t location t e new map var t n docs r n lang n stack n index 0 c default function var e n this i search pipeline trimmer c default trimmer search pipeline stopwords c default stopwordfilter o object keys i reduce function e t return l t match false i e push i t e this pipeline reset o e this pipeline add apply e o 1 r length en r 0 c default r 0 this use c default r 0 r length 1 this use c default multilanguage apply c default r this field title boost 10 this field text this ref location t foreach function e return n add e var i n el parentnode if i instanceof htmlelement throw new referenceerror i addeventlistener scroll function for n stack length i scrolltop i offsetheight i scrollheight 16 n stack splice 0 10 foreach function e return e settimeout function return function typeof n data n data then p p n data 250 t t default d call t n 0 function e t n use strict var r g e exports function e if string typeof e throw new typeerror expected a string return e replace r function e t n function t e exports t lunr n 36 call t n 1 function e t n var r i function var o function e var t new o builder return t pipeline add o trimmer o stopwordfilter o stemmer t searchpipeline add o stemmer e call t t t build o version 2 1 5 o utils o utils warn function e return function t e console console warn console warn t this o utils asstring function e return void 0 e null e e tostring o fieldref function e t n this docref e this fieldname t this stringvalue n o fieldref joiner o fieldref fromstring function e var t e indexof o fieldref joiner if 1 t throw malformed field ref string var n e slice 0 t r e slice t 1 return new o fieldref r n e o fieldref prototype tostring function return void 0 this stringvalue this stringvalue this fieldname o fieldref joiner this docref this stringvalue o idf function e t var n 0 for var r in e index r n object keys e r length var i t n 5 n 5 return math log 1 math abs i o token function e t this str e this metadata t o token prototype tostring function return this str o token prototype update function e return this str e this str this metadata this o token prototype clone function e return e e function e return e new o token e this str this metadata this metadata o tokenizer function e if null e void 0 e return if array isarray e return e map function e return new o token o utils asstring e tolowercase for var t e tostring trim tolowercase n t length r i 0 a 0 i 0 r push new o token t slice a i position a c index r length a i 1 return r o tokenizer separator s o pipeline function this stack o pipeline registeredfunctions object create null o pipeline registerfunction function e t t in this registeredfunctions o utils warn overwriting existing registered function t e label t o pipeline registeredfunctions e label e o pipeline warniffunctionnotregistered function e e label e label in this registeredfunctions o utils warn function is not registered with pipeline this may cause problems when serialising the index n e o pipeline load function e var t new o pipeline return e foreach function e var n o pipeline registeredfunctions e if n throw new error cannot load unregistered function e t add n t o pipeline prototype add function array prototype slice call arguments foreach function e o pipeline warniffunctionnotregistered e this stack push e this o pipeline prototype after function e t o pipeline warniffunctionnotregistered t var n this stack indexof e if 1 n throw new error cannot find existingfn n 1 this stack splice n 0 t o pipeline prototype before function e t o pipeline warniffunctionnotregistered t var n this stack indexof e if 1 n throw new error cannot find existingfn this stack splice n 0 t o pipeline prototype remove function e var t this stack indexof e 1 t this stack splice t 1 o pipeline prototype run function e for var t this stack length n 0 n 1 o e n i o e r n t i t math floor r 2 o this elements 2 i return o e 2 i o e 2 i o s u 2 a s t n c 1 r u 1 c 2 u 2 return t o vector prototype similarity function e return this dot e this magnitude e magnitude o vector prototype toarray function for var e new array this elements length 2 t 1 n 0 t 0 var a s i str charat 0 s in i node edges a i node edges s a new o tokenset i node edges s a 1 i str length a final 0 r push node a editsremaining i editsremaining str i str slice 1 if i editsremaining 0 i str length 1 var c s i str charat 1 s in i node edges c i node edges s c new o tokenset i node edges s c i str length 0 1 i str length i node final 0 i editsremaining 0 i str length 1 if in i node edges var u i node edges else var u new o tokenset i node edges u 1 i str length u final 0 r push node u editsremaining i editsremaining 1 str i str slice 1 if i editsremaining 0 if in i node edges var l i node edges else var l new o tokenset i node edges l 0 i str length l final 0 r push node l editsremaining i editsremaining 1 str i str if i editsremaining 0 i str length 1 var d f i str charat 0 h i str charat 1 h in i node edges d i node edges h d new o tokenset i node edges h d 1 i str length d final 0 r push node d editsremaining i editsremaining 1 str f i str slice 2 return n o tokenset fromstring function e for var t new o tokenset n t r 1 i 0 a e length i e t var n this uncheckednodes t r n child tostring r in this minimizednodes n parent edges n char this minimizednodes r n child str r this minimizednodes r n child this uncheckednodes pop o index function e this invertedindex e invertedindex this fieldvectors e fieldvectors this tokenset e tokenset this fields e fields this pipeline e pipeline o index prototype search function e return this query function t new o queryparser e t parse o index prototype query function e var t new o query this fields n object create null r object create null i object create null e call t t for var a 0 a 1 1 e o builder prototype k1 function e this k1 e o builder prototype add function e var t e this ref this documentcount 1 for var n 0 n this length return o querylexer eos var e this str charat this pos return this pos 1 e o querylexer prototype width function return this pos this start o querylexer prototype ignore function this start this pos this pos 1 this start this pos o querylexer prototype backup function this pos 1 o querylexer prototype acceptdigitrun function var e t do e this next t e charcodeat 0 while t 47 t 1 e backup e emit o querylexer term e ignore e more return o querylexer lextext o querylexer lexeditdistance function e return e ignore e acceptdigitrun e emit o querylexer edit distance o querylexer lextext o querylexer lexboost function e return e ignore e acceptdigitrun e emit o querylexer boost o querylexer lextext o querylexer lexeos function e e width 0 e emit o querylexer term o querylexer termseparator o tokenizer separator o querylexer lextext function e for var t e next if t o querylexer eos return o querylexer lexeos if 92 t charcodeat 0 if t return o querylexer lexfield if t return e backup e width 0 e emit o querylexer term o querylexer lexeditdistance if t return e backup e width 0 e emit o querylexer term o querylexer lexboost if t match o querylexer termseparator return o querylexer lexterm else e escapecharacter o queryparser function e t this lexer new o querylexer e this query t this currentclause this lexemeidx 0 o queryparser prototype parse function this lexer run this lexemes this lexer lexemes for var e o queryparser parsefieldorterm e e e this return this query o queryparser prototype peeklexeme function return this lexemes this lexemeidx o queryparser prototype consumelexeme function var e this peeklexeme return this lexemeidx 1 e o queryparser prototype nextclause function var e this currentclause this query clause e this currentclause o queryparser parsefieldorterm function e var t e peeklexeme if void 0 t switch t type case o querylexer field return o queryparser parsefield case o querylexer term return o queryparser parseterm default var n expected either a field or a term found t type throw t str length 1 n with value t str new o queryparseerror n t start t end o queryparser parsefield function e var t e consumelexeme if void 0 t if 1 e query allfields indexof t str var n e query allfields map function e return e join r unrecognised field t str possible fields n throw new o queryparseerror r t start t end e currentclause fields t str var i e peeklexeme if void 0 i var r expecting term found nothing throw new o queryparseerror r t start t end switch i type case o querylexer term return o queryparser parseterm default var r expecting term found i type throw new o queryparseerror r i start i end o queryparser parseterm function e var t e consumelexeme if void 0 t e currentclause term t str tolowercase 1 t str indexof e currentclause usepipeline 1 var n e peeklexeme if void 0 n return void e nextclause switch n type case o querylexer term return e nextclause o queryparser parseterm case o querylexer field return e nextclause o queryparser parsefield case o querylexer edit distance return o queryparser parseeditdistance case o querylexer boost return o queryparser parseboost default var r unexpected lexeme type n type throw new o queryparseerror r n start n end o queryparser parseeditdistance function e var t e consumelexeme if void 0 t var n parseint t str 10 if isnan n var r edit distance must be numeric throw new o queryparseerror r t start t end e currentclause editdistance n var i e peeklexeme if void 0 i return void e nextclause switch i type case o querylexer term return e nextclause o queryparser parseterm case o querylexer field return e nextclause o queryparser parsefield case o querylexer edit distance return o queryparser parseeditdistance case o querylexer boost return o queryparser parseboost default var r unexpected lexeme type i type throw new o queryparseerror r i start i end o queryparser parseboost function e var t e consumelexeme if void 0 t var n parseint t str 10 if isnan n var r boost must be numeric throw new o queryparseerror r t start t end e currentclause boost n var i e peeklexeme if void 0 i return void e nextclause switch i type case o querylexer term return e nextclause o queryparser parseterm case o querylexer field return e nextclause o queryparser parsefield case o querylexer edit distance return o queryparser parseeditdistance case o querylexer boost return o queryparser parseboost default var r unexpected lexeme type i type throw new o queryparseerror r i start i end function o a r a void 0 i function typeof r r call t n t e r e exports i 0 function return o function e t n use strict t esmodule 0 var r n 38 i function e return e e esmodule e default e r t default position i default function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i function function e t n r this e var i string typeof t document queryselector t t if i instanceof htmlelement i parentnode instanceof htmlelement throw new referenceerror if this el i this parent i parentnode i string typeof n document queryselector n n instanceof htmlelement throw new referenceerror this header i this height 0 this pad fixed window getcomputedstyle this header position return e prototype setup function var e array prototype reduce call this parent children function e t return math max e t offsettop 0 this offset e this pad this header offsetheight 0 this update e prototype update function e var t window pageyoffset n window innerheight e resize e type this setup var r top this pad this header offsetheight 0 bottom this parent offsettop this parent offsetheight i n r top math max 0 this offset t math max 0 t n r bottom i this height this el style height this height i px t this offset lock this el dataset mdstate this el dataset mdstate lock lock this el dataset mdstate this el dataset mdstate e prototype reset function this el dataset mdstate this el style height this height 0 e t default i function e t n use strict function r e return e e esmodule e default e t esmodule 0 var i n 40 o r i a n 44 s r a t default adapter o default repository s default function e t n use strict t esmodule 0 var r n 41 i function e return e e esmodule e default e r t default github i default function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function function i e t if e throw new referenceerror this hasn t been initialised super hasn t been called return t object typeof t function typeof t e t function o e t if function typeof t null t throw new typeerror super expression must either be null or a function not typeof t e prototype object create t t prototype constructor value e enumerable 1 writable 0 configurable 0 t object setprototypeof object setprototypeof e t e proto t t esmodule 0 var a n 42 s function e return e e esmodule e default e a c function e function t n r this t var o i this e call this n a github com exec o base if a 3 a length var s a 1 c a 2 console log username s console log repository c o base https api github com users s repos o name c return o return o t e t prototype fetch function var e this return function t var n arguments length 0 void 0 arguments 0 arguments 0 0 return fetch e base per page 30 page n then function e return e json then function r if r instanceof array throw new typeerror if e name var i r find function t return t name e name return i 30 r length i e format i stargazers count stars e format i forks count forks t n 1 return r length repositories t s default t default c function e t n use strict function r e t if e instanceof t throw new typeerror cannot call a class as a function t esmodule 0 var i n 43 o function e return e e esmodule e default e i a function function e t r this e var n string typeof t document queryselector t t if n instanceof htmlanchorelement throw new referenceerror this el n this base this el href this salt this hash this base return e prototype fetch function var e this return new promise function t var n o default getjson e salt cache source void 0 n t n e fetch then function n o default set e salt cache source n expires 1 96 t n e prototype fetch function throw new error fetch not implemented e prototype format function e return e 1e4 e 1e3 tofixed 0 k e 1e3 e 1e3 tofixed 1 k e e prototype hash function e var t 0 if 0 e length return t for var n 0 r e length n 1 if o e path r defaults o number typeof o expires var s new date s setmilliseconds s getmilliseconds 864e5 o expires o expires s o expires o expires o expires toutcstring try a json stringify i test a i a catch e i n write n write i t encodeuricomponent string i replace 23 24 26 2b 3a 3c 3e 3d 2f 3f 40 5b 5d 5e 60 7b 7d 7c g decodeuricomponent t encodeuricomponent string t t t replace 23 24 26 2b 5e 60 7c g decodeuricomponent t t replace g escape var c for var u in o o u c u 0 o u c o u return document cookie t i c t a for var l document cookie document cookie split d 0 9a z 2 g f 0 f this el children 0 offsettop 43 e this active this el dataset mdstate this active e hidden e prototype reset function this el dataset mdstate this active 1 e t default i", "title": ""},{"location": "/archive/", "text": "news archive for post in site posts capture this year post date date y endcapture capture next year post previous date date y endcapture if forloop first this year endif post date date b d y post title if forloop last else if this year next year next year endif endif endfor", "title": "Articles"},{"location": "/feed.xml", "text": "site title xml escape site description xml escape site url site baseurl site time date to rfc822 site time date to rfc822 jekyll v jekyll version for post in site posts limit 10 post title xml escape post content xml escape post date date to rfc822 post url prepend site baseurl prepend site url post url prepend site baseurl prepend site url for tag in post tags tag xml escape endfor for cat in post categories cat xml escape endfor endfor", "title": ""},{"location": "/", "text": "turing jl bayesian inference with probabilistic programming for f in page main feature row f title f excerpt markdownify endfor hello world in turing linear gaussian model page code sample excerpt markdownify quick start highlight julia page code sample snippet endhighlight news feed for post in site posts limit 10 post title post date date b d y endfor news advanced markov chain monte carlo samplers page samplers excerpt markdownify samplers interoperable with deep learning libraries page flux excerpt markdownify bayesian neural network tutorial page community title page community subtitle for f in page community comunities f title f text markdownify go to f title endfor page ecosystem title page ecosystem subtitle for f in page ecosystem ecosystems f title f text go to f title endfor", "title": "Turing.jl - Turing.jl"},{"location": "/news/", "text": "newssubscribe with rss to keep up with the latest news about turing for post in site posts limit 10 if post draft null or post draft false post title post date date b d y if post badges for badge in post badges badge tag endfor endif post excerpt read more endif endfor want to see more see the news archive", "title": "News"},{"location": "/search/search_index.json", "text": "config lang en prebuild index false separator s docs for page in site pages unless page excluded in search if added endif assign added false location page url text page content strip html strip newlines slugify ascii replace title page title assign added true endunless endfor for post in site posts unless page excluded in search if added endif assign added false location post url text post content strip html strip newlines slugify ascii replace title post title assign added true endunless endfor for doc in site docs unless doc excluded in search if added endif assign added false location doc url text doc content strip html strip newlines slugify ascii replace title doc title assign added true endunless endfor", "title": ""},{"location": "/sitemap.xml", "text": "now date y m d daily for section in site data toc site baseurl section url now date y m d daily endfor", "title": ""},{"location": "/robots.txt", "text": "sitemap sitemap xml absolute url", "title": ""},{"location": "/feed.xml", "text": "if page xsl endif jekyll site time date to xmlschema page url absolute url xml escape assign title site title default site name if page collection posts assign collection page collection capitalize assign title title append append collection endif if page category assign category page category capitalize assign title title append append category endif if title title smartify xml escape endif if site description site description xml escape endif if site author site author name default site author xml escape if site author email site author email xml escape endif if site author uri site author uri xml escape endif endif if page tags assign posts site tags page tags else assign posts site page collection endif if page category assign posts posts where category page category endif unless site show drafts assign posts posts where exp post post draft true endunless assign posts posts sort date reverse assign posts limit site feed posts limit default 10 for post in posts limit posts limit assign post title post title smartify strip html normalize whitespace xml escape post title post date date to xmlschema post last modified at default post date date to xmlschema post id absolute url xml escape assign excerpt only post feed excerpt only default site feed excerpt only unless excerpt only post content strip xml escape endunless assign post author post author default post authors 0 default site author assign post author site data authors post author default post author assign post author email post author email default nil assign post author uri post author uri default nil assign post author name post author name default post author post author name default xml escape if post author email post author email xml escape endif if post author uri post author uri xml escape endif if post category elsif post categories for category in post categories endfor endif for tag in post tags endfor if post excerpt and post excerpt empty post excerpt strip html normalize whitespace xml escape endif assign post image post image path default post image if post image unless post image contains assign post image post image absolute url endunless endif endfor", "title": ""},{"location": "/posts/2022-02-17-gsoc", "text": "it is another year of the google summer of code time and we have compiled an updated list of exciting turing projects projects that the turing team would be interested in working with students on over the summer are listed below this information is also cross posted at julia s turing project page if you are interested in exploring any of these projects or have any questions please reach out to the listed project mentors you can find their contact information at turing ml team more real world bayesian models in turing juliamentors kai xu tor e fjelde hong geproject difficulty mediumproject length 175 hrs or 350 hrsdescription there are many real world bayesian models out there and they deserve a turing julia implementation examples include but not limited toforecasting prophet datasets recommender system probabilistic matrix factorisation dataset ranking trueskill dataset bayesian revenue estimation example political forecasting model example topic mining latent dirichlet allocation and new variants multiple annotators combining unreliable observations dawid and skene 1979 for each model we would consider the following tasks as part of a gsoc project correctness test correctness of the implementation can be tested by doing inference for prior samples for which we know the ground truth latent variables performance benchmark this includes i time per mcmc step and ii time per effective sample if the model is differentiable a further break down of i into i 1 time per forward pass and i 2 time per gradient pass are needed real world results if available the final step is to apply the model to a real world dataset if such an experiment has been done in the literature consistency of inference results needs to be checkedimproving the integration between turing and turing s mcmc inference packagesmentors cameron pfiffer mohamed tarek david widmannproject difficulty easyproject length 175 hrsdescription turing jl is based on a set of inference packages maintained by the turinglang group this project is about making use of improvements in dynamicppl to create a generic integration between turing jl and the abstractmcmc jl sampling api the ultimate goal is to remove or substantially reduce algorithm specific glue code inside turing jl the project would also involve improving data structures for storing model parameters in dynamicppl directed graphical model support for the abstract probabilistic programming librarymentors philipp gabler hong geproject difficulty hardproject length 350 hrsdescription we want to have a very light weight representation of probabilistic models of static graphs similar to bugs which can serve as a representation target of other front end dsls or be dynamically built the representation should consist of the model and node representations stochastic and deterministic perhaps hyperparameters and conform to the abstractppl model interface with basic functions evaluation of density sampling conditioning at later stages some static analysis like extraction of markov blankets the model should also contain the state of the variables and implement the abstractppl trace interface dictionary functions querying of variable names the result should be able to work with existing sampling packages through the abstract interfaces a modular tape caching mechanism for reversediffmentors qingliang zhuo mohamed tarekproject difficulty mediumproject length 175 hrsdescription tape caching often leads to significant performance improvements for gradient based sampling algorithms e g hmc nuts tape caching is only possible at the complete computational level for reversediff at the moment this project is about implementing a more modular i e function as a caching barrier tape caching mechanism for reversediff jl benchmarking amp improving performance of the juliagaussianprocesses librariesmentors theo galy fajou will tebbutt st johnproject difficulty mediumproject length 350 hrsdescription although kernelfunctions jl has extensive correctness testing our performance testing is lacking this project aims to resolve this and resolve performance issues wherever they are found the student would first need to extend our existing benchmarking coverage and debug any obvious performance problems the next phase of the work would be to construct end to end examples of kernelfunctions being used in practice profile them to determine where performance problems lie and fix them iterative methods for inference in gaussian processesmentors will tebbutt s t john ross viljoenproject difficulty mediumproject length 175 hrsdescription there has recently been quite a bit of work on inference methods for gps that use iterative methods rather than the cholesky factorisation they look quite promising but no one has implemented any of these within the julia gp ecosystem yet but they should fit nicely within the abstractgps framework if you re interested in improving the gp ecosystem in julia this project might be for you approximate inference methods for non gaussian likelihoods in gaussian processesmentors s t john ross viljoen theo galy fajouproject difficulty hardproject length 350 hrsdescription adding approximate inference methods for non gaussian likelihoods which are available in other gp packages but not yet within juliagps the project would start by determining which approximate inference method s to implement there s lots to do and we re happy to work with a student on whichever method they are most interested in or to suggest one if they have no strong preference gpu integration in the juliagps ecosystemmentors ross viljoen theo galy fajou will tebbuttproject difficulty mediumproject length 350 hrsdescription this would involve first ensuring that common models are able to run fully on the gpu then identifying and improving gpu specific performance bottlenecks this would begin by implementing a limited end to end example involving a gp with a standard kernel and profiling it to debug any substantial performance bottlenecks from there support for a wider range of the functionality available in kernelfunctions jl and abstractgps jl can be added stretch goal extension of gpu support to some functionality in approximategps jl", "title": "Google Summer of Code 2022"},{"location": "/posts/2021-02-04-gsoc", "text": "it s about time for us to start thinking about projects we d like to see at turing jl for the google summer of code 2021 below is a list of projects the turing team would be interested in working with students on for the summer if you are interested in exploring any of these projects please reach out to the listed project mentors you can find their contact information at turing ml team mcmcchains improvementsmentors cameron pfiffer hong geproject difficulty easydescription mcmcchains is a key component of the turing jl ecosystem it is the package that determines how to analyze and store mcmc samples provided by packages like turing it s also used outside of turing for this project a student might improve the performance of the various statistical functions provided by mcmcchains changing the back end to use a data storage format that maintains the shape of parameter samples or improve the general plotting functionality of the package there s lots of fun little things to do for mcmcchains check out this meta issue for more details and dicussions particle filtering methodsmentors hong ge cameron pfifferproject difficulty mediumdescription turing s support for particle sampling methods is slowing being improved with the addition of advancedps jl if you re interested in implementing or improving particle sampling methods this is a great project for you nested samplingmentors miles lucas cameron pfiffer hong geproject difficulty harddescription nestedsamplers jl is an excellent package which implements nested sampling methods as of yet it is not connected to turing jl for this project a student would connect the nestedsamplers jl library to turing jl gpu accelerationmentors mohamed tarek hong ge kai xu tor fjeldeproject difficulty mediumdescription turing s native gpu support is limited in that the metropolis hastings and hmc samplers do not implement gpu sampling methods this can and should be done gpu methods are awesome if you are interested with working on parallelism and gpus this project is for you students will work with the code at advancedmh or advancedhmc depending on their interests documentation and tutorial improvementsmentors cameron pfiffer martin trappproject difficulty easydescription turing s documentation and tutorials need a bit of an overhaul turing has changed significantly since the last time the documentation was written and it s beginning to show students would use their knowledge of probabilistic programming languages and turing to shore up or rewrite documentation and tutorials iterative methods for inference in gaussian processesmentors will tebbutt s t john theo galy fajouproject difficulty mediumdescription there has recently been quite a bit of work on inference methods for gps that use iterative methods rather than the cholesky factorisation they look quite promising but no one has implemented any of these within the julia gp ecosystem yet but they should fit nicely within the abstractgps framework if you re interested in improving the gp ecosystem in julia this project might be for you implement advanced variational gaussian process modelsmentors st john will tebbutt theo galy fajouproject difficulty easy to mediumdescription sparse variational gaussian process models provide the flexibility to scale to large datasets handle arbitrary non conjugate likelihoods and to be used as building blocks for composite models such as deep gps this project is about making such models more readily available within the julia gp ecosystem depending on your interests you can focus on making it easier for end users and providing good tutorials or on the implementations of these models to give us the same or better performance as with established python packages such as gpflow integrating with flux jl etc", "title": "Google Summer of Code 2021"},{"location": "/posts/2020-09-11-gsoc", "text": "as the 2020 google summer of code comes to a close the turing team thought it would be a good opportunity to reflect on the work that was done by our superb students this summer saranjeet kaur s project focused primarily on expanding nestedsamplers jl nestedsamplers jl now supports polychord style nested sampling natively which is an absolute delight saranjeet wrote about this here she also provided a good tutorial on how to use nestedsamplers jl here the nestedsamplers jl integration with turing is still on going integrating new samplers with turing is one of the more difficult tasks if you are interested to see the progress on this check out the relevant pull request arthur lui s project was to provide a much needed set of benchmarks of bayesian nonparametric models between turing and other ppls arthur s work spawned a github repository with good practices for benchmarking as well as three blog posts with some very cool statistics on turing s performance dirichlet process gaussian mixture model via the stick breaking construction in various pplsgaussian process regression model in various pplsgaussian process classification model in various pplsfinally sharan yalburgi a returning gsoc student completed an epic amount of work turing s growing suite of gaussian process tools in particular the github organization juliagaussianprocesses was founded and serves as an effort to build a robust gaussian process framework for the julia ecosystem the framework consists of multiple gp related julia packages kernelfunctions jl provides kernel functions for gps as well as efficient ad for these kernels kernelfunctions jl also supports multi output gps by providing necessary data abstractions and multi output kernels abstractgps jl defines gp abstractions and provides exact posteriors it provides support for induced points based gp posteriors and for efficient sequential online sparse gp updates gplikelihoods jl defines alternate likelihoods for non gaussian gps gpmlj jl provides a julia interface for gpflow a gp library written in python using tensorflow special thanks to our three gsoc students for this summer who all did excellent work additional thanks to google for supporting open source software development and the julia language", "title": "Google Summer of Code 2020"},{"location": "/posts/2020-05-04-Imperial-Report13-analysis", "text": "the turing jl team is currently exploring possibilities in an attempt to help with the ongoing sars cov 2 crisis as preparation for this and to get our feet wet we decided to perform a replication study of the imperial report 13 which attempts to estimate the real number of infections and impact of non pharmaceutical interventions on covid 19 in the report the inference was performed using the probabilistic programming language ppl stan we have explicated their model and inference in turing jl a julia based ppl we believe the results and analysis of our study are relevant for the public and for other researchers who are actively working on epidemiological models to that end our implementation and results are available here in summary we replicated the imperial covid 19 model using turing jl subsequently we compared the inference results between turing and stan and our comparison indicates that results are reproducible with two different implementations in particular we performed 4 sets of simulations using the imperial covid 19 model the resulting estimates of the expected real number of cases in contrast to the recorded number of cases the reproduction number r t and the expected number of deaths as a function of time and non pharmaceutical interventions npis for each simulation are shown below simulation a hypothetical simulation from the model without data prior predictive or non pharmaceutical interventions under the prior assumptions of the imperial covid 19 model there is a very wide range of epidemic progressions with expected cases from almost 0 to 100 of the population over time the black bar corresponds to the date of the last observation note that r t has a different time range than the other plots following the original report this shows the 100 days following the country specific epidemic start which is defined to be 31 days prior to the first date of 10 cumulative deaths while the other plots show the last 60 days simulation b future simulation with non pharmaceutical interventions kept in place posterior predictive after incorporating the observed infection data we can see a substantially more refined range of epidemic progression the reproduction rate estimate lies in the range of 3 5 5 6 before any intervention is introduced the dotted lines correspond to observations and the black bar corresponds to the date of the last observation simulation c future simulation with non pharmaceutical interventions removed now we see the hypothetical scenarios after incorporating infection data but with non pharmaceutical interventions removed this plot looks similar to simulation a but with a more rapid progression of the pandemic since the estimated reproduction rate is bigger than the prior assumptions the dotted lines correspond to observations and the black bar corresponds to the date of the last observation simulation d future simulation with when lockdown is lifted two weeks before the last observation predictive posterior as a result there is a clear rapid rebound of the reproduction rate comparing with simulation b we do not observe an immediate increase in the number of expected cases and deaths upon lifting lockdown but there is a significant difference in the number of cases and deaths in the last few days in the plot simulation d results in both greater number of cases and deaths as expected this demonstrates how the effects of lifting an intervention might not become apparent in the measurable variables e g deaths until several weeks later the dotted lines correspond to observations the black bar corresponds to the date of the last observation and the red bar indicates when lockdown was lifted overall simulation a shows the prior modelling assumptions and how these prior assumptions determine the predicted number of cases etc before seeing any data simulation b predicts the trend of the number of cases etc using estimated parameters and by keeping all the non pharmaceutical interventions in place simulation c shows the estimate in the case where none of the intervention measures are ever put in place simulation d shows the estimates in the case when the lockdown was lifted two weeks prior to the last observation while keeping all the other non pharmaceutical interventions in place we want to emphasise that we do not provide additional analysis of the imperial model yet nor are we aiming to make any claims about the validity or the implications of the model instead we refer to imperial report 13 for more details and analysis the purpose of this post is solely to add validation to the inference performed in the paper by obtaining the same results using a different probabilistic programming language ppl and by exploring whether or not turing jl can be useful for researchers working on these problems for our next steps we re looking at collaboration with other researchers and further developments of this and similar models there are some immediate directions to explore incoporation of more sources of data e g national mobility seasonal changes and behavior changes in individuals how the assumptions incorporated into the priors and their parameters change resulting posterior the current model does not directly include recovery as a possibility and assumes that if a person has been infected once then he she will be infectious until death number of recovered cases suffers from the same issues as the number of cases it cannot be directly observed but we can also deal with it in a similar manner as is done with number of cases and incorporate this into the model for a potential improvement this will result in a plethora of different models from which we can select the most realistic one using different model comparions techniques e g leave one out cross validation loo cv such model refinement can be potentially valuable given the high impact of this pandemic and the uncertainty and debates in the potential outcomes acknowledgement we would like to thank the julia community for creating such an excellent platform for scientific computing and for the continuous feedback that we have received we also thank researchers from computational and biological laboratory at cambridge university for their feedback on an early version of the post", "title": "Replication study: Estimating number of infections and impact of NPIs on COVID-19 in European countries (Imperial Report 13)"},{"location": "/posts/2020-02-12-jsoc", "text": "last year turing participated in the google summer of code gsoc through the julia language organization it was a fun time and the project was better for it turing plans to participate in the upcoming gsoc and we wanted to outline some potential projects and expectations we have for applicants if you are not aware google provides funds to students around the world to develop a project of their choice over the summer students receive funds from google and spend three months on any open source project the turing development team has prepared a list of possible projects that we have deemed valuable to the project and easy enough that it could feasibly be created in the three month limit this list is not exlusive if you have a good idea you can write it up in your proposal though it is recommend that you reach out to any of the turing team on julia s slack you can get an invite here or discourse messages on discourse should be posted to the quot probabilistic programming quot category we ll find you possible project ideas benchmarking turing s performance has been sporadically benchmarked against various other probabilistic programming languages e g turing stan pymc3 tensorflow prob but a systemic approach to studying where turing excels and where it falls short would be useful a gsoc student would implement identical models in many ppls and build tools to benchmark all ppls against one another nested sampling integration turing focuses on modularity in inference methods and the development team would like to see more inference methods particularly the popular nested sampling method a julia package nestedsamplers jl but it is not hooked up to turing and does not currently have a stable api a gsoc student would either integrate that package or construct their own nested sampling method and build it into turing automated function memoization by model annotation function memoization is a way to reduce costly function evaluation by caching the output when the same inputs are given turing s gibbs sampler often ends up rerunning expensive functions multiple times and it would be a significant performance improvement to allow turing s model compiler to automatically memoize functions where appropriate a student working on this project would become intimately familiar with turing s model compiler and build in various automated improvements making distributions gpu compatible julia s gpu tooling is generally quite good but currently turing is not able to reliably use gpus while sampling because distributions jl is not gpu compatible a student on this project would work with the turing developers and the distributions developers to allow the use of gpu parallelism where possible in turing static distributions small fixed size vectors and matrices are fairly common in turing models this means that sampling in turing can probably benefit from using statically sized vectors and matrices from staticarrays jl instead of the dynamic normal julia arrays beside the often superior performance of small static vectors and matrices static arrays are also automatically compatible with the gpu stack in julia currently the main obstacle to using staticarrays jl is that distributions in distributions jl are not compatible with staticarrays a gsoc student would adapt the multivariate and matrix variate distributions as well as the univariate distribution with vector parameters in distributions jl to make a spin off package called staticdistributions jl the student would then benchmark staticdistributions jl against distributions jl and showcase an example of using staticdistributions jl together with cuarrays jl and or cudanative jl for gpu acceleration gpnet extensions one of turing s sattelite packages gpnet is designed to provide a comprehensive suite of gaussian process tools see this issue for potential tasks there s a lot of interesting stuff going on with gps and this task in particular may have some creative freedom to it better chains and model diagnostics one package that turing and many others rely on heavily is mcmcchains jl a package designed to format store and analyze parameter samples generated during mcmc inference mcmcchains is currently showing its age a little and has many bad design choices that need to be fixed alternatively a student could contstruct a far more lightweight chain system model comparison tools turing and its sattelite packages do not currently provide a comprehensive suite of model comparison tools a critical tool for the applied statistician a student who worked on this project would implement various model comparison tools like loo and waic among others mle map tools maximum likelihood estimates mle and maximum a posteriori map estimates can currently only be done by users through a clunky set of workarounds a streamlined function like mle model or map model would be very useful for many of turing s users who want to see what the mle or map estimates look like and it may be valuable to allow for functionality that allows mcmc sampling to begin from the mle or map estimates students working on this project will work with optimization packages such as optim jl to make mle and map estimation straightforward for turing models particle sampler improvements turing s development team has spent a lot of time and energy to make inference methods more modular but turing s particle samplers have not yet been modernized and spun off into a separate package two packages that resulted from this were advancedhmc for hamiltonian mcmc methods and advancedmh for metropolis hastings style inference methods a student who worked on this project would become very familiar with turing s inference backend and with particle sampling methods this is a good project for people who love making things efficient and easily extendable other projects are welcome but we do strongly recommend discussing any potential projects with members of the turing team as they will end up mentoring gsoc students for the duration of the project we re looking forward to what people are interested in", "title": "Google Summer of Code/Julia Summer of Code"},{"location": "/posts/2019-12-14-initial-post", "text": "all good open source projects should have a blog and turing is one such project later on members of the turing team may be populating this feed with posts on topics likeinteresting things you can do with turing or interesting things we have seen others do development updates and major release announcements research updates explorations of turing s internals updates to turing s sattelite projects advancedhmc jl or bijectors jl stay tuned", "title": "Turing's Blog"},{"location": "/docs/contributing/guide", "text": "contributingturing is an open source project if you feel that you have some relevant skills and are interested in contributing then please do get in touch you can contribute by opening issues on github or implementing things yourself and making a pull request we would also appreciate example models written using turing turing has a style guide it is not strictly necessary to review it before making a pull request but you may be asked to change portions of your code to conform with the style guide before it is merged how to contributegetting startedfork this repository clone your fork on your local machine git clone https github com your username turing jl add a remote corresponding to this repository git remote add upstream https github com turinglang turing jl what can i do look at the issues page to find an outstanding issue for instance you could implement new features fix bugs or write example models git workflowfor more information on how the git workflow typically functions please see the github s introduction or julia s contribution guide", "title": "Contributing"},{"location": "/docs/contributing/style-guide", "text": "style guidethis style guide is adapted from invenia s style guide we would like to thank them for allowing us to access and use it please don t let not having read it stop you from contributing to turing no one will be annoyed if you open a pr whose style doesn t follow these conventions we will just help you correct it before it gets merged these conventions were originally written at invenia taking inspiration from a variety of sources including python s pep8 julia s notes for contributors and julia s style guide what follows is a mixture of a verbatim copy of invenia s original guide and some of our own modifications a word on consistencywhen adhering to this style it s important to realize that these are guidelines and not rules this is stated best in the pep8 a style guide is about consistency consistency with this style guide is important consistency within a project is more important consistency within one module or function is most important but most importantly know when to be inconsistent sometimes the style guide just doesn t apply when in doubt use your best judgment look at other examples and decide what looks best and don t hesitate to ask synopsisattempt to follow both the julia contribution guidelines the julia style guide and this guide when convention guidelines conflict this guide takes precedence known conflicts will be noted in this guide use 4 spaces per indentation level no tabs try to adhere to a 92 character line length limit use upper camel case convention for modules and types use lower case with underscores for method names note julia code likes to use lower case without underscores comments are good try to explain the intentions of the code use whitespace to make the code more readable no whitespace at the end of a line trailing whitespace avoid padding brackets with spaces ex int64 value preferred over int64 value editor configurationsublime text settingsif you are a user of sublime text we recommend that you have the following options in your julia syntax specific settings to modify these settings first open any julia file jl in sublime text then navigate to preferences gt settings more gt syntax specific user translate tabs to spaces true tab size 4 trim trailing white space on save true ensure newline at eof on save true rulers 92 vim settingsif you are a user of vim we recommend that you add the following options to your vimrc file set tabstop 4 quot sets tabstops to a width of four columns set softtabstop 4 quot determines the behaviour of tab and backspace keys with expandtab set shiftwidth 4 quot determines the results of gt gt lt lt and au filetype julia setlocal expandtab quot replaces tabs with spaces au filetype julia setlocal colorcolumn 93 quot highlights column 93 to help maintain the 92 character line limit by default vim seems to guess that jl files are written in lisp to ensure that vim recognizes julia files you can manually have it check for the jl extension but a better solution is to install julia vim which also includes proper syntax highlighting and a few cool other features atom settingsatom defaults preferred line length to 80 characters we want that at 92 for julia to change it go to atom gt preferences gt packages search for the quot language julia quot package and open the settings for it find preferred line length under quot julia grammar quot and change it to 92 code formattingfunction namingnames of functions should describe an action or property irrespective of the type of the argument the argument s type provides this information instead for example buyfood food should be buy food food names of functions should usually be limited to one or two lowercase words ideally write buyfood not buy food but if you are writing a function whose name is hard to read without underscores then please do use them method definitionsonly use short form function definitions when they fit on a single line yes foo x int64 abs x 3 no foobar array data abstractarray t item t where t lt int64 t abs x abs item 3 for x in array data no foobar array data abstractarray t item t where t lt int64 t abs x abs item 3 for x in array data yes function foobar array data abstractarray t item t where t lt int64 return t abs x abs item 3 for x in array data endwhen using long form functions always use the return keyword yes function fnc x result zero x result fna x return resultend no function fnc x result zero x result fna x end yes function foo x y return new x y end no function foo x y new x y endfunctions definitions with parameter lines which exceed 92 characters should separate each parameter by a newline and indent by one level yes function foobar df dataframe id symbol variable symbol value abstractstring prefix abstractstring codeend ok function foobar df dataframe id symbol variable symbol value abstractstring prefix abstractstring codeend no function foobar df dataframe id symbol variable symbol value abstractstring prefix abstractstring codeend no function foobar df dataframe id symbol variable symbol value abstractstring prefix abstractstring codeendkeyword argumentswhen calling a function always separate your keyword arguments from your positional arguments with a semicolon this avoids mistakes in ambiguous cases such as splatting a dict yes xy foo x y 3 no xy foo x y 3 whitespaceavoid extraneous whitespace in the following situations immediately inside parentheses square brackets or braces yes spam ham 1 eggs no spam ham 1 eggs immediately before a comma or semicolon yes if x 4 show x y x y y x endno if x 4 show x y x y y x endwhen using ranges unless additional operators are used yes ham 1 9 ham 1 3 9 ham 1 3 end no ham 1 9 ham 1 3 9 yes ham lower upper ham lower step upper yes ham lower offset upper offset yes ham lower offset upper offset no ham lower offset upper offset more than one space around an assignment or other operator to align it with another yes x 1y 2long variable 3 no x 1y 2long variable 3when using parametric types yes f a abstractarray t n where t lt real n g a abstractarray lt real n where n no f a abstractarray t n where t lt real n g a abstractarray lt real n where n always surround these binary operators with a single space on either side assignment updating operators etc numeric comparisons operators lt gt etc note that this guideline does not apply when performing assignment in method definitions yes i i 1no i i 1yes submitted 1no submitted 1yes x 2 lt yno x 2 lt yassignments using expanded array tuple or function notation should have the first open bracket on the same line assignment operator and the closing bracket should match the indentation level of the assignment alternatively you can perform assignments on a single line when they are short yes arr 1 2 3 arr 1 2 3 result function arg1 arg2 arr 1 2 3 no arr 1 2 3 arr 1 2 3 arr 1 2 3 nested array or tuples that are in expanded notation should have the opening and closing brackets at the same indentation level yes x 1 2 3 hello world a b c no y 1 2 3 hello world z 1 2 3 hello world always include the trailing comma when working with expanded arrays tuples or functions notation this allows future edits to easily move elements around or add additional elements the trailing comma should be excluded when the notation is only on a single line yes arr 1 2 3 result function arg1 arg2 arr 1 2 3 no arr 1 2 3 result function arg1 arg2 arr 1 2 3 triple quotes use the indentation of the lowest indented line excluding the opening triple quote this means the closing triple quote should be aligned to least indented line in the string triple backticks should also follow this style even though the indentation does not matter for them yes str hello world str hello world cmd program flag value parameter no str hello world commentscomments should be used to state the intended behaviour of code this is especially important when the code is doing something clever that may not be obvious upon first inspection avoid writing comments that state exactly what the code obviously does yes x x 1 compensate for border no x x 1 increment xcomments that contradict the code are much worse than no comments always make a priority of keeping the comments up to date with code changes comments should be complete sentences if a comment is a phrase or sentence its first word should be capitalized unless it is an identifier that begins with a lower case letter never alter the case of identifiers if a comment is short the period at the end can be omitted block comments generally consist of one or more paragraphs built out of complete sentences and each sentence should end in a period comments should be separated by at least two spaces from the expression and have a single space after the when referencing julia in documentation note that quot julia quot refers to the programming language while quot julia quot typically in backticks e g julia refers to the executable a commmentcode another commentmore codetododocumentationit is recommended that most modules types and functions should have docstrings that being said only exported functions are required to be documented avoid documenting methods like as the built in docstring for the function already covers the details well try to document a function and not individual methods where possible as typically all methods will have similar docstrings if you are adding a method to a function which was defined in base or another package only add a docstring if the behaviour of your function deviates from the existing docstring docstrings are written in markdown and should be concise docstring lines should be wrapped at 92 characters bar x y compute the bar index between x and y if y is missing compute the bar index betweenall pairs of columns of x function bar x y when types or methods have lots of parameters it may not be feasible to write a concise docstring in these cases it is recommended you use the templates below note if a section doesn t apply or is overly verbose for example quot throws quot if your function doesn t throw an exception it can be excluded it is recommended that you have a blank line between the headings and the content when the content is of sufficient length try to be consistent within a docstring whether you use this additional whitespace note that the additional space is only for reading raw markdown and does not effect the rendered version type template should be skipped if is redundant with the constructor s docstring myarray t n my super awesome array wrapper fields data abstractarray t n stores the array being wrapped metadata dict stores metadata about the array struct myarray t n lt abstractarray t n data abstractarray t n metadata dictendfunction template only required for exported functions mysearch array myarray t val t verbose true where t gt intsearches the array for the val for some reason we don t want to use julia sbuiltin search arguments array myarray t the array to search val t the value to search for keywords verbose bool true print out progress details returns int the index where val is located in the array throws notfounderror i guess we could throw an error if val isn t found function mysearch array abstractarray t val t where t endif your method contains lots of arguments or keywords you may want to exclude them from the method signature on the first line and instead use args and or kwargs manager args kwargs gt managera cluster manager which spawns workers arguments min workers integer the minimum number of workers to spawn or an exception is thrown max workers integer the requested number of worker to spawn keywords definition abstractstring name of the job definition to use defaults to the definition used within the current instance name abstractstring queue abstractstring function manager endfeel free to document multiple methods for a function within the same docstring be careful to only do this for functions you have defined manager max workers kwargs manager min workers max workers kwargs manager min workers max workers kwargs a cluster manager which spawns workers arguments min workers int the minimum number of workers to spawn or an exception is thrown max workers int the number of requested workers to spawn keywords definition abstractstring name of the job definition to use defaults to the definition used within the current instance name abstractstring queue abstractstring function manager endif the documentation for bullet point exceeds 92 characters the line should be wrapped and slightly indented avoid aligning the text to the keywords definition abstractstring name of the job definition to use defaults to the definition used within the current instance for additional details on documenting in julia see the official documentation test formattingtestsetsjulia provides test sets which allows developers to group tests into logical groupings test sets can be nested and ideally packages should only have a single quot root quot test set it is recommended that the quot runtests jl quot file contains the root test set which contains the remainder of the tests testset pkgextreme begin include arithmetic jl include utils jl endthe file structure of the test folder should mirror that of the src folder every file in src should have a complementary file in the test folder containing tests relevant to that file s contents comparisonsmost tests are written in the form test x y since the function doesn t take types into account tests like the following are valid test 1 0 1 avoid adding visual noise into test comparisons yes test value 0 no test value 0 0in cases where you are checking the numerical validity of a model s parameter estimates please use the check numerical function found in test test utils numerical tests jl this function will evaluate a model s parameter estimates using tolerance levels atol and rtol testing will only be performed if you are running the test suite locally or if travis is executing the quot numerical quot testing stage here is an example of usage check that m and s are plus or minus one from 1 5 and 2 2 respectively check numerical chain m s 1 5 2 2 atol 1 0 checks the estimates for a default gdemo model using values 1 5 and 2 0 check gdemo chain atol 0 1 checks the estimates for a default mog model check mogtest default chain atol 0 1", "title": "Style Guide"},{"location": "/docs/for-developers/compiler", "text": "in this section the current design of turing s model quot compiler quot is described which enables turing to perform various types of bayesian inference without changing the model definition the quot compiler quot is essentially just a macro that rewrites the user s model definition to a function that generates a model struct that julia s dispatch can operate on and that julia s compiler can successfully do type inference on for efficient machine code generation overviewthe following terminology will be used in this section d observed data variables conditioned upon in the posterior p parameter variables distributed according to the prior distributions these will also be referred to as random variables model a fully defined probabilistic model with input dataturing s model macro rewrites the user provided function definition such that it can be used to instantiate a model by passing in the observed data d the following are the main jobs of the model macro parse and lines e g y normal c x 1 0 figure out if a variable belongs to the data d and or to the parameters penable the handling of missing data variables in d when defining a model and treating them as parameter variables in p insteadenable the tracking of random variables using the data structures varname and varinfochange lines with a variable in p on the lhs to a call to tilde assume or dot tilde assumechange lines with a variable in d on the lhs to a call to tilde observe or dot tilde observeenable type stable automatic differentiation of the model using type parametersthe modela model model is a callable struct that one can sample from by calling model model rng varinfo sampler context where rng is a random number generator default random default rng varinfo is a data structure that stores information about the random variables default dynamicppl varinfo sampler is a sampling algorithm default dynamicppl samplefromprior and context is a sampling context that can e g modify how the log probability is accumulated default dynamicppl defaultcontext sampling resets the log joint probability of varinfo and increases the evaluation counter of sampler if context is a likelihoodcontext only the log likelihood will be accumulated with the defaultcontext the log joint probability of p and d is accumulated the model struct contains the three internal fields f args and defaults when model model is called then the internal function model f is called as model f rng varinfo sampler context model args for multithreaded sampling instead of varinfo a threadsafe wrapper is passed to model f the positional and keyword arguments that were passed to the user defined model function when the model was created are saved as a namedtuple in model args the default values of the positional and keyword arguments of the user defined model functions if any are saved as a namedtuple in model defaults they are used for constructing model instances with different arguments by the logprob and prob string macros examplelet s take the following model as an example model function gauss x missing y 1 0 type tv vector float64 where tv lt abstractvector if x missing x tv undef 3 end p tv undef 2 p 1 inversegamma 2 3 p 2 normal 0 1 0 x 1 2 normal p 2 sqrt p 1 x 3 normal y normal p 2 sqrt p 1 endthe above call of the model macro defines the function gauss with positional arguments x y and type tv rewritten in such a way that every call of it returns a model model note that only the function body is modified by the model macro and the function signature is left untouched it is also possible to implement models with keyword arguments such as model function gauss type tv vector float64 x missing y 1 0 where tv lt abstractvector endthis would allow us to generate a model by calling gauss x rand 3 if an argument has a default value missing it is treated as a random variable for variables which require an initialization because we need to loop or broadcast over its elements such as x above the following needs to be done if x missing x endnote that since gauss behaves like a regular function it is possible to define additional dispatches in a second step as well for instance we could achieve the same behaviour by model function gauss x y 1 0 type tv vector float64 where tv lt abstractvector p tv undef 2 endfunction gauss missing y 1 0 type tv vector float64 where tv lt abstractvector return gauss tv undef 3 y tv endif x is sampled as a whole from a distribution and not indexed e g x normal or x mvnormal there is no need to initialize it in an if block step 1 break up the model definitionfirst the model macro breaks up the user provided function definition using dynamicppl build model info this function returns a dictionary consisting of allargs exprs the expressions of the positional and keyword arguments without default values allargs syms the names of the positional and keyword arguments e g x y tv above allargs namedtuple an expression that constructs a namedtuple of the positional and keyword arguments e g x x y y tv tv above defaults namedtuple an expression that constructs a namedtuple of the default positional and keyword arguments if any e g x missing y 1 tv vector float64 above modeldef a dictionary with the name arguments and function body of the model definition as returned by macrotools splitdef step 2 generate the body of the internal model functionin a second step dynamicppl generate mainbody generates the main part of the transformed function body using the user provided function body and the provided function arguments without default values for figuring out if a variable denotes an observation or a random variable hereby the function dynamicppl generate tilde replaces the l r lines in the model and the function dynamicppl generate dot tilde replaces the l r and l r lines in the model in the above example p 1 inversegamma 2 3 is replaced with something similar to repl 25 6 begin var tmpright 323 inversegamma 2 3 var tmpright 323 isa union distribution abstractvector lt distribution throw argumenterror right hand side of a must be subtype of distribution or a vector of distributions var vn 325 dynamicppl varname p 1 var inds 326 1 p 1 dynamicppl tilde assume rng context sampler var tmpright 323 var vn 325 var inds 326 varinfo endhere the first line is a so called line number node that enables more helpful error messages by providing users with the exact location of the error in their model definition then the right hand side rhs of the is assigned to a variable with an automatically generated name we check that the rhs is a distribution or an array of distributions otherwise an error is thrown next we extract a compact representation of the variable with its name and index or indices finally the expression is replaced with a call to dynamicppl tilde assume since the compiler figured out that p 1 is a random variable using the following heuristic if the symbol on the lhs of p in this case is not among the arguments to the model x y t in this case it is a random variable if the symbol on the lhs of p in this case is among the arguments to the model but has a value of missing it is a random variable if the value of the lhs of p 1 in this case is missing then it is a random variable otherwise it is treated as an observation the dynamicppl tilde assume function takes care of sampling the random variable if needed and updating its value and the accumulated log joint probability in the varinfo object if l r is an observation dynamicppl tilde observe is called with the same arguments except the random number generator rng since observations are never sampled a similar transformation is performed for expressions of the form l r and l r for instance x 1 2 normal p 2 sqrt p 1 is replaced with repl 25 8 begin var tmpright 331 normal p 2 sqrt p 1 var tmpright 331 isa union distribution abstractvector lt distribution throw argumenterror right hand side of a must be subtype of distribution or a vector of distributions var vn 333 dynamicppl varname x 1 2 var inds 334 1 2 var isassumption 335 begin let var vn 336 dynamicppl varname x 1 2 if dynamicppl inargnames var vn 336 model dynamicppl inmissings var vn 336 model true else x 1 2 missing end end end if var isassumption 335 x 1 2 dynamicppl dot tilde assume rng context sampler var tmpright 331 x 1 2 var vn 333 var inds 334 varinfo else dynamicppl dot tilde observe context sampler var tmpright 331 x 1 2 var vn 333 var inds 334 varinfo endendthe main difference in the expanded code between l r and l r is that the former doesn t assume l to be defined it can be a new julia variable in the scope while the latter assumes l already exists moreover dynamicppl dot tilde assume and dynamicppl dot tilde observe are called instead of dynamicppl tilde assume and dynamicppl tilde observe step 3 replace the user provided function bodyfinally we replace the user provided function body using dynamicppl build output this function uses macrotools combinedef to reassemble the user provided function with a new function body in the modified function body an anonymous function is created whose function body was generated in step 2 above and whose arguments area random number generator rng a model model a datastructure varinfo a sampler sampler a sampling context context and all positional and keyword arguments of the user provided model function as positional argumentswithout any default values finally in the new function body a model model with this anonymous function as internal function is returned varnamein order to track random variables in the sampling process turing uses the varname struct which acts as a random variable identifier generated at runtime the varname of a random variable is generated from the expression on the lhs of a statement when the symbol on the lhs is in the set p of unobserved random variables every varname instance has a type parameter sym which is the symbol of the julia variable in the model that the random variable belongs to for example x 1 normal will generate an instance of varname x assuming x is an unobserved random variable every varname also has a field indexing which stores the indices required to access the random variable from the julia variable indicated by sym as a tuple of tuples each element of the tuple thereby contains the indices of one indexing operation varname also supports hierarchical arrays and range indexing some examples x normal will generate a varname x x 1 normal will generate a varname x 1 x 1 mvnormal zeros 2 i will generate a varname x colon 1 x 1 1 1 normal will generate a varname x colon 1 2 the easiest way to manually construct a varname is to use the varname macro on an indexing expression which will take the sym value from the actual variable name and put the index values appropriately into the constructor varinfooverviewvarinfo is the data structure in turing that facilitates tracking random variables and certain metadata about them that are required for sampling for instance the distribution of every random variable is stored in varinfo because we need to know the support of every random variable when sampling using hmc for example random variables whose distributions have a constrained support are transformed using a bijector from bijectors jl so that the sampling happens in the unconstrained space different samplers require different metadata about the random variables the definition of varinfo in turing is struct varinfo tmeta tlogp lt abstractvarinfo metadata tmeta logp base refvalue tlogp num produce base refvalue int endbased on the type of metadata the varinfo is either aliased untypedvarinfo or typedvarinfo metadata can be either a subtype of the union type metadata or a namedtuple of multiple such subtypes let vi be an instance of varinfo if vi isa varinfo lt metadata then it is called an untypedvarinfo if vi isa varinfo lt namedtuple then vi metadata would be a namedtuple mapping each symbol in p to an instance of metadata vi would then be called a typedvarinfo the other fields of varinfo include logp which is used to accumulate the log probability or log probability density of the variables in p and d num produce keeps track of how many observations have been made in the model so far this is incremented when running a statement when the symbol on the lhs is in d metadatathe metadata struct stores some metadata about the random variables sampled this helps query certain information about a variable such as its distribution which samplers sample this variable its value and whether this value is transformed to real space or not let md be an instance of metadata md vns is the vector of all varname instances let vn be an arbitrary element of md vnsmd idcs is the dictionary that maps each varname instance to its index inmd vns md ranges md dists md orders and md flags md vns md idcs vn vn md dists md idcs vn is the distribution of vn md gids md idcs vn is the set of algorithms used to sample vn this is used inthe gibbs sampling process md orders md idcs vn is the number of observe statements before vn is sampled md ranges md idcs vn is the index range of vn in md vals md vals md ranges md idcs vn is the linearized vector of values of corresponding to vn md flags is a dictionary of true false flags md flags flag md idcs vn is thevalue of flag corresponding to vn note that in order to make md metadata type stable all the md vns must have the same symbol and distribution type however one can have a single julia variable e g x that is a matrix or a hierarchical array sampled in partitions e g x 1 mvnormal zeros 2 i x 2 mvnormal ones 2 i the symbol x can still be managed by a single md metadata without hurting the type stability since all the distributions on the rhs of are of the same type however in turing models one cannot have this restriction so we must use a type unstable metadata if we want to use one metadata instance for the whole model this is what untypedvarinfo does a type unstable metadata will still work but will have inferior performance to strike a balance between flexibility and performance when constructing the spl sampler instance the model is first run by sampling the parameters in p from their priors using an untypedvarinfo i e a type unstable metadata is used for all the variables then once all the symbols and distribution types have been identified a vi typedvarinfo is constructed where vi metadata is a namedtuple mapping each symbol in p to a specialized instance of metadata so as long as each symbol in p is sampled from only one type of distributions vi typedvarinfo will have fully concretely typed fields which brings out the peak performance of julia", "title": "Turing Compiler Design"},{"location": "/docs/for-developers/how_turing_implements_abstractmcmc", "text": "how turing implements abstractmcmcprerequisite interface guide introductionconsider the following turing code block model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s endmod gdemo 1 5 2 alg is n samples 1000chn sample mod alg n samples the function sample is part of the abstractmcmc interface as explained in the interface guide building a a sampling method that can be used by sample consists in overloading the structs and functions in abstractmcmc the interface guide also gives a standalone example of their implementation advancedmh jl turing sampling methods most of which are written here also implement abstractmcmc turing defines a particular architecture for abstractmcmc implementations that enables working with models defined by the model macro and uses dynamicppl as a backend the goal of this page is to describe this architecture and how you would go about implementing your own sampling method in turing using importance sampling as an example i don t go into all the details for instance i don t address selectors or parallelism first we explain how importance sampling works in the abstract consider the model defined in the first code block mathematically it can be written begin align s amp sim text inversegamma 2 3 m amp sim text normal 0 sqrt s x amp sim text normal m sqrt s y amp sim text normal m sqrt s end align the latent variables are s and m the observed variables are x and y the model joint distribution p s m x y decomposes into the prior p s m and the likelihood p x y mid s m since x 1 5 and y 2 are observed the goal is to infer the posterior distribution p s m mid x y importance sampling produces independent samples s i m i from the prior distribution it also outputs unnormalized weights w i frac p x y s i m i p s i m i p x y mid s i m i such that the empirical distribution frac 1 n sum i 1 n frac w i sum j 1 n w j delta s i m i is a good approximation of the posterior 1 define a samplerrecall the last line of the above code block chn sample mod alg n samples here sample takes as arguments a model mod an algorithm alg and a number of samples n samples and returns an instance chn of chains which can be analysed using the functions in mcmcchains modelsto define a model you declare a joint distribution on variables in the model macro and specify which variables are observed and which should be inferred as well as the value of the observed variables thus when implementing importance sampling mod gdemo 1 5 2 creates an instance mod of the struct model which corresponds to the observations of a value of 1 5 for x and a value of 2 for y this is all handled by dynamicppl more specifically here i will return to how models are used to inform sampling algorithms below algorithmsan algorithm is just a sampling method in turing it is a subtype of the abstract type inferencealgorithm defining an algorithm may require specifying a few high level parameters for example quot hamiltonian monte carlo quot may be too vague but quot hamiltonian monte carlo with 10 leapfrog steps per proposal and a stepsize of 0 01 quot is an algorithm quot metropolis hastings quot may be too vague but quot metropolis hastings with proposal distribution p quot is an algorithm thusstepsize 0 01l 10alg hmc stepsize l defines a hamiltonian monte carlo algorithm an instance of hmc which is a subtype of inferencealgorithm in the case of importance sampling there is no need to specify additional parameters alg is defines an importance sampling algorithm an instance of is which is a subtype of inferencealgorithm when creating your own turing sampling method you must therefore build a subtype of inferencealgorithm corresponding to your method samplerssamplers are not the same as algorithms an algorithm is a generic sampling method a sampler is an object that stores information about how algorithm and model interact during sampling and is modified as sampling progresses the sampler struct is defined in dynamicppl turing implements abstractmcmc s abstractsampler with the sampler struct defined in dynamicppl the most important attributes of an instance spl of sampler are spl alg the sampling method used an instance of a subtype of inferencealgorithmspl state information about the sampling process see belowwhen you call sample mod alg n samples turing first uses model and alg to build an instance spl of sampler then calls the native abstractmcmc function sample mod spl n samples when you define your own turing sampling method you must therefore build a sampler constructor that uses a model and an algorithm to initialize an instance of sampler for importance sampling function sampler alg is model model s selector info dict symbol any state isstate model return sampler alg info s state enda state struct implementing abstractsamplerstate corresponding to your method we cover this in the following paragraph statesthe vi field contains all the important information about sampling first and foremost the values of all the samples but also the distributions from which they are sampled the names of model parameters and other metadata as we will see below many important steps during sampling correspond to queries or updates to spl state vi by default you can use samplerstate a concrete type defined in inference inference jl which extends abstractsamplerstate and has no field except for vi mutable struct samplerstate vitype lt varinfo lt abstractsamplerstate vi vitypeendwhen doing importance sampling we care not only about the values of the samples but also their weights we will see below that the weight of each sample is also added to spl state vi moreover the average frac 1 n sum j 1 n w i frac 1 n sum j 1 n p x y mid s i m i of the sample weights is a particularly important quantity it is used to normalize the empirical approximation of the posterior distributionits logarithm is the importance sampling estimate of the log evidence log p x y to avoid having to compute it over and over again is jldefines an is specific concrete type isstate for sampler states with an additional field final logevidence containing log left frac 1 n sum j 1 n w i right mutable struct isstate v lt varinfo f lt abstractfloat lt abstractsamplerstate vi v final logevidence fend additional constructorisstate model model isstate varinfo model 0 0 the following diagram summarizes the hierarchy presented above 2 overload the functions used inside mcmcsamplea lot of the things here are method specific however turing also has some functions that make it easier for you to implement these functions for examples transitionsabstractmcmc stores information corresponding to each individual sample in objects called transition but does not specify what the structure of these objects could be you could decide to implement a type mytransition for transitions corresponding to the specifics of your methods however there are many situations in which the only information you need for each sample is its value theta log of the joint probability of the observed data and this sample lpinference jl defines a struct transition which corresponds to this default situationstruct transition t f lt abstractfloat t lp fendit also contains a constructor that builds an instance of transition from an instance spl of sampler theta is spl state vi converted to a namedtuple and lp is getlogp spl state vi is jl uses this default constructor at the end of the step function here how sample worksa crude summary which ignores things like parallelism is the following sample calls mcmcsample which callssample init to set things upstep repeatedly to produce multiple new transitionssample end to perform operations once all samples have been obtainedbundle samples to convert a vector of transitions into a more palatable type for instance a chain you can of course implement all of these functions but abstractmcmc as well as turing also provide default implementations for simple cases for instance importance sampling uses the default implementations of sample init and bundle samples which is why you don t see code for them inside is jl 3 overload assume and observethe functions mentioned above such as sample init step etc must of course use information about the model in order to generate samples in particular these functions may need samples from distributions defined in the model or to evaluate the density of these distributions at some values of the corresponding parameters or observations for an example of the former consider importance sampling as defined in is jl this implementation of importance sampling uses the model prior distribution as a proposal distribution and therefore requires samples from the prior distribution of the model another example is approximate bayesian computation which requires multiple samples from the model prior and likelihood distributions in order to generate a single sample an example of the latter is the metropolis hastings algorithm at every step of sampling from a target posterior p theta mid x text obs in order to compute the acceptance ratio you need to evaluate the model joint density p left theta text prop x text obs right with theta text prop a sample from the proposal and x text obs the observed data this begs the question how can these functions access model information during sampling recall that the model is stored as an instance m of model one of the attributes of m is the model evaluation function m f which is built by compiling the model macro executing f runs the tilde statements of the model in order and adds model information to the sampler the instance of sampler that stores information about the ongoing sampling process at each step see here for more information about how the model macro is compiled the dynamicppl functions assume and observe determine what kind of information to add to the sampler for every tilde statement consider an instance m of model and a sampler spl with associated varinfo vi spl state vi at some point during the sampling process an abstractmcmc function such as step calls m vi which calls the model evaluation function m f vi for every tilde statement in the model macro m f vi returns model related information samples value of the model density etc and adds it to vi how does it do that recall that the code for m f vi is automatically generated by compilation of the model macrofor every tilde statement in the model declaration this code contains a call to assume vi if the variable on the lhs of the tilde is a model parameter to infer and observe vi if the variable on the lhs of the tilde is an observationin the file corresponding to your sampling method ie in turing jl src inference lt your method gt jl you have overloaded assume and observe so that they can modify vi to include the information and samples that you care about at a minimum assume and observe return the log density lp of the sample or observation the model evaluation function then immediately calls acclogp vi lp which adds lp to the value of the log joint density stored in vi here s what assume looks like for importance sampling function dynamicppl assume rng spl sampler lt is dist distribution vn varname vi r rand rng dist push vi vn r dist spl return r 0endthe function first generates a sample r from the distribution dist the right hand side of the tilde statement it then adds r to vi and returns r and 0 the observe function is even simpler function dynamicppl observe spl sampler lt is dist distribution value vi return logpdf dist value endit simply returns the density in the discrete case the probability of the observed value under the distribution dist 4 summary importance sampling step by stepwe focus on the abstractmcmc functions that are overridden in is jl and executed inside mcmcsample step which is called n samples times and sample end which is executed once after those n samples iterations during the i th iteration step does 3 things empty spl state vi remove information about the previous sample from the sampler s varinfomodel rng spl state vi spl call the model evaluation functioncalls to assume add the samples from the prior s i and m i to spl state vicalls to both assume or observe are followed by the line acclogp vi lp where lp is an output of assume and observelp is set to 0 after assume and to the value of the density at the observation after observewhen all the tilde statements have been covered spl state vi logp is the sum of the lp i e the likelihood log p x y mid s i m i log p x mid s i m i log p y mid s i m i of the observations given the latent variable samples s i and m i return transition spl build a transition from the sampler and return that transitionthe transition s vi field is simply spl state vithe lp field contains the likelihood spl state vi logp when the n samples iterations are completed sample end fills the final logevidence field of spl stateit simply takes the logarithm of the average of the sample weights using the log weights for numerical stability", "title": "How Turing implements AbstractMCMC"},{"location": "/docs/for-developers/interface", "text": "the sampling interfaceturing implements a sampling interface hosted at abstractmcmc that is intended to provide a common framework for markov chain monte carlo samplers the interface presents several structures and functions that one needs to overload in order to implement an interface compatible sampler this guide will demonstrate how to implement the interface without turing interface overviewany implementation of an inference method that uses the abstractmcmc interface should implement a subset of the following types and functions a subtype of abstractsampler defined as a mutable struct containing state information or sampler parameters a function sample init which performs any necessary set up default do not perform any set up a function step which returns a transition that represents a single draw from the sampler a function transitions init which returns a container for the transitions obtained from the sampler default return a vector t of length n where t is the type of the transition obtained in the first step and n is the number of requested samples a function transitions save which saves transitions to the container default save the transition of iteration i at position i in the vector of transitions a function sample end which handles any sampler wrap up default do not perform any wrap up a function bundle samples which accepts the container of transitions and returns a collection of samples default return the vector of transitions the interface methods with exclamation points are those that are intended to allow for state mutation any mutating function is meant to allow mutation where needed you might use sample init to run some kind of sampler preparation before sampling begins this could mutate a sampler s state step might mutate a sampler flag after each sample sample end contains any wrap up you might need to do if you were sampling in a transformed space this might be where you convert everything back to a constrained space why do you have an interface the motivation for the interface is to allow julia s fantastic probabilistic programming language community to have a set of standards and common implementations so we can all thrive together markov chain monte carlo methods tend to have a very similar framework to one another and so a common interface should help more great inference methods built in single purpose packages to experience more use among the community implementing metropolis hastings without turingmetropolis hastings is often the first sampling method that people are exposed to it is a very straightforward algorithm and is accordingly the easiest to implement so it makes for a good example in this section you will learn how to use the types and functions listed above to implement the metropolis hastings sampler using the mcmc interface the full code for this implementation is housed in advancedmh jl importslet s begin by importing the relevant libraries we ll import abstracmcmc which contains the interface framework we ll fill out we also need distributions and random import the relevant libraries import abstractmcmcusing distributionsusing randoman interface extension like the one we re writing right now typically requires that you overload or implement several functions specifically you should import the functions you intend to overload this next code block accomplishes that from distributions we need sampleable variateform and valuesupport three abstract types that define a distribution models in the interface are assumed to be subtypes of sampleable variateform valuesupport in this section our model is going be be extremely simple so we will not end up using these except to make sure that the inference functions are dispatching correctly samplerlet s begin our sampler definition by defining a sampler called metropolishastings which is a subtype of abstractsampler correct typing is very important for proper interface implementation if you are missing a subtype your method may not be dispatched to when you call sample define a sampler type struct metropolishastings t d lt abstractmcmc abstractsampler init t proposal dend default constructors metropolishastings init real metropolishastings init normal 0 1 metropolishastings init vector lt real metropolishastings init mvnormal zero init i above we have defined a sampler that stores the initial parameterization of the prior and a distribution object from which proposals are drawn you can have a struct that has no fields and simply use it for dispatching onto the relevant functions or you can store a large amount of state information in your sampler the general intuition for what to store in your sampler struct is that anything you may need to perform inference between samples but you don t want to store in a transition should go into the sampler struct it s the only way you can carry non sample related state information between step calls modelnext we need to have a model of some kind a model is a struct that s a subtype of abstractmodel that contains whatever information is necessary to perform inference on your problem in our case we want to know the mean and variance parameters for a standard normal distribution so we can keep our model to the log density of a normal note that we only have to do this because we are not yet integrating the sampler with turing turing has a very sophisticated modelling engine that removes the need to define custom model structs define a model type stores the log density function struct densitymodel f lt function lt abstractmcmc abstractmodel fendtransitionthe next step is to define some transition which we will return from each step call we ll keep it simple by just defining a wrapper struct that contains the parameter draws and the log density of that draw create a very basic transition type only stores the parameter draws and the log probability of the draw struct transition t l t lp lend store the new draw and its log density transition model densitymodel transition model transition can now store any type of parameter whether it s a vector of draws from multiple parameters or a single univariate draw metropolis hastingsnow it s time to get into the actual inference we ve defined all of the core pieces we need but we need to implement the step function which actually performs inference as a refresher metropolis hastings implements a very basic algorithm pick some initial state theta 0 for t in 1 n dogenerate a proposal parameterization theta prime t sim q theta prime t mid theta t 1 calculate the acceptance probability alpha text min left 1 frac pi theta t pi theta t 1 frac q theta t 1 mid theta t q theta t mid theta t 1 right if u le alpha where u sim 0 1 then theta t theta t otherwise theta t theta t 1 of course it s much easier to do this in the log space so the acceptance probability is more commonly written as log alpha min left 0 log pi theta t log pi theta t 1 log q theta t 1 mid theta prime t log q theta prime t mid theta t 1 right in interface terms we should do the following make a new transition containing a proposed sample calculate the acceptance probability if we accept return the new transition otherwise return the old one stepsthe step function is the function that performs the bulk of your inference in our case we will implement two step functions one for the very first iteration and one for every subsequent iteration define the first step function which is called at the beginning of sampling return the initial parameter used to define the sampler function abstractmcmc step rng abstractrng model densitymodel spl metropolishastings n integer nothing kwargs return transition model spl init endthe first step function just packages up the initial parameterization inside the sampler and returns it we implicitly accept the very first parameterization the other step function performs the usual steps from metropolis hastings included are several helper functions proposal and q which are designed to replicate the functions in the pseudocode above proposal generates a new proposal in the form of a transition which can be univariate if the value passed in is univariate or it can be multivariate if the transition given is multivariate proposals use a basic normal or mvnormal proposal distribution q returns the log density of one parameterization conditional on another according to the proposal distribution step generates a new proposal checks the acceptance probability and then returns either the previous transition or the proposed transition define a function that makes a basic proposal depending on a univariate parameterization or a multivariate parameterization propose spl metropolishastings model densitymodel real transition model rand spl proposal propose spl metropolishastings model densitymodel vector lt real transition model rand spl proposal propose spl metropolishastings model densitymodel t transition propose spl model t calculates the probability q cond using the proposal distribution spl proposal q spl metropolishastings real cond real logpdf spl proposal cond q spl metropolishastings vector lt real cond vector lt real logpdf spl proposal cond q spl metropolishastings t1 transition t2 transition q spl t1 t2 calculate the density of the model given some parameterization model densitymodel model model densitymodel t transition t lp define the other step function returns a transition containing either a new proposal if accepted or the previous proposal if not accepted function abstractmcmc step rng abstractrng model densitymodel spl metropolishastings integer prev transition kwargs generate a new proposal propose spl model prev calculate the log acceptance probability model model prev q spl prev q spl prev decide whether to return the previous or the new one if log rand rng lt min 0 0 return else return prev endendchainsin the default implementation sample just returns a vector of all transitions if instead you would like to obtain a chains object e g to simplify downstream analysis you have to implement the bundle samples function as well it accepts the vector of transitions and returns a collection of samples fortunately our transition is incredibly simple and we only need to build a little bit of functionality to accept custom parameter names passed in by the user a basic chains constructor that works with the transition struct we defined function abstractmcmc bundle samples rng abstractrng densitymodel s metropolishastings n integer ts vector lt transition chain type type any param names missing kwargs turn all the transitions into a vector of vectors vals copy reduce hcat vcat t t lp for t in ts check if we received any parameter names if ismissing param names param names parameter i for i in 1 length first vals 1 end add the log density field to the parameter names push param names lp bundle everything up and return a chains struct return chains vals param names internals lp endall done you can even implement different output formats by implementing bundle samples for different chain types which can be provided as keyword argument to sample as default sample uses chain type any testing the implementationnow that we have all the pieces we should test the implementation by defining a model to calculate the mean and variance parameters of a normal distribution we can do this by constructing a target density function providing a sample of data and then running the sampler with sample generate a set of data from the posterior we want to estimate data rand normal 5 3 30 define the components of a basic model insupport 2 gt 0dist normal 1 2 density insupport sum logpdf dist data inf construct a densitymodel model densitymodel density set up our sampler with initial parameters spl metropolishastings 0 0 0 0 sample from the posterior chain sample model spl 100000 param names if all the interface functions have been extended properly you should get an output from display chain that looks something like this object of type chains with data of type 100000 3 1 array float64 3 iterations 1 100000thinning interval 1chains 1samples per chain 100000internals lpparameters 2 element array chaindataframe 1 summary statistics row parameters mean std naive se mcse ess r hat symbol float64 float64 float64 float64 any any 1 5 33157 0 854193 0 0027012 0 00893069 8344 75 1 00009 2 4 54992 0 632916 0 00200146 0 00534942 14260 8 1 00005 quantiles row parameters 2 5 25 0 50 0 75 0 97 5 symbol float64 float64 float64 float64 float64 1 3 6595 4 77754 5 33182 5 89509 6 99651 2 3 5097 4 09732 4 47805 4 93094 5 96821 it looks like we re extremely close to our true parameters of normal 5 3 though with a fairly high variance due to the low sample size conclusionwe ve seen how to implement the sampling interface for general projects turing s interface methods are ever evolving so please open an issue at abstractmcmc with feature requests or problems", "title": "Interface Guide"},{"location": "/docs/for-developers/variational_inference", "text": "overviewin this post we ll have a look at what s known as variational inference vi a family of approximate bayesian inference methods in particular we will focus on one of the more standard vi methods called automatic differentiation variational inference advi here we ll have a look at the theory behind vi but if you re interested in how to use advi in turing jl check out this tutorial motivationin bayesian inference one usually specifies a model as follows given data x i i 1 n begin align text prior quad z amp sim p z text likelihood quad x i amp overset text i i d sim p x mid z quad text where quad i 1 dots n end align where overset text i i d sim denotes that the samples are identically independently distributed our goal in bayesian inference is then to find the posterior p z mid x i i 1 n prod i 1 n p z mid x i in general one cannot obtain a closed form expression for p z mid x i i 1 n but one might still be able to sample from p z mid x i i 1 n with guarantees of converging to the target posterior p z mid x i i 1 n as the number of samples go to infty e g mcmc as you are hopefully already aware turing jl provides a lot of different methods with asymptotic exactness guarantees that we can apply to such a problem unfortunately these unbiased samplers can be prohibitively expensive to run as the model p increases in complexity the convergence of these unbiased samplers can slow down dramatically still in the infinite limit these methods should converge to the true posterior but infinity is fairly large like at least more than 12 so this might take a while in such a case it might be desirable to sacrifice some of these asymptotic guarantees and instead approximate the posterior p z mid x i i 1 n using some other model which we ll denote q z there are multiple approaches to take in this case one of which is variational inference vi variational inference vi in vi we re looking to approximate p z mid x i i 1 n using some approximate or variational posterior q z to approximate something you need a notion of what quot close quot means in the context of probability densities a standard such quot measure quot of closeness is the kullback leibler kl divergence though this is far from the only one the kl divergence is defined between two densities q z and p z mid x i i 1 n as begin align mathrm d kl left q z p z mid x i i 1 n right amp int log left frac q z prod i 1 n p z mid x i right q z mathrm d z amp mathbb e z sim q z left log q z sum i 1 n log p z mid x i right amp mathbb e z sim q z left log q z right sum i 1 n mathbb e z sim q z left log p z mid x i right end align it s worth noting that unfortunately the kl divergence is not a metric distance in the analysis sense due to its lack of symmetry on the other hand it turns out that minimizing the kl divergence that it s actually equivalent to maximizing the log likelihood also under reasonable restrictions on the densities at hand mathrm d kl left q z p z mid x i i 1 n right 0 quad iff quad q z p z mid x i i 1 n quad forall z therefore one could and we will attempt to approximate p z mid x i i 1 n using a density q z by minimizing the kl divergence between these two one can also show that mathrm d kl ge 0 which we ll need later finally notice that the kl divergence is only well defined when in fact q z is zero everywhere p z mid x i i 1 n is zero i e mathrm supp left q z right subseteq mathrm supp left p z mid x right otherwise there might be a point z 0 sim q z such that p z 0 mid x i i 1 n 0 resulting in log left frac q z 0 right which doesn t make sense one major problem as we can see in the definition of the kl divergence we need p z mid x i i 1 n for any z if we want to compute the kl divergence between this and q z we don t have that the entire reason we even do bayesian inference is that we don t know the posterior cleary this isn t going to work or is it computing kl divergence without knowing the posteriorfirst off recall that p z mid x i frac p x i z p x i so we can write begin align mathrm d kl left q z p z mid x i i 1 n right amp mathbb e z sim q z left log q z right sum i 1 n mathbb e z sim q z left log p x i z log p x i right amp mathbb e z sim q z left log q z right sum i 1 n mathbb e z sim q z left log p x i z right sum i 1 n mathbb e z sim q z left log p x i right amp mathbb e z sim q z left log q z right sum i 1 n mathbb e z sim q z left log p x i z right sum i 1 n log p x i end align where in the last equality we used the fact that p x i is independent of z now you re probably thinking quot oh great now you ve introduced p x i which we also can t compute in general quot woah calm down human let s do some more algebra the above expression can be rearranged to mathrm d kl left q z p z mid x i i 1 n right underbrace sum i 1 n mathbb e z sim q z left log p x i z right mathbb e z sim q z left log q z right mathrm elbo q underbrace sum i 1 n mathbb e z sim q z left log p x i right text constant see the left hand side is constant and as we mentioned before mathrm d kl ge 0 what happens if we try to maximize the term we just gave the completely arbitrary name mathrm elbo well if mathrm elbo goes up while p x i stays constant then mathrm d kl has to go down that is the q z which minimizes the kl divergence is the same q z which maximizes mathrm elbo q underset q mathrm argmin mathrm d kl left q z p z mid x i i 1 n right underset q mathrm argmax mathrm elbo q where begin align mathrm elbo q amp left sum i 1 n mathbb e z sim q z left log p x i z right right mathbb e z sim q z left log q z right amp left sum i 1 n mathbb e z sim q z left log p x i z right right mathbb h left q z right end align and mathbb h left q z right denotes the differential entropy of q z assuming joint p x i z and the entropy mathbb h left q z right are both tractable we can use a monte carlo for the remaining expectation this leaves us with the following tractable expression underset q mathrm argmin mathrm d kl left q z p z mid x i i 1 n right approx underset q mathrm argmax widehat mathrm elbo q where widehat mathrm elbo q frac 1 m left sum k 1 m sum i 1 n log p x i z k right mathbb h left q z right quad text where quad z k sim q z quad forall k 1 dots m hence as long as we can sample from q z somewhat efficiently we can indeed minimize the kl divergence neat eh sidenote in the case where q z is tractable but mathbb h left q z right is not we can use an monte carlo estimate for this term too but this generally results in a higher variance estimate also i fooled you real good the elbo isn t an arbitrary name hah in fact it s an abbreviation for the expected lower bound elbo because it uhmm well it s the expected lower bound remember mathrm d kl ge 0 yup maximizing the elbofinding the optimal q over all possible densities of course isn t feasible instead we consider a family of parameterized densities mathscr d theta where theta denotes the space of possible parameters each density in this family q theta in mathscr d theta is parameterized by a unique theta in theta moreover we ll assume q theta z i e evaluating the probability density q at any point z is differentiable z sim q theta z i e the process of sampling from q theta z is differentiable 1 is fairly straight forward but 2 is a bit tricky what does it even mean for a sampling process to be differentiable this is quite an interesting problem in its own right and would require something like a 50 page paper to properly review the different approaches highly recommended read we re going to make use of a particular such approach which goes under a bunch of different names reparametrization trick path derivative etc this refers to making the assumption that all elements q theta in mathscr q theta can be considered as reparameterizations of some base density say bar q z that is if q theta in mathscr q theta then z sim q theta z quad iff quad z g theta tilde z quad text where quad bar z sim bar q z for some function g theta differentiable wrt theta so all q theta in mathscr q theta are using the same reparameterization function g but each q theta correspond to different choices of theta for f theta under this assumption we can differentiate the sampling process by taking the derivative of g theta wrt theta and thus we can differentiate the entire widehat mathrm elbo q theta wrt theta with the gradient available we can either try to solve for optimality either by setting the gradient equal to zero or maximize widehat mathrm elbo q theta stepwise by traversing mathscr q theta in the direction of steepest ascent for the sake of generality we re going to go with the stepwise approach with all this nailed down we eventually reach the section on automatic differentiation variational inference advi automatic differentiation variational inference advi so let s revisit the assumptions we ve made at this point the variational posterior q theta is in a parameterized family of densities denoted mathscr q theta with theta in theta mathscr q theta is a space of reparameterizable densities with bar q z as the base density the parameterization function g theta is differentiable wrt theta evaluation of the probability density q theta z is differentiable wrt theta mathbb h left q theta z right is tractable evaluation of the joint density p x z is tractable and differentiable wrt z the support of q z is a subspace of the support of p z mid x mathrm supp left q z right subseteq mathrm supp left p z mid x right all of these are not necessary to do vi but they are very convenient and results in a fairly flexible approach one distribution which has a density satisfying all of the above assumptions except 7 we ll get back to this in second for any tractable and differentiable p z mid x i i 1 n is the good ole gaussian normal distribution z sim mathcal n mu sigma quad iff quad z g mu l bar z mu l t tilde z quad text where quad bar z sim bar q z mathcal n 1 d i d times d where sigma l l t with l obtained from the cholesky decomposition abusing notation a bit we re going to write theta mu sigma mu 1 dots mu d l 11 dots l 1 d l 2 1 dots l 2 d dots l d 1 dots l d d with this assumption we finally have a tractable expression for widehat mathrm elbo q mu sigma well assuming 7 is holds since a gaussian has non zero probability on the entirety of mathbb r d we also require p z mid x i i 1 n to have non zero probability on all of mathbb r d though not necessary we ll often make a mean field assumption for the variational posterior q z i e assume independence between the latent variables in this case we ll write theta mu sigma 2 mu 1 dots mu d sigma 1 2 dots sigma d 2 examplesas a trivial example we could apply the approach described above to is the following generative model for p z mid x i i 1 n begin align m amp sim mathcal n 0 1 x i amp overset text i i d mathcal n m 1 quad i 1 dots n end align in this case z m and we have the posterior defined p m mid x i i 1 n p m prod i 1 n p x i mid m then the variational posterior would be q mu sigma mathcal n mu sigma 2 quad text where quad mu in mathbb r sigma 2 in mathbb r and since prior of m mathcal n 0 1 has non zero probability on the entirety of mathbb r same as q m i e assumption 7 above holds everything is fine and life is good but what about this generative model for p z mid x i i 1 n begin align s amp sim mathrm inversegamma 2 3 m amp sim mathcal n 0 s x i amp overset text i i d mathcal n m s quad i 1 dots n end align with posterior p s m mid x i i 1 n p s p m mid s prod i 1 n p x i mid s m and the mean field variational posterior q s m will be q mu 1 mu 2 sigma 1 2 sigma 2 2 s m p mathcal n mu 1 sigma 1 2 s p mathcal n mu 2 sigma 2 2 m where we ve denoted the evaluation of the probability density of a gaussian as p mathcal n mu sigma 2 x observe that mathrm inversegamma 2 3 has non zero probability only on mathbb r 0 infty which is clearly not all of mathbb r like q s m has i e mathrm supp left q s m right not subseteq mathrm supp left p z mid x i i 1 n right recall from the definition of the kl divergence that when this is the case the kl divergence isn t well defined this gets us to the automatic part of advi quot automatic quot how for a lot of the standard continuous densities p we can actually construct a probability density tilde p with non zero probability on all of mathbb r by transforming the quot constrained quot probability density p to tilde p in fact in these cases this is a one to one relationship as we ll see this helps solve the support issue we ve been going on and on about transforming densities using change of variablesif we want to compute the probability of x taking a value in some set a subseteq mathrm supp left p x right we have to integrate p x over a i e mathbb p p x in a int a p x mathrm d x this means that if we have a differentiable bijection f mathrm supp left q x right to mathbb r d with differentiable inverse f 1 mathbb r d to mathrm supp left p x right we can perform a change of variables mathbb p p x in a int f 1 a p left f 1 y right left det mathcal j f 1 y right mathrm d y where mathcal j f 1 x denotes the jacobian of f 1 evaluted at x observe that this defines a probability distribution mathbb p tilde p left y in f 1 a right int f 1 a tilde p y mathrm d y since f 1 left mathrm supp p x right mathbb r d which has probability 1 this probability distribution has density tilde p y with mathrm supp left tilde p y right mathbb r d defined tilde p y p left f 1 y right left det mathcal j f 1 y right or equivalently tilde p left f x right frac p x big det mathcal j f x big due to the fact that big det mathcal j f 1 y big big det mathcal j f x big 1 note it s also necessary that the log abs det jacobian term is non vanishing this can for example be accomplished by assuming f to also be elementwise monotonic back to viso why is this is useful well we re looking to generalize our approach using a normal distribution to cases where the supports don t match up how about defining q z by begin align eta amp sim mathcal n mu sigma z amp f 1 eta end align where f 1 mathbb r d to mathrm supp left p z mid x right is a differentiable bijection with differentiable inverse then z sim q mu sigma z implies z in mathrm supp left p z mid x right as we wanted the resulting variational density is q mu sigma z p mathcal n mu sigma left f z right big det mathcal j f z big note that the way we ve constructed q z here is basically a reverse of the approach we described above here we sample from a distribution with support on mathbb r and transform to mathrm supp left p z mid x right if we want to write the elbo explicitly in terms of eta rather than z the first term in the elbo becomes begin align mathbb e z sim q mu sigma z left log p x i z right amp mathbb e eta sim mathcal n mu sigma bigg log frac p left x i f 1 eta right big det mathcal j f 1 eta big bigg amp mathbb e eta sim mathcal n mu sigma left log p left x i f 1 eta right right mathbb e eta sim mathcal n mu sigma left left det mathcal j f 1 eta right right end align the entropy is invariant under change of variables thus mathbb h left q mu sigma z right is simply the entropy of the normal distribution which is known analytically hence the resulting empirical estimate of the elbo is begin align widehat mathrm elbo q mu sigma amp frac 1 m left sum k 1 m sum i 1 n left log p left x i f 1 eta k right log big det mathcal j f 1 eta k big right right mathbb h left p mathcal n mu sigma z right amp text where quad z k sim mathcal n mu sigma quad forall k 1 dots m end align and maximizing this wrt mu and sigma is what s referred to as automatic differentiation variational inference advi now if you want to try it out check out the tutorial on how to use advi in turing jl", "title": "Variational Inference"},{"location": "/docs/library/advancedhmc/", "text": "indexadvancedhmc abstractintegratoradvancedhmc abstracttrajectorysampleradvancedhmc binarytreeadvancedhmc classicnouturnadvancedhmc endpointtsadvancedhmc fixedintegrationtimeadvancedhmc fixednstepsadvancedhmc fullmomentumrefreshmentadvancedhmc generalisednouturnadvancedhmc hmcprogresscallbackadvancedhmc hmcsampleradvancedhmc hmcstateadvancedhmc jitteredleapfrogadvancedhmc leapfrogadvancedhmc multinomialts advancedhmc multinomialts v0 24 docs library advancedhmc advancedhmc multinomialts tuple random abstractrng advancedhmc phasepoint advancedhmc multinomialts v0 24 docs library advancedhmc advancedhmc multinomialts tuple multinomialts abstractfloat advancedhmc phasepoint advancedhmc nuts v0 24 docs library advancedhmc advancedhmc nuts union tuple tc tuple ts tuple advancedhmc abstractintegrator vararg any n where n where ts tc advancedhmc partialmomentumrefreshment advancedhmc slicets v0 24 docs library advancedhmc advancedhmc slicets tuple random abstractrng advancedhmc phasepoint advancedhmc slicets advancedhmc slicets v0 24 docs library advancedhmc advancedhmc slicets tuple slicets abstractfloat advancedhmc phasepoint advancedhmc strictgeneralisednouturnadvancedhmc temperedleapfrog advancedhmc termination v0 24 docs library advancedhmc advancedhmc termination union tuple f tuple multinomialts trajectory f f where f lt abstractfloat advancedhmc termination v0 24 docs library advancedhmc advancedhmc termination union tuple f tuple slicets trajectory f f where f lt abstractfloat advancedhmc terminationadvancedhmc trajectoryadvancedhmc transition advancedhmc a v0 24 docs library advancedhmc advancedhmc a tuple any any any advancedhmc build tree v0 24 docs library advancedhmc advancedhmc build tree union tuple tc tuple i tuple ts tuple random abstractrng trajectory ts i tc hamiltonian advancedhmc phasepoint advancedhmc abstracttrajectorysampler int64 int64 abstractfloat where ts lt advancedhmc abstracttrajectorysampler i lt advancedhmc abstractintegrator tc lt advancedhmc dynamicterminationcriterion advancedhmc check left subtree v0 24 docs library advancedhmc advancedhmc check left subtree union tuple t tuple hamiltonian t t t where t lt advancedhmc binarytree advancedhmc check right subtree v0 24 docs library advancedhmc advancedhmc check right subtree union tuple t tuple hamiltonian t t t where t lt advancedhmc binarytree advancedhmc combine v0 24 docs library advancedhmc advancedhmc combine tuple advancedhmc binarytree advancedhmc binarytree advancedhmc find good stepsize v0 24 docs library advancedhmc advancedhmc find good stepsize union tuple t tuple random abstractrng hamiltonian abstractvector t where t lt real advancedhmc isterminated v0 24 docs library advancedhmc advancedhmc isterminated tuple classicnouturn hamiltonian advancedhmc binarytree advancedhmc isterminated v0 24 docs library advancedhmc advancedhmc isterminated tuple strictgeneralisednouturn hamiltonian any any any advancedhmc isterminated v0 24 docs library advancedhmc advancedhmc isterminated tuple generalisednouturn hamiltonian advancedhmc binarytree advancedhmc maxabs v0 24 docs library advancedhmc advancedhmc maxabs tuple any any advancedhmc mh accept ratio v0 24 docs library advancedhmc advancedhmc mh accept ratio union tuple t tuple random abstractrng t t where t lt abstractfloat advancedhmc nom step size advancedhmc pm next v0 24 docs library advancedhmc advancedhmc pm next tuple any namedtuple advancedhmc randcat v0 24 docs library advancedhmc advancedhmc randcat union tuple t tuple union random abstractrng abstractvector var quot s9 quot where var quot s9 quot lt random abstractrng abstractmatrix t where t advancedhmc simple pm next v0 24 docs library advancedhmc advancedhmc simple pm next tuple any namedtuple advancedhmc statadvancedhmc step size advancedhmc temper v0 24 docs library advancedhmc advancedhmc temper tuple temperedleapfrog any namedtuple i is half var quot s17 quot where var quot s17 quot lt tuple integer bool int64 advancedhmc transition v0 24 docs library advancedhmc advancedhmc transition tuple trajectory hamiltonian advancedhmc phasepoint advancedhmc update nom step sizefunctions advancedhmc a method a single hamiltonian integration step note this function is intended to be used in find good stepsize only advancedhmc build tree method recursivly build a tree for a given depth j advancedhmc check left subtree method check left subtree h t tleft tright do a u turn check between the leftmost phase point of t and the leftmost phase point of tright the right subtree advancedhmc check right subtree method check right subtree h t tleft tright do a u turn check between the rightmost phase point of t and the rightmost phase point of tleft the left subtree advancedhmc combine method combine treeleft treeright merge a left tree treeleft and a right tree treeright under given hamiltonian h then draw a new candidate sample and update related statistics for the resulting tree advancedhmc find good stepsize method find a good initial leap frog step size via heuristic search advancedhmc isterminated method isterminated h t detect u turn for two phase points zleft and zright under given hamiltonian h using the original no u turn cirterion ref https arxiv org abs 1111 4246 https arxiv org abs 1701 02434 advancedhmc isterminated method isterminated h t detect u turn for two phase points zleft and zright under given hamiltonian h using the generalised no u turn criterion ref https arxiv org abs 1701 02434 advancedhmc isterminated method isterminated tc h t tleft tright detect u turn for two phase points zleft and zright under given hamiltonian h using the generalised no u turn criterion with additional u turn checks ref https arxiv org abs 1701 02434 https github com stan dev stan pull 2800 advancedhmc maxabs method maxabs a b return the value with the largest absolute value advancedhmc mh accept ratio method perform mh acceptance based on energy i e negative log probability advancedhmc nom step size method nom step size abstractintegrator get the nominal integration step size the current integration step size may differ from this for example if the step size is jittered nominal step size is usually used in adaptation advancedhmc pm next method progress meter update with all trajectory stats iteration number and metric shown advancedhmc randcat method randcat rng p abstractmatrix generating categorical random variables in a vectorized mode p is supposed to be a matrix of d n where each column is a probability vector examplep 0 5 0 3 0 4 0 6 0 1 0 1 u 0 3 0 4 c 0 5 0 3 0 9 0 9 1 0 1 0 then c lt u is 0 1 0 0 0 0 thus convert int vec sum c lt u dims 1 1 equals 1 2 advancedhmc simple pm next method simple progress meter update without any show values advancedhmc stat method returns the statistics for transition t advancedhmc step size function step size abstractintegrator get the current integration step size advancedhmc temper method temper lf temperedleapfrog r step namedtuple i is half lt tuple integer bool n steps int tempering step step is a named tuple withi being the current leapfrog iteration andis half indicating whether or not it s the first half momentum tempering step advancedhmc transition method transition h z make a mcmc transition from phase point z using the trajectory under hamiltonian h note this is a rng implicit fallback function for transition global rng h z advancedhmc update nom step size function update nom step size i abstractintegrator gt abstractintegratorreturn a copy of the integrator i with the new nominal step size nom step size statsbase sample method sample model abstractmcmc logdensitymodel kernel advancedhmc abstractmcmckernel metric advancedhmc abstractmetric adaptor advancedhmc adaptation abstractadaptor n integer kwargs gt anya convenient wrapper around abstractmcmc sample avoiding explicit construction of hmcsampler statsbase sample method sample rng abstractrng h hamiltonian abstractmcmckernel abstractvecormat t n samples int adaptor abstractadaptor noadaptation n adapts int min div n samples 10 1 000 drop warmup bool false verbose bool true progress bool false sample n samples samples using the proposal under hamiltonian h the randomness is controlled by rng if rng is not provided global rng will be used the initial point is given by the adaptor is set by adaptor for which the default is no adaptation it will perform n adapts steps of adaptation for which the default is the minimum of 1 000 and 10 of n samplesdrop warmup controls to drop the samples during adaptation phase or notverbose controls the verbosityprogress controls whether to show the progress meter or nottypes advancedhmc abstractintegrator type abstract type abstractintegratorrepresents an integrator used to simulate the hamiltonian system implementationa abstractintegrator is expected to have the following implementations stat ref nom step size ref step size ref advancedhmc abstracttrajectorysampler type how to sample a phase point from the simulated trajectory advancedhmc binarytree type a full binary tree trajectory with only necessary leaves and information stored advancedhmc classicnouturn type struct classicnouturn f lt abstractfloat lt advancedhmc dynamicterminationcriterionclassic no u turn criterion as described in eq 9 in 1 informally this will terminate the trajectory expansion if continuing the simulation either forwards or backwards in time will decrease the distance between the left most and right most positions fieldsmax depth int64 max abstractfloatreferenceshoffman m d amp gelman a 2014 the no u turn sampler adaptively setting path lengths in hamiltonian monte carlo journal of machine learning research 15 1 1593 1623 arxiv advancedhmc endpointts type samples the end point of the trajectory advancedhmc fixedintegrationtime type struct fixedintegrationtime f lt abstractfloat lt advancedhmc staticterminationcriterionstandard hmc implementation with a fixed integration time fields abstractfloat total length of the trajectory i e take floor integrator step size number of leapfrog steps referencesneal r m 2011 mcmc using hamiltonian dynamics handbook of markov chain monte carlo 2 11 2 arxiv advancedhmc fixednsteps type struct fixednsteps lt advancedhmc staticterminationcriterionstatic hmc with a fixed number of leapfrog steps fieldsl int64 number of steps to simulate i e length of trajectory will be l 1 referencesneal r m 2011 mcmc using hamiltonian dynamics handbook of markov chain monte carlo 2 11 2 arxiv advancedhmc fullmomentumrefreshment type completly resample new momentum advancedhmc generalisednouturn type struct generalisednouturn f lt abstractfloat lt advancedhmc dynamicterminationcriteriongeneralised no u turn criterion as described in section a 4 2 in 1 fieldsmax depth int64 max abstractfloatreferencesbetancourt m 2017 a conceptual introduction to hamiltonian monte carlo arxiv preprint arxiv 1701 02434 advancedhmc hmcprogresscallback type hmcprogresscallbacka callback to be used with abstractmcmc jl s interface replicating the logging behavior of the non abstractmcmc sample v0 24 docs library advancedhmc statsbase sample tuple abstractmcmc logdensitymodel advancedhmc abstractmcmckernel advancedhmc abstractmetric advancedhmc adaptation abstractadaptor integer fieldspm progress meter from progressmeters jl progress specifies whether or not to use display a progress bar verbose if progress is not specified and this is true some information will be logged upon completion of adaptation num divergent transitions number of divergent transitions fo far num divergent transitions during adaption advancedhmc hmcsampler type hmcsamplera abstractmcmc abstractsampler for kernels in advancedhmc jl fieldsinitial kernel initial abstractmcmckernel initial metric initial abstractmetric initial adaptor initial abstractadaptor notesnote that all the fields have the prefix initial to indicate that these will not necessarily correspond to the kernel metric and adaptor after sampling to access the updated fields use the resulting hmcstate advancedhmc hmcstate type hmcstaterepresents the state of a hmcsampler fieldsi index of current iteration transition current transition metric current abstractmetric possibly adapted current abstractmcmckernel adaptor current abstractadaptor advancedhmc jitteredleapfrog type struct jitteredleapfrog ft lt abstractfloat t lt union abstractarray ft lt abstractfloat 1 ft lt abstractfloat lt advancedhmc abstractleapfrog t lt union abstractarray ft lt abstractfloat 1 ft lt abstractfloat leapfrog integrator with randomly quot jittered quot step size for every trajectory fields 0 union abstractvector ft ft where ft lt abstractfloat nominal non jittered step size jitter abstractfloat the proportion of the nominal step size 0 that may be added or subtracted union abstractvector ft ft where ft lt abstractfloat current jittered step size descriptionthis is the same as leapfrog ref but with a quot jittered quot step size this means that at the beginning of each trajectory we sample a step size by adding or subtracting from the nominal base step size 0 some random proportion of 0 with the proportion specified by jitter i e 0 jitter 0 rand p jittering might help alleviate issues related to poor interactions with a fixed step size in regions with high quot curvature quot the current choice of step size might mean over shoot leading to almost all steps being rejected randomly sampling the step size at the beginning of the trajectories can therefore increase the probability of escaping such high curvature regions exact periodicity of the simulated trajectories might occur i e you might be so unlucky as to simulate the trajectory forwards in time l and ending up at the same point which results in non ergodicity see section 3 2 in 1 if momentum is refreshed before each trajectory then this should not happen exactly but it can still be an issue in practice randomly choosing the step size might help alleviate such problems referencesneal r m 2011 mcmc using hamiltonian dynamics handbook of markov chain monte carlo 2 11 2 arxiv advancedhmc leapfrog type struct leapfrog t lt union abstractvector var s29 var s29 where var s29 lt abstractfloat lt advancedhmc abstractleapfrog t lt union abstractvector var s29 var s29 where var s29 lt abstractfloat leapfrog integrator with fixed step size fields union abstractvector var quot s29 quot var quot s29 quot where var quot s29 quot lt abstractfloat step size advancedhmc multinomialts type struct multinomialts f lt abstractfloat lt advancedhmc abstracttrajectorysamplermultinomial trajectory sampler carried during the building of the tree it contains the weight of the tree defined as the total probabilities of the leaves fieldszcand advancedhmc phasepoint sampled candidate phasepoint w abstractfloat total energy for the given tree i e the sum of energies of all leaves advancedhmc multinomialts method struct multinomialts f lt abstractfloat lt advancedhmc abstracttrajectorysamplermultinomial sampler for a trajectory consisting only a leaf node tree weight is the unnormalised energy of the leaf advancedhmc multinomialts method struct multinomialts f lt abstractfloat lt advancedhmc abstracttrajectorysamplermultinomial sampler for the starting single leaf tree log weights for leaf nodes are their unnormalised hamiltonian energies ref https github com stan dev stan blob develop src stan mcmc hmc nuts base nuts hpp l226 advancedhmc nuts method nuts int args kwargs convenient constructor for the no u turn sampler nuts this falls back to hmckernel trajectory ts int tc args kwargs wherets lt union multinomialts slicets is the type for trajectory samplertc lt union classicnouturn generalisednouturn strictgeneralisednouturn is the type for termination criterion see classicnouturn generalisednouturn and strictgeneralisednouturn for details in parameters advancedhmc partialmomentumrefreshment type struct partialmomentumrefreshment f lt abstractfloat lt advancedhmc abstractmomentumrefreshmentpartial momentum refreshment with refresh rate fields abstractfloatsee equation 5 19 1 r r sqrt 1 gwhere r is the momentum and g is a gaussian random variable referencesneal radford m quot mcmc using hamiltonian dynamics quot handbook of markov chain monte carlo 2 11 2011 2 advancedhmc slicets type struct slicets f lt abstractfloat lt advancedhmc abstracttrajectorysamplertrajectory slice sampler carried during the building of the tree it contains the slice variable and the number of acceptable condidates in the tree fieldszcand advancedhmc phasepoint sampled candidate phasepoint u abstractfloat slice variable in log space n int64 number of acceptable candidates i e those with probability larger than slice variable u advancedhmc slicets method struct slicets f lt abstractfloat lt advancedhmc abstracttrajectorysamplerslice sampler for the starting single leaf tree slice variable is initialized advancedhmc slicets method struct slicets f lt abstractfloat lt advancedhmc abstracttrajectorysamplercreate a slice sampler for a single leaf tree the slice variable is copied from the passed in sampler s andthe number of acceptable candicates is computed by comparing the slice variable against the current energy advancedhmc strictgeneralisednouturn type struct strictgeneralisednouturn f lt abstractfloat lt advancedhmc dynamicterminationcriteriongeneralised no u turn criterion as described in section a 4 2 in 1 with added u turn check as described in 2 fieldsmax depth int64 max abstractfloatreferencesbetancourt m 2017 a conceptual introduction to hamiltonian monte carlo arxiv preprint arxiv 1701 02434 https github com stan dev stan pull 2800 advancedhmc temperedleapfrog type struct temperedleapfrog ft lt abstractfloat t lt union abstractarray ft lt abstractfloat 1 ft lt abstractfloat lt advancedhmc abstractleapfrog t lt union abstractarray ft lt abstractfloat 1 ft lt abstractfloat tempered leapfrog integrator with fixed step size and quot temperature quot fields union abstractvector ft ft where ft lt abstractfloat step size abstractfloat temperature parameter descriptiontempering can potentially allow greater exploration of the posterior e g in a multi modal posterior jumps between the modes can be more likely to occur advancedhmc termination type terminationtermination reasonsdynamic due to stoping criterianumerical due to large energy deviation from starting possibly numerical errors advancedhmc termination method termination s nt h0 h check termination of a hamiltonian trajectory advancedhmc termination method termination s nt h0 h check termination of a hamiltonian trajectory advancedhmc trajectory type struct trajectory ts lt advancedhmc abstracttrajectorysampler i lt advancedhmc abstractintegrator tc lt advancedhmc abstractterminationcriterion numerically simulated hamiltonian trajectories advancedhmc transition type struct transition p lt advancedhmc phasepoint nt lt namedtuple a transition that contains the phase point and other statistics of the transition fieldsz advancedhmc phasepoint phase point for the transition stat namedtuple statistics related to the transition e g energy", "title": "AdvancedHMC"},{"location": "/docs/library/", "text": "indexturing binomiallogitturing flatturing flatposturing orderedlogisticturing inference gibbsturing inference hmcturing inference hmcdaturing inference isturing inference mhturing inference nutsturing inference pgturing inference smcmodelling dynamicppl model macro model expr warn false macro to specify a probabilistic model if warn is true a warning is displayed if internal variable names are used in the model definition examplesmodel definition model function model x y 42 endto generate a model call model xvalue or model xvalue yvalue samplers dynamicppl sampler type sampler t generic sampler type for inference algorithms of type t in dynamicppl sampler should implement the abstractmcmc interface and in particular abstractmcmc step a default implementation of the initial sampling step is provided that supports resuming sampling from a previous state and setting initial parameter values it requires to overload loadstate and initialstep for loading previous states and actually performing the initial sampling step respectively additionally sometimes one might want to implement initialsampler that specifies how the initial parameter values are sampled if they are not provided by default values are sampled from the prior turing inference gibbs type gibbs algs compositional mcmc interface gibbs sampling combines one or more sampling algorithms each of which samples from a different set of variables in a model example model function gibbs example x v1 normal 0 1 v2 categorical 5 end use pg for a v2 variable and use hmc for the v1 variable note that v2 is discrete so the pg sampler is more appropriate than is hmc alg gibbs hmc 0 2 3 v1 pg 20 v2 tips hmc and nuts are fast samplers and can throw off particle basedmethods like particle gibbs you can increase the effectiveness of particle sampling by including more particles in the particle sampler source turing inference hmc type hmc float64 n leapfrog int hamiltonian monte carlo sampler with static trajectory arguments float64 the leapfrog step size to use n leapfrog int the number of leapfrog steps to use usage hmc 0 05 10 tips if you are receiving gradient errors when using hmc try reducing the leapfrog step size e g original step sizesample gdemo 1 5 2 hmc 0 1 10 1000 reduced step sizesample gdemo 1 5 2 hmc 0 01 10 1000 source turing inference hmcda type hmcda n adapts int float64 float64 float64 0 0 hamiltonian monte carlo sampler with dual averaging algorithm usage hmcda 200 0 65 0 3 arguments n adapts int numbers of samples to use for adaptation float64 target acceptance rate 65 is often recommended float64 target leapfrog length float64 0 0 inital step size 0 means automatically search by turing for more information please view the following paper arxiv link hoffman matthew d and andrew gelman quot the no u turn sampler adaptively setting path lengths in hamiltonian monte carlo quot journal of machine learning research 15 no 1 2014 1593 1623 source turing inference is type is importance sampling algorithm usage is example define a simple normal model with unknown mean and variance model function gdemo x s inversegamma 2 3 m normal 0 sqrt s x 1 normal m sqrt s x 2 normal m sqrt s return s mendsample gdemo 1 5 2 is 1000 source turing inference mh type mh space construct a metropolis hastings algorithm the arguments space can beblank i e mh in which case mh defaults to using the prior for each parameter as the proposal distribution a set of one or more symbols to sample with mh in conjunction with gibbs i e gibbs mh m pg 10 s an iterable of pairs or tuples mapping a symbol to a advancedmh proposal distribution or function that generates returns a conditional proposal distribution a covariance matrix to use as for mean zero multivariate normal proposals examplesthe default mh will use propose samples from the prior distribution using advancedmh staticproposal model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s endchain sample gdemo 1 5 2 0 mh 1 000 mean chain alternatively you can specify particular parameters to sample if you want to combine sampling from multiple samplers model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end samples s with mh and m with pgchain sample gdemo 1 5 2 0 gibbs mh s pg 10 m 1 000 mean chain using custom distributions defaults to using static mh model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end use a static proposal for s and random walk with proposal standard deviation of 0 25 for m chain sample gdemo 1 5 2 0 mh s gt inversegamma 2 3 m gt normal 0 1 1 000 mean chain specifying explicit proposals using the advancedmh interface model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end use a static proposal for s and random walk with proposal standard deviation of 0 25 for m chain sample gdemo 1 5 2 0 mh s gt advancedmh staticproposal inversegamma 2 3 m gt advancedmh randomwalkproposal normal 0 0 25 1 000 mean chain using a custom function to specify a conditional distribution model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end use a static proposal for s and and a conditional proposal for m where the proposal is centered around the current sample chain sample gdemo 1 5 2 0 mh s gt inversegamma 2 3 m gt x gt normal x 1 1 000 mean chain providing a covariance matrix will cause mh to perform random walk sampling in the transformed space with proposals drawn from a multivariate normal distribution the provided matrix must be positive semi definite and square usage model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end providing a custom variance covariance matrixchain sample gdemo 1 5 2 0 mh 0 25 0 05 0 05 0 50 1 000 mean chain source turing inference nuts type nuts n adapts int float64 max depth int 10 max float64 1000 0 init float64 0 0 no u turn sampler nuts sampler usage nuts use default nuts configuration nuts 1000 0 65 use 1000 adaption steps and target accept ratio 0 65 arguments n adapts int the number of samples to use with adaptation float64 target acceptance rate for dual averaging max depth int maximum doubling tree depth max float64 maximum divergence during doubling tree init float64 inital step size 0 means automatically searching using a heuristic procedure source turing inference pg type struct pg space r lt turing inference particleinferenceparticle gibbs sampler fieldsnparticles int64 number of particles resampler any resampling algorithm source turing inference smc type struct smc space r lt turing inference particleinferencesequential monte carlo sampler fieldsresampler anysourcedistributions turing flat type flat the flat distribution is the improper distribution of real numbers that has the improper probability density function f x 1 source turing flatpos type flatpos l real the positive flat distribution with real valued parameter l is the improper distribution of real numbers that has the improper probability density function f x begin cases 0 amp text if x leq l 1 amp text otherwise end cases source turing binomiallogit type binomiallogit n logitp the binomial distribution with logit parameterization characterizes the number of successes in a sequence of independent trials it has two parameters n the number of trials and logitp the logit of the probability of success in an individual trial with the distribution p x k n choose k text logistic logitp k 1 text logistic logitp n k quad text for k 0 1 2 ldots n see also binomialsource warning quot missing docstring quot missing docstring for vecbinomiallogit check documenter s build log for details turing orderedlogistic type orderedlogistic c abstractvector the ordered logistic distribution with real valued parameter and cutpoints c has the probability mass function p x k begin cases 1 text logistic eta c 1 amp text if k 1 text logistic eta c k 1 text logistic eta c k amp text if 1 lt k lt k text logistic eta c k 1 amp text if k k end cases where k length c 1 source", "title": "API"},{"location": "/docs/library/bijectors/", "text": "indexbijectors adbijectorbijectors abstractbijectorbijectors bijectorbijectors composedbijectors corrbijectorbijectors couplingbijectors inversebijectors leakyrelubijectors namedbijectorbijectors namedcompositionbijectors namedcouplingbijectors namedinversebijectors orderedbijector bijectors partitionmask v0 24 docs library bijectors bijectors partitionmask union tuple t tuple int64 any where t bijectors partitionmaskbijectors permutebijectors rationalquadraticsplinebijectors stackedbijectors link chol lkjbijectors bijector bijectors combine v0 24 docs library bijectors bijectors combine tuple bijectors partitionmask any any any bijectors composel v0 24 docs library bijectors bijectors composel union tuple vararg bijector n n1 where n1 tuple n where n bijectors composer v0 24 docs library bijectors bijectors composer union tuple vararg bijector n n1 where n1 tuple n where n bijectors compute r v0 24 docs library bijectors bijectors compute r tuple abstractvector var quot s110 quot where var quot s110 quot lt real any any bijectors couple v0 24 docs library bijectors bijectors couple tuple bijectors coupling abstractvector t where t bijectors coupling bijectors find alpha v0 24 docs library bijectors bijectors find alpha tuple real real real bijectors forward bijectors get u hat v0 24 docs library bijectors bijectors get u hat tuple abstractvector var quot s46 quot where var quot s46 quot lt real abstractvector var quot s45 quot where var quot s45 quot lt real bijectors isclosedform bijectors logabsdetjac v0 24 docs library bijectors bijectors logabsdetjac tuple adbijector real bijectors logabsdetjac v0 24 docs library bijectors bijectors logabsdetjac tuple inverse var quot s27 quot n where var quot s27 quot lt bijector n any bijectors logabsdetjacinv v0 24 docs library bijectors bijectors logabsdetjacinv tuple bijector any bijectors logabsdetjacinv v0 24 docs library bijectors bijectors logabsdetjacinv tuple univariatetransformed var quot s111 quot var quot s110 quot where var quot s111 quot lt distribution var quot s110 quot lt bijector real bijectors logpdf with jac v0 24 docs library bijectors bijectors logpdf with jac tuple univariatetransformed var quot s111 quot var quot s110 quot where var quot s111 quot lt distribution var quot s110 quot lt bijector real bijectors ordered v0 24 docs library bijectors bijectors ordered tuple distribution multivariate continuous bijectors partition v0 24 docs library bijectors bijectors partition tuple bijectors partitionmask any bijectors transformed v0 24 docs library bijectors bijectors transformed tuple distribution bijector functions bijectors link chol lkj method function link chol lkj w link function for cholesky factor an alternative and maybe more efficient implementation was considered for i 2 k j i 1 k z i j w i j w i 1 j z i 1 j sqrt 1 z i 1 j 2 endbut this implementation will not work when w i 1 j 0 though it is a zero measure set unit matrix initialization will not work for equivelence following explanations is given by torfjelde for i j in the loop below we definez w 1 1 z and soz w 1 1 z w 1 z 1 1 z w 1 z w 1 1 z w w 1 z z w w w z 1 z which is the above implementation bijectors bijector method bijector d distribution returns the constrained to unconstrained bijector for distribution d bijectors combine method combine m partitionmask x 1 x 2 x 3 combines x 1 x 2 and x 3 into a single vector bijectors composel method composel ts bijector composed lt tuple constructs composed such that ts are applied left to right bijectors composer method composer ts bijector composed lt tuple constructs composed such that ts are applied right to left bijectors compute r method compute r y minus z0 abstractvector lt real plus hat compute the unique solution r to the equation y minus z0 2 r left 1 frac plus hat r right subject to r 0 and r since gt 0 and plus hat gt 0 the solution is unique and given by r sqrt plus hat 2 4 plus hat 2 where y minus z0 2 for details see appendix a 2 of the reference referencesd rezende s mohamed 2015 variational inference with normalizing flows arxiv 1505 05770 bijectors couple method returns the coupling law constructed from x bijectors coupling method returns the constructor of the coupling law bijectors find alpha method find alpha wt y wt u hat b compute an approximate real valued solution to the equation wt y wt u hat tanh b the uniqueness of the solution is guaranteed since wt u hat 1 for details see appendix a 1 of the reference initial bracketfor all we have wt u hat wt y leq wt u hat tanh b wt y leq wt u hat wt y thus wt u hat wt y leq 0 leq wt u hat wt y which implies wt y wt u hat wt y wt u hat to avoid floating point issues if wt y wt u hat we use the more conservative interval wt y 2 wt u hat wt y 2 wt u hat as initial bracket at the cost of one additional iteration step referencesd rezende s mohamed 2015 variational inference with normalizing flows arxiv 1505 05770 bijectors forward method forward d distribution forward d distribution num samples int returns a namedtuple with fields x y logabsdetjac and logpdf in the case where d isa transformeddistribution this meansx rand d dist y d transform x logabsdetjac is the logabsdetjac of the quot forward quot transform logpdf is the logpdf of y not xin the case where d isa distribution this meansx rand d y xlogabsdetjac 0 0logpdf is logpdf of x bijectors get u hat method get u hat u abstractvector lt real w abstractvector lt real return a tuple of vector u that guarantees invertibility of the planar layer and scalar w u mathematical backgroundaccording to appendix a 1 vector u defined by u w u u log 1 exp w u 1 w u frac w w guarantees that the planar layer f z z u tanh w z b is invertible for all w u and b we can rewrite u as u u log 1 exp w u 1 frac w w additionally we obtain w u w u log 1 exp w u 1 log 1 exp w u 1 referencesd rezende s mohamed 2015 variational inference with normalizing flows arxiv 1505 05770 bijectors isclosedform method isclosedform b bijector boolisclosedform b inverse lt bijector boolreturns true or false depending on whether or not evaluation of b has a closed form implementation most bijectors have closed form evaluations but there are cases where this is not the case for example the inverse evaluation of planarlayer requires an iterative procedure to evaluate bijectors logabsdetjac method computes the absolute determinant of the jacobian of the inverse transformation bijectors logabsdetjac method logabsdetjac b bijector x logabsdetjac ib inverse lt bijector y computes the log abs det j b x where j is the jacobian of the transform similarily for the inverse transform default implementation for inverse lt bijector is implemented as logabsdetjac of original bijector bijectors logabsdetjacinv method logabsdetjacinv b bijector y just an alias for logabsdetjac inverse b y bijectors logabsdetjacinv method logabsdetjacinv td univariatetransformed y real logabsdetjacinv td multivariatetransformed y abstractvector lt real computes the logabsdetjac of the inverse transformation since rand td returns the transformed random variable bijectors logpdf with jac method logpdf with jac td univariatetransformed y real logpdf with jac td mvtransformed y abstractvector lt real logpdf with jac td matrixtransformed y abstractmatrix lt real makes use of the forward method to potentially re use computation and returns a tuple logpdf logabsdetjac bijectors ordered method ordered d distribution return a distribution whose support are ordered vectors i e vectors with increasingly ordered elements bijectors partition method partition m partitionmask x partitions x into 3 disjoint subvectors bijectors transformed method transformed d distribution transformed d distribution b bijector couples distribution d with the bijector b by returning a transformeddistribution if no bijector is provided i e transformed d is called then transformed d bijector d is returned changesofvariables with logabsdet jacobian method with logabsdet jacobian b bijector x computes both transform and logabsdetjac in one forward pass and returns a named tuple b x logabsdetjac b x this defaults to the call above but often one can re use computation in the computation of the forward pass and the computation of the logabsdetjac forward allows the user to take advantange of such efficiencies if they exist types bijectors adbijector type abstract type for a bijector n making use of auto differentation ad to implement jacobian and by impliciation logabsdetjac bijectors abstractbijector type abstract type for a bijector bijectors bijector type abstract type of bijectors with fixed dimensionality bijectors composed type composed ts a b1 bijector n b2 bijector n composed lt tuple composel ts bijector n composed lt tuple composer ts bijector n composed lt tuple where a refers to eithertuple vararg lt bijector n a tuple of bijectors of dimensionality nabstractarray lt bijector n an array of bijectors of dimensionality na bijector representing composition of bijectors composel and composer results in a composed for which application occurs from left to right and right to left respectively note that all the alternative ways of constructing a composed returns a tuple of bijectors this ensures type stability of implementations of all relating methdos e g inverse if you want to use an array as the container instead you can docomposed b1 b2 in general this is not advised since you lose type stability but there might be cases where this is desired e g if you have a insanely large number of bijectors to compose examplessimple examplelet s consider a simple example of exp julia gt using bijectors expjulia gt b exp exp 0 julia gt b bcomposed tuple exp 0 exp 0 0 exp 0 exp 0 julia gt b b 1 0 exp exp 1 0 evaluationtruejulia gt inverse b b exp exp 1 0 1 0 inversiontruejulia gt logabsdetjac b b 1 0 determinant of jacobian3 718281828459045notesorderit s important to note that does what is expected mathematically which means that the bijectors are applied to the input right to left e g first applying b2 and then b1 b1 b2 x b1 b2 x gt truebut in the composed struct itself we store the bijectors left to right so thatcb1 b1 b2 gt composed ts b2 b1 cb2 composel b2 b1 gt composed ts b2 b1 cb1 x cb2 x b1 b2 x gt truestructure will result in quot flatten quot the composition structure while composel and composer preserve the compositional structure this is most easily seen by an example julia gt b exp exp 0 julia gt cb1 b b cb2 b b julia gt cb1 cb2 ts lt different exp 0 exp 0 exp 0 exp 0 julia gt cb1 cb2 ts isa ntuple 4 exp 0 truejulia gt bijectors composer cb1 cb2 ts composed tuple exp 0 exp 0 0 exp 0 exp 0 composed tuple exp 0 exp 0 0 exp 0 exp 0 julia gt bijectors composer cb1 cb2 ts isa tuple composed composed true bijectors corrbijector type corrbijector lt bijector 2 a bijector implementation of stan s parametrization method for correlation matrix https mc stan org docs 2 23 reference manual correlation matrix transform section htmlbasically a unconstrained strictly upper triangular matrix y is transformed to a correlation matrix by following readable but not that efficient form k size y 1 z tanh y for j 1 k i 1 k if i gt j w i j 0 elseif 1 i j w i j 1 elseif 1 lt i j w i j prod sqrt 1 z 1 i 1 j 2 elseif 1 i lt j w i j z i j elseif 1 lt i lt j w i j z i j prod sqrt 1 z 1 i 1 j 2 endendit is easy to see that every column is a unit vector for example w3 w3 w 1 3 2 w 2 3 2 w 3 3 2 z 1 3 2 z 2 3 sqrt 1 z 1 3 2 2 sqrt 1 z 1 3 2 sqrt 1 z 2 3 2 2 z 1 3 2 z 2 3 2 1 z 1 3 2 1 z 1 3 2 1 z 2 3 2 z 1 3 2 z 2 3 2 z 2 3 2 z 1 3 2 1 z 1 3 2 z 2 3 2 z 1 3 2 z 2 3 2 1and diagonal elements are positive so w is a cholesky factor for a positive matrix x w wconsider block matrix representation for xx w1 w2 wn w1 w2 wn w1 w1 w1 w2 w1 wn w2 w1 w2 w2 w2 wn the diagonal elements are given by wk wk 1 thus x is a correlation matrix every step is invertible so this is a bijection bijector note the implementation doesn t follow their quot manageable expression quot directly because their equation seems wrong 7 30 2020 insteadly it follows definition above the quot manageable expression quot directly which is also described in above doc bijectors coupling type coupling f m f mask m implements a coupling layer as defined in 1 examples julia gt m partitionmask 3 1 2 lt going to use x 2 to parameterize transform of x 1 partitionmask sparsearrays sparsematrixcsc float64 int64 1 1 1 0 2 1 1 0 3 1 1 0 julia gt cl coupling gt shift 1 m lt will do y 1 1 x 1 1 x 2 2 julia gt x 1 2 3 julia gt cl x 3 element array float64 1 3 0 2 0 3 0julia gt inverse cl cl x 3 element array float64 1 1 0 2 0 3 0julia gt coupling cl get the bijector map gt b shiftjulia gt couple cl x get the bijector resulting from x shift array float64 1 1 2 0 references 1 kobyzev i prince s amp brubaker m a normalizing flows introduction and ideas corr 2019 bijectors inverse type inverse b bijector inverse b bijector a bijector representing the inverse transform of b bijectors leakyrelu type leakyrelu t n t lt bijector n defines the invertible mappingx x if x 0 else xwhere gt 0 bijectors namedbijector type namedbijector lt abstractnamedbijectorwraps a namedtuple of key gt bijector pairs implementing evaluation inversion etc examples julia gt using bijectors namedbijector scale expjulia gt b namedbijector a scale 2 0 b exp julia gt x a 1 b 0 c 42 julia gt b x a 2 0 b 1 0 c 42 0 julia gt a 2 x a b exp x b c x c a 2 0 b 1 0 c 42 0 bijectors namedcomposition type namedcomposition lt abstractnamedbijectorwraps a tuple of array of abstractnamedbijector and implements their composition this is very similar to composed for bijector with the exception that we do not require the inputs to have the same quot dimension quot which in this case refers to the symbols for the namedtuple that this takes as input see also composed bijectors namedcoupling type namedcoupling target deps f lt abstractnamedbijectorimplements a coupling layer for named bijectors examples julia gt using bijectors namedcoupling scalejulia gt b namedcoupling b a c a c gt scale a c namedcoupling b a c var quot 3 4 quot var quot 3 4 quot julia gt x a 1 b 2 c 3 julia gt b x a 1 0 b 8 0 c 3 0 julia gt a x a b x a x c x b c x c a 1 0 b 8 0 c 3 0 bijectors namedinverse type namedinverse lt abstractnamedbijectorrepresents the inverse of a abstractnamedbijector similarily to inverse for bijector see also inverse bijectors orderedbijector type orderedbijector a bijector mapping ordered vectors in to unordered vectors in see alsostan s documentationnote that this transformation and its inverse are the opposite of in this reference bijectors partitionmask type partitionmask a a 1 a a 2 a a 3 a where a this is used to partition and recombine a vector into 3 disjoint quot subvectors quot implementspartition m partitionmask x partitions x into 3 disjoint quot subvectors quot combine m partitionmask x 1 x 2 x 3 combines 3 disjoint vectors into a single onenote that partitionmask is not a bijector it is indeed a bijection but does not follow the bijector interface its main use is in coupling where we want to partition the input into 3 parts one part to transform one part to map into the parameter space of the transform applied to the first part and the last part of the vector is not used for anything examples julia gt using bijectors partitionmask partition combinejulia gt m partitionmask 3 1 2 lt assumes input length 3partitionmask bool sparsearrays sparsematrixcsc bool int64 1 1 true 2 1 true 3 1 true julia gt partition into 3 parts the last part is inferred to be indices 3 from the fact that 1 and 2 does not make up all indices in 1 3 x1 x2 x3 partition m 1 2 3 1 0 2 0 3 0 julia gt recombines the partitions into a vector combine m x1 x2 x3 3 element array float64 1 1 0 2 0 3 0note that the underlying sparsematrix is using bool as the element type we can also specify this to be some other type using the sp type keyword julia gt m partitionmask float32 3 1 2 partitionmask float32 sparsearrays sparsematrixcsc float32 int64 1 1 1 0 2 1 1 0 3 1 1 0 bijectors partitionmask method partitionmask n int indices assumes you want to split the vector where indices refer to the parts of the vector you want to apply the bijector to bijectors permute type permute a lt bijector 1 a bijector implementation of a permutation the permutation is performed using a matrix of type a there are a couple of different ways to construct permute permute 0 1 1 0 will map 1 2 gt 2 1 permute 2 1 will map 1 2 gt 2 1 permute 2 2 gt 1 1 gt 2 will map 1 2 gt 2 1 permute 2 1 2 gt 2 1 will map 1 2 gt 2 1 if this is not clear the examples might be of help examplesa simple example is permuting a vector of size 3 julia gt b1 permute 0 1 0 1 0 0 0 0 1 permute array int64 2 0 1 0 1 0 0 0 0 1 julia gt b2 permute 2 1 3 specify all elements at oncepermute sparsearrays sparsematrixcsc float64 int64 2 1 1 0 1 2 1 0 3 3 1 0 julia gt b3 permute 3 2 gt 1 1 gt 2 element wisepermute sparsearrays sparsematrixcsc float64 int64 2 1 1 0 1 2 1 0 3 3 1 0 julia gt b4 permute 3 1 2 gt 2 1 block wisepermute sparsearrays sparsematrixcsc float64 int64 2 1 1 0 1 2 1 0 3 3 1 0 julia gt b1 a b2 a b3 a b4 atruejulia gt b1 1 2 3 3 element array float64 1 2 0 1 0 3 0julia gt b2 1 2 3 3 element array float64 1 2 0 1 0 3 0julia gt b3 1 2 3 3 element array float64 1 2 0 1 0 3 0julia gt b4 1 2 3 3 element array float64 1 2 0 1 0 3 0julia gt inverse b1 permute linearalgebra transpose int64 array int64 2 0 1 0 1 0 0 0 0 1 julia gt inverse b1 b1 1 2 3 3 element array float64 1 1 0 2 0 3 0 bijectors rationalquadraticspline type rationalquadraticspline t 0 lt bijector 0 rationalquadraticspline t 1 lt bijector 1 implementation of the rational quadratic spline flow 1 outside of the interval minimum widths maximum widths this mapping is given by the identity map inside the interval it s given by a monotonic spline i e monotonic polynomials connected at intermediate points with endpoints fixed so as to continuously transform into the identity map for the sake of efficiency there are separate implementations for 0 dimensional and 1 dimensional inputs notesthere are two constructors for rationalquadraticspline rationalquadraticspline widths heights derivatives it is assumed that widths heights and derivatives satisfy the constraints that makes this a valid bijector i e widths monotonically increasing and length widths k heights monotonically increasing and length heights k derivatives non negative and derivatives 1 derivatives end 1 rationalquadraticspline widths heights derivatives b other than than the lengths no assumptions are made on parameters therefore we will transform the parameters s t widths new b b where k length widths heights new b b where k length heights derivatives new 0 with derivatives new 1 derivates new end 1 where k 1 length derivatives examplesunivariate julia gt using bijectors rationalquadraticsplinejulia gt k 3 b 2 julia gt monotonic spline on b b with k intermediate knots quot connection points quot b rationalquadraticspline randn k randn k randn k 1 b julia gt b 0 5 inside of b b transformed1 412300607463467julia gt b 5 outside of b b not transformed5 0or we can use the constructor with the parameters correctly constrained julia gt b rationalquadraticspline b widths b heights b derivatives julia gt b 0 5 inside of b b transformed1 412300607463467multivariate julia gt d 2 k 3 b 2 julia gt b rationalquadraticspline randn d k randn d k randn d k 1 b julia gt b 1 1 2 element array float64 1 1 2568224171342797 0 5537259740554675julia gt b 5 5 2 element array float64 1 5 0 5 0julia gt b 1 5 2 element array float64 1 1 2568224171342797 5 0references 1 durkan c bekasov a murray i amp papamakarios g neural spline flows corr arxiv 1906 04032 stat ml 2019 bijectors stacked type stacked bs stacked bs ranges stack bs bijector 0 where 0 means 0 dim bijector a bijector which stacks bijectors together which can then be applied to a vector where bs i bijector is applied to x ranges i unitrange int argumentsbs can be either a tuple or an abstractarray of 0 and or 1 dimensional bijectorsif bs is a tuple implementations are type stable using generated functionsif bs is an abstractarray implementations are not type stable and use iterative methodsranges needs to be an iterable consisting of unitrange int length bs length ranges needs to be true examplesb1 logit 0 0 1 0 b2 identity 0 b stack b1 b2 b 0 0 1 0 b1 0 0 1 0 gt true", "title": "Bijectors"},{"location": "/docs/tutorials/index", "text": "tutorialsthis section contains tutorials on how to implement common models in turing if you prefer to have an interactive jupyter notebook please fork or download the turingtutorials repository a list of all the tutorials available can be found to the left the introduction tutorial contains an introduction to coin flipping with turing and a brief overview of probabilistic programming tutorials are under continuous development but there are some older version available at the turingtutorials within the old notebooks section some of these were built using prior versions of turing and may not function correctly but they can assist in the syntax used for common models if there is a tutorial you would like to request please open an issue on the turingtutorials repository", "title": "Tutorials"},{"location": "/docs/using-turing/advanced", "text": "advanced usagehow to define a customized distributionturing jl supports the use of distributions from the distributions jl package by extension it also supports the use of customized distributions by defining them as subtypes of distribution type of the distributions jl package as well as corresponding functions below shows a workflow of how to define a customized distribution using our own implementation of a simple uniform distribution as a simple example 1 define the distribution typefirst define a type of the distribution as a subtype of a corresponding distribution type in the distributions jl package struct customuniform lt continuousunivariatedistribution end2 implement sampling and evaluation of the log pdfsecond define rand and logpdf which will be used to run the model sample in 0 1 distributions rand rng abstractrng d customuniform rand rng p x 1 logp x 0distributions logpdf d customuniform x real zero x 3 define helper functionsin most cases it may be required to define some helper functions 3 1 domain transformationcertain samplers such as hmc require the domain of the priors to be unbounded therefore to use our customuniform as a prior in a model we also need to define how to transform samples from 0 1 to to do this we simply need to define the corresponding bijector from bijectors jl which is what turing jl uses internally to deal with constrained distributions to transform from 0 1 to we can use the logit bijector bijectors bijector d customuniform logit 0 1 you d do the exact same thing for continuousmultivariatedistribution and continuousmatrixdistribution for example wishart defines a distribution over positive definite matrices and so bijector returns a pdbijector when called with a wishart distribution as an argument for discrete distributions there is no need to define a bijector the identity bijector is used by default alternatively for univariatedistribution we can define the minimum and maximum of the distributiondistributions minimum d customuniform 0 distributions maximum d customuniform 1 and bijectors jl will return a default bijector called truncatedbijector which makes use of minimum and maximum derive the correct transformation internally turing basically does the following when it needs to convert a constrained distribution to an unconstrained distribution e g when sampling using hmc b bijector dist transformed dist transformed dist b results in distribution with transformed support correction for logpdfand then we can call rand and logpdf as usual whererand transformed dist returns a sample in the unconstrained space andlogpdf transformed dist y returns the log density of the original distribution but with y living in the unconstrained space to read more about bijectors jl check out the project readme update the accumulated log probability in the model definitionturing accumulates log probabilities internally in an internal data structure that is accessible through the internal variable varinfo inside of the model definition see below for more details about model internals however since users should not have to deal with internal data structures a macro turing addlogprob is provided that increases the accumulated log probability for instance this allows you to include arbitrary terms in the likelihoodusing turingmyloglikelihood x loglikelihood normal 1 x model function demo x normal turing addlogprob myloglikelihood x endand to reject samples using turingusing linearalgebra model function demo x m mvnormal zero x i if dot m x lt 0 turing addlogprob inf exit the model evaluation early return end x mvnormal m i returnendnote that addlogprob always increases the accumulated log probability regardless of the provided sampling context for instance if you do not want to apply turing addlogprob when evaluating the prior of your model but only when computing the log likelihood and the log joint probability then you should check the type of the internal variable context such asif dynamicppl leafcontext context turing priorcontext turing addlogprob myloglikelihood x endmodel internalsthe model macro accepts a function definition and rewrites it such that call of the function generates a model struct for use by the sampler models can be constructed by hand without the use of a macro taking the gdemo model as an example the macro based definitionusing turing model function gdemo x set priors s inversegamma 2 3 m normal 0 sqrt s observe each value of x x normal m sqrt s endmodel gdemo 1 5 2 0 can be implemented also a bit less generally with the macro free versionusing turing create the model function function gdemo model varinfo context x assume s has an inversegamma distribution s varinfo dynamicppl tilde assume context inversegamma 2 3 turing varname s varinfo assume m has a normal distribution m varinfo dynamicppl tilde assume context normal 0 sqrt s turing varname m varinfo observe each value of x i according to a normal distribution dynamicppl dot tilde observe context normal m sqrt s x turing varname x varinfo endgdemo x turing model gdemo x instantiate a model object with our data variables model gdemo 1 5 2 0 task copyingturing copies julia tasks to deliver efficient inference algorithms but it also provides alternative slower implementation as a fallback task copying is enabled by default task copying requires us to use the tapedtask facility which is provided by libtask to create tasks", "title": "Advanced Usage"},{"location": "/docs/using-turing/autodiff", "text": "automatic differentiationswitching ad modesturing supports four packages of automatic differentiation ad in the back end during sampling the default ad backend is forwarddiff for forward mode ad three reverse mode ad backends are also supported namely tracker zygote and reversediff zygote and reversediff are supported optionally if explicitly loaded by the user with using zygote or using reversediff next to using turing to switch between the different ad backends one can call function turing setadbackend backend sym where backend sym can be forwarddiff forwarddiff tracker tracker zygote zygote or reversediff reversediff jl when using reversediff to compile the tape only once and cache it for later use the user has to call turing setrdcache true however note that the use of caching in certain types of models can lead to incorrect results and or errors models for which the compiled tape can be safely cached are models with fixed size loops and no run time if statements compile time if statements are fine compositional sampling with differing ad modesturing supports intermixed automatic differentiation methods for different variable spaces the snippet below shows using forwarddiff to sample the mean m parameter and using the tracker based trackerad autodiff for the variance s parameter using turing define a simple normal model with unknown mean and variance model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end sample using gibbs and varying autodiff backends c sample gdemo 1 5 2 gibbs hmc turing forwarddiffad 1 0 1 5 m hmc turing trackerad 0 1 5 s 1000 generally trackerad is faster when sampling from variables of high dimensionality greater than 20 and forwarddiffad is more efficient for lower dimension variables this functionality allows those who are performance sensitive to fine tune their automatic differentiation for their specific models if the differentiation method is not specified in this way turing will default to using whatever the global ad backend is currently this defaults to forwarddiff", "title": "Automatic Differentiation"},{"location": "/docs/using-turing/dynamichmc", "text": "using dynamichmcturing supports the use of dynamichmc as a sampler through the dynamicnuts function to use the dynamicnuts function you must import the dynamichmc package as well as turing turing does not formally require dynamichmc but will include additional functionality if both packages are present here is a brief example of how to apply dynamicnuts import turing and dynamichmc using dynamichmc turing model definition model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end pull 2 000 samples using dynamicnuts chn sample gdemo 1 5 2 0 dynamicnuts 2000", "title": "Using DynamicHMC"},{"location": "/docs/using-turing/get-started", "text": "getting startedinstallationto use turing you need to install julia first and then install turing install juliayou will need to install julia 1 3 or greater which you can get from the official julia website install turing jlturing is an officially registered julia package so you can install a stable version of turing by running the following in the julia repl julia gt add turingyou can check if all tests pass by runningjulia gt test turingexamplehere s a simple example showing the package in action using turingusing statsplots define a simple normal model with unknown mean and variance model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end run sampler collect resultschn sample gdemo 1 5 2 hmc 0 1 5 1000 summarise resultsdescribe chn plot and save resultsp plot chn savefig gdemo plot png", "title": "Getting Started"},{"location": "/docs/using-turing/guide", "text": "guidebasicsintroductiona probabilistic program is julia code wrapped in a model macro it can use arbitrary julia code but to ensure correctness of inference it should not have external effects or modify global state stack allocated variables are safe but mutable heap allocated objects may lead to subtle bugs when using task copying by default libtask deepcopies array and dict objects when copying task to avoid bugs with data stored in mutable structure in turing models to specify distributions of random variables turing programs should use the notation x distr where x is a symbol and distr is a distribution if x is undefined in the model function inside the probabilistic program this puts a random variable named x distributed according to distr in the current scope distr can be a value of any type that implements rand distr which samples a value from the distribution distr if x is defined this is used for conditioning in a style similar to anglican another ppl in this case x is an observed value assumed to have been drawn from the distribution distr the likelihood is computed using logpdf distr y the observe statements should be arranged so that every possible run traverses all of them in exactly the same order this is equivalent to demanding that they are not placed inside stochastic control flow available inference methods include importance sampling is sequential monte carlo smc particle gibbs pg hamiltonian monte carlo hmc hamiltonian monte carlo with dual averaging hmcda and the no u turn sampler nuts simple gaussian demobelow is a simple gaussian demo illustrate the basic usage of turing jl import packages using turingusing statsplots define a simple normal model with unknown mean and variance model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s endnote as a sanity check the prior expectation of s is mean inversegamma 2 3 3 2 1 3 and the prior expectation of m is 0 this can be easily checked using prior p1 sample gdemo missing missing prior 100000 we can perform inference by using the sample function the first argument of which is our probabilistic program and the second of which is a sampler more information on each sampler is located in the api run sampler collect results c1 sample gdemo 1 5 2 smc 1000 c2 sample gdemo 1 5 2 pg 10 1000 c3 sample gdemo 1 5 2 hmc 0 1 5 1000 c4 sample gdemo 1 5 2 gibbs pg 10 m hmc 0 1 5 s 1000 c5 sample gdemo 1 5 2 hmcda 0 15 0 65 1000 c6 sample gdemo 1 5 2 nuts 0 65 1000 the mcmcchains module which is re exported by turing provides plotting tools for the chain objects returned by a sample function see the mcmcchains repository for more information on the suite of tools available for diagnosing mcmc chains summarise resultsdescribe c3 plot resultsplot c3 savefig gdemo plot png the arguments for each sampler are smc number of particles pg number of particles number of iterations hmc leapfrog step size leapfrog step numbers gibbs component sampler 1 component sampler 2 hmcda total leapfrog length target accept ratio nuts number of adaptation steps optional target accept ratio for detailed information on the samplers please review turing jl s api documentation modelling syntax explainedusing this syntax a probabilistic model is defined in turing the model function generated by turing can then be used to condition the model onto data subsequently the sample function can be used to generate samples from the posterior distribution in the following example the defined model is conditioned to the data arg1 1 arg2 2 by passing 1 2 to the model function model function model name arg 1 arg 2 endthe conditioned model can then be passed onto the sample function to run posterior inference model func model name 1 2 chn sample model func hmc perform inference by sampling using hmc the returned chain contains samples of the variables in the model var 1 mean chn var 1 taking the mean of a variable named var 1 the key var 1 can be a symbol or a string for example to fetch x 1 one can use chn symbol quot x 1 quot or chn quot x 1 quot if you want to retrieve all parameters associated with a specific symbol you can use group as an example if you have the parameters quot x 1 quot quot x 2 quot and quot x 3 quot calling group chn x or group chn quot x quot will return a new chain with only quot x 1 quot quot x 2 quot and quot x 3 quot turing does not have a declarative form more generally the order in which you place the lines of a model macro matters for example the following example works define a simple normal model with unknown mean and variance model function model function y s poisson 1 y normal s 1 return yendsample model function 10 smc 100 but if we switch the s poisson 1 and y normal s 1 lines the model will no longer sample correctly define a simple normal model with unknown mean and variance model function model function y y normal s 1 s poisson 1 return yendsample model function 10 smc 100 sampling multiple chainsturing supports distributed and threaded parallel sampling to do so call sample model sampler parallel type n n chains where parallel type can be either mcmcthreads or mcmcdistributed for thread and parallel sampling respectively having multiple chains in the same object is valuable for evaluating convergence some diagnostic functions like gelmandiag require multiple chains if you do not want parallelism or are on an older version julia you can sample multiple chains with the mapreduce function replace num chains below with however many chains you wish to sample chains mapreduce c gt sample model fun sampler 1000 chainscat 1 num chains the chains variable now contains a chains object which can be indexed by chain to pull out the first chain from the chains object use chains 1 the method is the same if you use either of the below parallel sampling methods multithreaded samplingif you wish to perform multithreaded sampling and are running julia 1 3 or greater you can call sample with the following signature using turing model function gdemo x s inversegamma 2 3 m normal 0 sqrt s for i in eachindex x x i normal m sqrt s endendmodel gdemo 1 5 2 0 sample four chains using multiple threads each with 1000 samples sample model nuts mcmcthreads 1000 4 be aware that turing cannot add threads for you you must have started your julia instance with multiple threads to experience any kind of parallelism see the julia documentation for details on how to achieve this distributed samplingto perform distributed sampling using multiple processes you must first import distributed process parallel sampling can be done like so load distributed to add processes and the everywhere macro using distributed load turing using turing add four processes to use for sampling addprocs 4 initialize everything on all the processes note make sure to do this after you ve already loaded turing so each process does not have to precompile parallel sampling may fail silently if you do not do this everywhere using turing define a model on all processes everywhere model function gdemo x s inversegamma 2 3 m normal 0 sqrt s for i in eachindex x x i normal m sqrt s endend declare the model instance everywhere everywhere model gdemo 1 5 2 0 sample four chains using multiple processes each with 1000 samples sample model nuts mcmcdistributed 1000 4 sampling from an unconditional distribution the prior turing allows you to sample from a declared model s prior if you wish to draw a chain from the prior to inspect your prior distributions you can simply runchain sample model prior n samples you can also run your model as if it were a function from the prior distribution by calling the model without specifying inputs or a sampler in the below example we specify a gdemo model which returns two variables x and y the model includes x and y as arguments but calling the function without passing in x or y means that turing s compiler will assume they are missing values to draw from the relevant distribution the return statement is necessary to retrieve the sampled x and y values model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s return x yendassign the function with missing inputs to a variable and turing will produce a sample from the prior distribution samples from p x y g prior sample gdemo missing missing g prior sample output 0 685690547873451 1 1972706455914328 sampling from a conditional distribution the posterior treating observations as random variablesinputs to the model that have a value missing are treated as parameters aka random variables to be estimated sampled this can be useful if you want to simulate draws for that parameter or if you are sampling from a conditional distribution turing supports the following syntax model function gdemo x type t float64 where t if x missing initialize x if missing x vector t undef 2 end s inversegamma 2 3 m normal 0 sqrt s for i in eachindex x x i normal m sqrt s endend construct a model with x missingmodel gdemo missing c sample model hmc 0 01 5 500 note the need to initialize x when missing since we are iterating over its elements later in the model the generated values for x can be extracted from the chains object using c x turing also supports mixed missing and non missing values in x where the missing ones will be treated as random variables to be sampled while the others get treated as observations for example model function gdemo x s inversegamma 2 3 m normal 0 sqrt s for i in eachindex x x i normal m sqrt s endend x 1 is a parameter but x 2 is an observationmodel gdemo missing 2 4 c sample model hmc 0 01 5 500 default valuesarguments to turing models can have default values much like how default values work in normal julia functions for instance the following will assign missing to x and treat it as a random variable if the default value is not missing x will be assigned that value and will be treated as an observation instead using turing model function generative x missing type t float64 where t lt real if x missing initialize x when missing x vector t undef 10 end s inversegamma 2 3 m normal 0 sqrt s for i in 1 length x x i normal m sqrt s end return s mendm generative chain sample m hmc 0 01 5 1000 access values inside chainyou can access the values inside a chain several ways turn them into a dataframe objectuse their raw axisarray formcreate a three dimensional array objectfor example let c be a chain dataframe c converts c to a dataframe c value retrieves the values inside c as an axisarray andc value data retrieves the values inside c as a 3d array variable types and type parametersthe element type of a vector or matrix of random variables should match the eltype of the its prior distribution lt integer for discrete distributions and lt abstractfloat for continuous distributions moreover if the continuous random variable is to be sampled using a hamiltonian sampler the vector s element type needs to either be 1 real to enable auto differentiation through the model which uses special number types that are sub types of real or 2 some type parameter t defined in the model header using the type parameter syntax e g function gdemo x type t float64 where t similarly when using a particle sampler the julia variable used should either be 1 an array or 2 an instance of some type parameter t defined in the model header using the type parameter syntax e g function gdemo x type t vector float64 where t querying probabilities from model or chainconsider first the following simplified gdemo model model function gdemo0 x s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s end instantiate three models with different value of xmodel1 gdemo0 1 model4 gdemo0 4 model10 gdemo0 10 now query the instantiated models compute the likelihood of x 1 0 given the values of s 1 0 and m 1 0 for the parameters prob x 1 0 model model1 s 1 0 m 1 0 prob x 1 0 model model4 s 1 0 m 1 0 prob x 1 0 model model10 s 1 0 m 1 0 notice that even if we use three models instantiated with three different values of x we should obtain the same likelihood we can easily verify that value in this case pdf normal 1 0 1 0 1 0 let us now consider the following gdemo model model function gdemo x y s inversegamma 2 3 m normal 0 sqrt s x normal m sqrt s y normal m sqrt s end instantiate the model model gdemo 2 0 4 0 the following are examples of valid queries of the turing model or chain prob quot x 1 0 y 1 0 model model s 1 0 m 1 0 quot calculates the likelihood of x 1 and y 1 given s 1 and m 1 prob quot s 1 0 m 1 0 model model x nothing y nothing quot calculates the joint probability of s 1 and m 1 ignoring x and y x and y are ignored so they can be optionally dropped from the rhs of but it is recommended to define them prob quot s 1 0 m 1 0 x 1 0 model model y nothing quot calculates the joint probability of s 1 m 1 and x 1 ignoring y prob quot s 1 0 m 1 0 x 1 0 y 1 0 model model quot calculates the joint probability of all the variables after the mcmc sampling given a chain prob quot x 1 0 y 1 0 chain chain model model quot calculates the element wise likelihood of x 1 0 and y 1 0 for each sample in chain if save state true was used during sampling i e sample model sampler n save state true you can simply do prob quot x 1 0 y 1 0 chain chain quot in all the above cases logprob can be used instead of prob to calculate the log probabilities instead maximum likelihood and maximum a posterior estimatesturing provides support for two mode estimation techniques maximum likelihood estimation mle and maximum a posterior map estimation optimization is performed by the optim jl package mode estimation is currently a optional tool and will not be available to you unless you have manually installed optim and loaded the package with a using statement to install optim run import pkg pkg add quot optim quot mode estimation only works when all model parameters are continuous discrete parameters cannot be estimated with mle map as of yet to understand how mode estimation works let us first load turing and optim to enable mode estimation and then declare a model note that loading optim explicitly is required for mode estimation to function as turing does not load the opimization suite unless optim is loaded as well using turingusing optim model function gdemo x s inversegamma 2 3 m normal 0 sqrt s for i in eachindex x x i normal m sqrt s endendonce the model is defined we can construct a model instance as we normally would create some data to pass to the model data 1 5 2 0 instantiate the gdemo model with our data model gdemo data mode estimation is typically quick and easy at this point turing extends the function optim optimize and accepts the structs mle or map which inform turing whether to provide an mle or map estimate respectively by default the lbfgs optimizer is used though this can be changed basic usage is generate a mle estimate mle estimate optimize model mle generate a map estimate map estimate optimize model map if you wish to change to a different optimizer such as neldermead simply place your optimizer in the third argument slot use neldermeadmle estimate optimize model mle neldermead use simulatedannealingmle estimate optimize model mle simulatedannealing use particleswarmmle estimate optimize model mle particleswarm use newtonmle estimate optimize model mle newton use acceleratedgradientdescentmle estimate optimize model mle acceleratedgradientdescent some methods may have trouble calculating the mode because not enough iterations were allowed or the target function moved upwards between function calls turing will warn you if optim fails to converge by running optim converge a typical solution to this might be to add more iterations or allow the optimizer to increase between function iterations increase the iterations and allow function eval to increase between calls mle estimate optimize model mle newton optim options iterations 10 000 allow f increases true more options for optim are available here analyzing your mode estimateturing extends several methods from statsbase that can be used to analyze your mode estimation results methods implemented include vcov informationmatrix coeftable params and coef among others for example let s examine our ml estimate from above using coeftable import statsbase to use it s statistical methods using statsbase print out the coefficient table coeftable mle estimate estimate stderror tstat s 0 0625 0 0625 1 0m 1 75 0 176777 9 8995 standard errors are calculated from the fisher information matrix inverse hessian of the log likelihood or log joint t statistics will be familiar to frequentist statisticians warning standard errors calculated in this way may not always be appropriate for map estimates so please be cautious in interpreting them sampling with the map mle as initial statesyou can begin sampling your chain from an mle map estimate by extracting the vector of parameter values and providing it to the sample function with the keyword init params for example here is how to sample from the full posterior using the map estimate as the starting point generate an map estimate map estimate optimize model map sample with the map estimate as the starting point chain sample model nuts 1 000 init params map estimate values array beyond the basicscompositional sampling using gibbsturing jl provides a gibbs interface to combine different samplers for example one can combine an hmc sampler with a pg sampler to run inference for different parameters in a single model as below model function simple choice xs p beta 2 2 z bernoulli p for i in 1 length xs if z 1 xs i normal 0 1 else xs i normal 2 1 end endendsimple choice f simple choice 1 5 2 0 0 3 chn sample simple choice f gibbs hmc 0 2 3 p pg 20 z 1000 the gibbs sampler can be used to specify unique automatic differentiation backends for different variable spaces please see the automatic differentiation article for more for more details of compositional sampling in turing jl please check the corresponding paper working with filldist and arraydistturing provides filldist dist distribution n int and arraydist dists abstractvector lt distribution as a simplified interface to construct product distributions e g to model a set of variables that share the same structure but vary by group constructing product distributions with filldistthe function filldist provides a general interface to construct product distributions over distributions of the same type and parameterisation note that in contrast to the product distribution interface provided by distributions jl product filldist supports product distributions over univariate or multivariate distributions example usage model function demo x g k length unique g a filldist exponential k product fill exponential k mu a g x normal mu endconstructing product distributions with arraydistthe function arraydist provides a general interface to construct product distributions over distributions of varying type and parameterisation note that in contrast to the product distribution interface provided by distributions jl product arraydist supports product distributions over univariate or multivariate distributions example usage model function demo x g k length unique g a arraydist exponential i for i in 1 k mu a g x normal mu endworking with mcmcchains jlturing jl wraps its samples using mcmcchains chain so that all the functions working for mcmcchains chain can be re used in turing jl two typical functions are mcmcchains describe and mcmcchains plot which can be used as follows for an obtained chain chn for more information on mcmcchains please see the github repository describe chn lists statistics of the samples plot chn plots statistics of the samples there are numerous functions in addition to describe and plot in the mcmcchains package such as those used in convergence diagnostics for more information on the package please see the github repository changing default settingssome of turing jl s default settings can be changed for better usage ad chunk sizeforwarddiff turing s default ad backend uses forward mode chunk wise ad the chunk size can be set manually by setchunksize new chunk size ad backendturing supports four packages of automatic differentiation ad in the back end during sampling the default ad backend is forwarddiff for forward mode ad three reverse mode ad backends are also supported namely tracker zygote and reversediff zygote and reversediff are supported optionally if explicitly loaded by the user with using zygote or using reversediff next to using turing for more information on turing s automatic differentiation backend please see the automatic differentiation article progress loggingturing jl uses progresslogging jl to log the progress of sampling progress logging is enabled as default but might slow down inference it can be turned on or off by setting the keyword argument progress of sample to true or false respectively moreover you can enable or disable progress logging globally by calling setprogress true or setprogress false respectively turing uses heuristics to select an appropriate visualization backend if you use juno the progress is displayed with a progress bar in the atom window for jupyter notebooks the default backend is consoleprogressmonitor jl in all other cases progress logs are displayed with terminalloggers jl alternatively if you provide a custom visualization backend turing uses it instead of the default backend", "title": "Guide"},{"location": "/docs/using-turing/index", "text": "turing documentationwelcome to the documentation for turing introductionturing is a general purpose probabilistic programming language for robust efficient bayesian inference and decision making current features include general purpose probabilistic programming with an intuitive modelling interface robust efficient hamiltonian monte carlo hmc sampling for differentiable posterior distributions particle mcmc sampling for complex posterior distributions involving discrete variables and stochastic control flow andcompositional inference via gibbs sampling that combines particle mcmc hmc and random walk mh rwmh", "title": "Turing Documentation"},{"location": "/docs/using-turing/performancetips", "text": "performance tipsthis section briefly summarises a few common techniques to ensure good performance when using turing we refer to the julia documentation for general techniques to ensure good performance of julia programs use multivariate distributionsit is generally preferable to use multivariate distributions if possible the following example model function gmodel x m normal for i 1 length x x i normal m 0 2 endendcan be directly expressed more efficiently using a simple transformation using fillarrays model function gmodel x m normal x mvnormal fill m length x 0 04 i endchoose your ad backendturing currently provides support for two different automatic differentiation ad backends generally try to use forwarddiff for models with few parameters and reversediff tracker or zygote for models with large parameter vectors or linear algebra operations see automatic differentiation for details special care for tracker and zygotein case of tracker and zygote it is necessary to avoid loops for now this is mainly due to the reverse mode ad backends tracker and zygote which are inefficient for such cases reversediff does better but vectorized operations will still perform better avoiding loops can be done using filldist dist n and arraydist dists filldist dist n creates a multivariate distribution that is composed of n identical and independent copies of the univariate distribution dist if dist is univariate or it creates a matrix variate distribution composed of n identical and independent copies of the multivariate distribution dist if dist is multivariate filldist dist n m can also be used to create a matrix variate distribution from a univariate distribution dist arraydist dists is similar to filldist but it takes an array of distributions dists as input writing a custom distribution with a custom adjoint is another option to avoid loops ensure that types in your model can be inferredfor efficient gradient based inference e g using hmc nuts or advi it is important to ensure the types in your model can be inferred the following example with abstract types model function tmodel x y p n size x params vector real undef n for i 1 n params i truncated normal 0 inf end a x params y mvnormal a i endcan be transformed into the following representation with concrete types model function tmodel x y type t float64 where t p n size x params vector t undef n for i 1 n params i truncated normal 0 inf end a x params y mvnormal a i endalternatively you could use filldist in this example model function tmodel x y params filldist truncated normal 0 inf size x 2 a x params y mvnormal a i endnote that you can use code warntype to find types in your model definition that the compiler cannot infer they are marked in red in the julia repl for example consider the following simple program model function tmodel x p vector real undef 1 p 1 normal p p 1 x normal p 1 endwe can useusing randommodel tmodel 1 0 code warntype model f model turing varinfo model turing samplingcontext random default rng turing samplefromprior turing defaultcontext model args to inspect type inference in the model reuse computations in gibbs samplingoften when performing gibbs sampling one can save computational time by caching the output of expensive functions the cached values can then be reused in future gibbs sub iterations which do not change the inputs to this expensive function for example in the following model model function demo x a gamma b normal c function1 a d function2 b x normal c d endalg gibbs mh a mh b sample demo zeros 10 alg 1000 when only updating a in a gibbs sub iteration keeping b the same the value of d doesn t change and when only updating b the value of c doesn t change however if function1 and function2 are expensive and are both run in every gibbs sub iteration a lot of time would be spent computing values that we already computed before such a problem can be overcome using memoization jl memoizing a function lets us store and reuse the output of the function for every input it is called with this has a slight time overhead but for expensive functions the savings will be far greater to use memoization jl simply define memoized versions of function1 and function2 as such using memoization memoize memoized function1 args function1 args memoize memoized function2 args function2 args then define the turing model using the new functions as such model function demo x a gamma b normal c memoized function1 a d memoized function2 b x normal c d end", "title": "Performance Tips"},{"location": "/docs/using-turing/quick-start", "text": "probabilistic programming in thirty secondsif you are already well versed in probabilistic programming and just want to take a quick look at how turing s syntax works or otherwise just want a model to start with we have provided a bayesian coin flipping model to play with this example can be run on however you have julia installed see getting started but you will need to install the packages turing and statsplots if you have not done so already this is an excerpt from a more formal example introducing probabilistic programming which can be found in jupyter notebook form here or as part of the documentation website here import libraries using turing statsplots random set the true probability of heads in a coin p true 0 5 iterate from having seen 0 observations to 100 observations ns 0 100 draw data from a bernoulli distribution i e draw heads or tails random seed 12 data rand bernoulli p true last ns declare our turing model model function coinflip y our prior belief about the probability of heads in a coin p beta 1 1 the number of observations n length y for n in 1 n heads or tails of a coin are drawn from a bernoulli distribution y n bernoulli p endend settings of the hamiltonian monte carlo hmc sampler iterations 1000 0 05 10 start sampling chain sample coinflip data hmc iterations plot a summary of the sampling process for the parameter p i e the probability of heads in a coin histogram chain p", "title": "Probabilistic Programming in Thirty Seconds"},{"location": "/docs/using-turing/sampler-viz", "text": "sampler visualizationintroductionthe codefor each sampler we will use the same code to plot sampler paths the block below loads the relevant libraries and defines a function for plotting the sampler s trajectory across the posterior the turing model definition used here is not especially practical but it is designed in such a way as to produce visually interesting posterior surfaces to show how different samplers move along the distribution env gks encoding utf 8 allows the use of unicode characters in plots jlusing plotsusing statsplotsusing turingusing bijectorsusing randomusing dynamicppl getlogp settrans getval reconstruct vectorize setval set a seed random seed 0 define a strange model model function gdemo x s inversegamma 2 3 m normal 0 sqrt s bumps sin m cos m m m 5 bumps for i in eachindex x x i normal m sqrt s end return s mend define our data points x 1 5 2 0 13 0 2 1 0 0 set up the model call sample from the prior model gdemo x vi turing varinfo model convert the variance parameter to the real line before sampling note we only have to do this here because we are being very hands on turing will handle all of this for you during normal sampling dist inversegamma 2 3 svn vi metadata s vns 1 mvn vi metadata m vns 1 setval vi vectorize dist bijectors link dist reconstruct dist getval vi svn svn settrans vi true svn evaluate surface at coordinates function evaluate m1 m2 spl turing samplefromprior vi svn m1 vi mvn m2 model vi spl getlogp vi endfunction plot sampler chain label extract values from chain val get chain s m lp ss link ref inversegamma 2 3 val s ms val m lps val lp how many surface points to sample granularity 100 range start stop points spread 0 5 start minimum ss spread std ss stop maximum ss spread std ss start minimum ms spread std ms stop maximum ms spread std ms rng collect range start stop stop length granularity rng collect range start stop stop length granularity make surface plot p surface rng rng evaluate camera 30 65 ticks nothing colorbar false color inferno title label line range 1 length ms scatter3d ss line range ms line range lps line range mc viridis marker z collect line range msw 0 legend false colorbar false alpha 0 5 xlabel ylabel zlabel log probability title label return pend samplersgibbsgibbs sampling tends to exhibit a quot jittery quot trajectory the example below combines hmc and pg sampling to traverse the posterior c sample model gibbs hmc 0 01 5 s pg 20 m 1000 plot sampler c hmchamiltonian monte carlo hmc sampling is a typical sampler to use as it tends to be fairly good at converging in a efficient manner it can often be tricky to set the correct parameters for this sampler however and the nuts sampler is often easier to run if you don t want to spend too much time fiddling with step size and and the number of steps to take note however that hmc does not explore the positive values very well likely due to the leapfrog and step size parameter settings c sample model hmc 0 01 10 1000 plot sampler c hmcdathe hmcda sampler is an implementation of the hamiltonian monte carlo with dual averaging algorithm found in the paper quot the no u turn sampler adaptively setting path lengths in hamiltonian monte carlo quot by hoffman and gelman 2011 the paper can be found on arxiv for the interested reader c sample model hmcda 200 0 65 0 3 1000 plot sampler c mhmetropolis hastings mh sampling is one of the earliest markov chain monte carlo methods mh sampling does not quot move quot a lot unlike many of the other samplers implemented in turing typically a much longer chain is required to converge to an appropriate parameter estimate the plot below only uses 1 000 iterations of metropolis hastings c sample model mh 1000 plot sampler c as you can see the mh sampler doesn t move parameter estimates very often nutsthe no u turn sampler nuts is an implementation of the algorithm found in the paper quot the no u turn sampler adaptively setting path lengths in hamiltonian monte carlo quot by hoffman and gelman 2011 the paper can be found on arxiv for the interested reader nuts tends to be very good at traversing complex posteriors quickly c sample model nuts 0 65 1000 plot sampler c the only parameter that needs to be set other than the number of iterations to run is the target acceptance rate in the hoffman and gelman paper they note that a target acceptance rate of 0 65 is typical here is a plot showing a very high acceptance rate note that it appears to quot stick quot to a mode and is not particularly good at exploring the posterior as compared to the 0 65 target acceptance ratio case c sample model nuts 0 95 1000 plot sampler c an exceptionally low acceptance rate will show very few moves on the posterior c sample model nuts 0 2 1000 plot sampler c pgthe particle gibbs pg sampler is an implementation of an algorithm from the paper quot particle markov chain monte carlo methods quot by andrieu doucet and holenstein 2010 the interested reader can learn more here the two parameters are the number of particles and the number of iterations the plot below shows the use of 20 particles c sample model pg 20 1000 plot sampler c next we plot using 50 particles c sample model pg 50 1000 plot sampler c", "title": "Sampler Visualization"}]}
