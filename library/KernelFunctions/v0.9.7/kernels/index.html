<!DOCTYPE html><HTML lang="en"><head><script charset="utf-8" src="../../../assets/default/multidoc_injector.js" type="text/javascript"></script><script charset="utf-8" src="../../../assets/default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../assets/default/flexsearch_integration.js" type="text/javascript"></script><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Kernel Functions · KernelFunctions</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script data-main="../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../assets/themeswap.js"></script><link href="../../../assets/default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../assets/default/flexsearch.css" rel="stylesheet" type="text/css"/><link href="../../../assets/multidoc-custom.css" rel="stylesheet" type="text/css"/></head><body><nav id="multi-page-nav"><div class="hidden-on-mobile" id="nav-items"><div class="nav-dropdown"><button class="nav-item dropdown-label">Modelling languages</button><ul class="nav-dropdown-container"><a class="nav-link nav-item" href="../../../DynamicPPL/">DynamicPPL</a><a class="nav-link nav-item" href="../../../SymbolicPPL/">SymbolicPPL</a><a class="nav-link nav-item" href="../../../TuringGLM/">TuringGLM</a></ul></div><div class="nav-dropdown"><button class="nav-item dropdown-label">MCMC</button><ul class="nav-dropdown-container"><a class="nav-link nav-item" href="../../../AdvancedHMC/">AdvancedHMC</a><a class="nav-link nav-item" href="../../../AbstractMCMC/">AbstractMCMC</a><a class="nav-link nav-item" href="../../../ThermodynamicIntegration/">ThermodynamicIntegration</a><a class="nav-link nav-item" href="../../../AdvancedPS/">AdvancedPS</a><a class="nav-link nav-item" href="../../../EllipticalSliceSampling/">EllipticalSliceSampling</a><a class="nav-link nav-item" href="../../../NestedSamplers/">NestedSamplers</a></ul></div><div class="nav-dropdown"><button class="nav-item dropdown-label">Diagnostics</button><ul class="nav-dropdown-container"><a class="nav-link nav-item" href="../../../MCMCChains/">MCMCChains</a><a class="nav-link nav-item" href="../../../MCMCDiagnosticTools/">MCMCDiagnosticTools</a><a class="nav-link nav-item" href="../../../ParetoSmooth/">ParetoSmooth</a></ul></div><a class="nav-link nav-item" href="../../../Bijectors/">Bijectors</a><a class="nav-link nav-item" href="../../../TuringCallbacks/">TuringCallbacks</a><a class="nav-link nav-item" href="../../../TuringBenchmarking/">TuringBenchmarking</a><div class="nav-dropdown"><button class="nav-item dropdown-label">Gaussian Processes</button><ul class="nav-dropdown-container"><a class="nav-link nav-item" href="../../../AbstractGPs/">AbstractGPs</a><a class="nav-link active nav-item" href="../../">KernelFunctions</a><a class="nav-link nav-item" href="../../../ApproximateGPs/">ApproximateGPs</a></ul></div><div class="search nav-item"><input id="search-input" placeholder="Search..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding"></div></div></div><button id="multidoc-toggler"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg></button></nav><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KernelFunctions</span></div><form action="../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User guide</a></li><li class="is-active"><a class="tocitem" href="">Kernel Functions</a><ul class="internal"><li><a class="tocitem" href="#base_kernels"><span>Base Kernels</span></a></li><li><a class="tocitem" href="#Composite-Kernels"><span>Composite Kernels</span></a></li><li><a class="tocitem" href="#Multi-output-Kernels"><span>Multi-output Kernels</span></a></li></ul></li><li><a class="tocitem" href="../transform/">Input Transforms</a></li><li><a class="tocitem" href="../metrics/">Metrics</a></li><li><a class="tocitem" href="../theory/">Theory</a></li><li><a class="tocitem" href="../create_kernel/">Custom Kernels</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../example/">Examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="">Kernel Functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Kernel Functions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/master/docs/src/kernels.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="Kernel-Functions"><a class="docs-heading-anchor" href="#Kernel-Functions">Kernel Functions</a><a id="Kernel-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-Functions" title="Permalink"></a></h1><h2 id="base_kernels"><a class="docs-heading-anchor" href="#base_kernels">Base Kernels</a><a id="base_kernels-1"></a><a class="docs-heading-anchor-permalink" href="#base_kernels" title="Permalink"></a></h2><p>These are the basic kernels without any transformation of the data. They are the building blocks of KernelFunctions.</p><h3 id="Constant-Kernels"><a class="docs-heading-anchor" href="#Constant-Kernels">Constant Kernels</a><a id="Constant-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Constant-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.ZeroKernel" id="KernelFunctions.ZeroKernel"><code>KernelFunctions.ZeroKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ZeroKernel()</code></pre><p>Zero kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span>, the zero kernel is defined as</p><p class="math-container">\[k(x, x') = 0.\]</p><p>The output type depends on <span>$x$</span> and <span>$x'$</span>.</p><p>See also: <a href="#KernelFunctions.ConstantKernel"><code>ConstantKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/constant.jl#L1-L15" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.ConstantKernel" id="KernelFunctions.ConstantKernel"><code>KernelFunctions.ConstantKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ConstantKernel(; c::Real=1.0)</code></pre><p>Kernel of constant value <code>c</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span>, the kernel of constant value <span>$c \geq 0$</span> is defined as</p><p class="math-container">\[k(x, x') = c.\]</p><p>See also: <a href="#KernelFunctions.ZeroKernel"><code>ZeroKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/constant.jl#L51-L64" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.WhiteKernel" id="KernelFunctions.WhiteKernel"><code>KernelFunctions.WhiteKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WhiteKernel()</code></pre><p>White noise kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span>, the white noise kernel is defined as</p><p class="math-container">\[k(x, x') = \delta(x, x').\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/constant.jl#L24-L35" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.EyeKernel" id="KernelFunctions.EyeKernel"><code>KernelFunctions.EyeKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">EyeKernel()</code></pre><p>Alias of <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/constant.jl#L38-L42" target="_blank">source</a></section></article><h3 id="Cosine-Kernel"><a class="docs-heading-anchor" href="#Cosine-Kernel">Cosine Kernel</a><a id="Cosine-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Cosine-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.CosineKernel" id="KernelFunctions.CosineKernel"><code>KernelFunctions.CosineKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CosineKernel()</code></pre><p>Cosine kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the cosine kernel is defined as</p><p class="math-container">\[k(x, x') = \cos(\pi \|x-x'\|_2).\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/cosine.jl#L1-L12" target="_blank">source</a></section></article><h3 id="Exponential-Kernels"><a class="docs-heading-anchor" href="#Exponential-Kernels">Exponential Kernels</a><a id="Exponential-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Exponential-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.ExponentialKernel" id="KernelFunctions.ExponentialKernel"><code>KernelFunctions.ExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExponentialKernel()</code></pre><p>Exponential kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the exponential kernel is defined as</p><p class="math-container">\[k(x, x') = \exp\big(- \|x - x'\|_2\big).\]</p><p>See also: <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L48-L61" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.LaplacianKernel" id="KernelFunctions.LaplacianKernel"><code>KernelFunctions.LaplacianKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LaplacianKernel()</code></pre><p>Alias of <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L74-L78" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.SqExponentialKernel" id="KernelFunctions.SqExponentialKernel"><code>KernelFunctions.SqExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SqExponentialKernel()</code></pre><p>Squared exponential kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the squared exponential kernel is defined as</p><p class="math-container">\[k(x, x') = \exp\bigg(- \frac{\|x - x'\|_2^2}{2}\bigg).\]</p><p>See also: <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L1-L14" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.SEKernel" id="KernelFunctions.SEKernel"><code>KernelFunctions.SEKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SEKernel()</code></pre><p>Alias of <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L41-L45" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.GaussianKernel" id="KernelFunctions.GaussianKernel"><code>KernelFunctions.GaussianKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GaussianKernel()</code></pre><p>Alias of <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L34-L38" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.RBFKernel" id="KernelFunctions.RBFKernel"><code>KernelFunctions.RBFKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RBFKernel()</code></pre><p>Alias of <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L27-L31" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.GammaExponentialKernel" id="KernelFunctions.GammaExponentialKernel"><code>KernelFunctions.GammaExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GammaExponentialKernel(; γ::Real=2.0)</code></pre><p>γ-exponential kernel with parameter <code>γ</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the γ-exponential kernel<sup class="footnote-reference"><a href="#footnote-RW" id="citeref-RW">[RW]</a></sup> with parameter <span>$\gamma \in (0, 2]$</span> is defined as</p><p class="math-container">\[k(x, x'; \gamma) = \exp\big(- \|x - x'\|_2^{\gamma}\big).\]</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>The default value of parameter <code>γ</code> will be changed to <code>1.0</code> in the next breaking release of KernelFunctions.</p></div></div><p>See also: <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>, <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L88-L108" target="_blank">source</a></section></article><h3 id="Exponentiated-Kernel"><a class="docs-heading-anchor" href="#Exponentiated-Kernel">Exponentiated Kernel</a><a id="Exponentiated-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Exponentiated-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.ExponentiatedKernel" id="KernelFunctions.ExponentiatedKernel"><code>KernelFunctions.ExponentiatedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExponentiatedKernel()</code></pre><p>Exponentiated kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the exponentiated kernel is defined as</p><p class="math-container">\[k(x, x') = \exp(x^\top x').\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponentiated.jl#L1-L12" target="_blank">source</a></section></article><h3 id="Fractional-Brownian-Motion-Kernel"><a class="docs-heading-anchor" href="#Fractional-Brownian-Motion-Kernel">Fractional Brownian Motion Kernel</a><a id="Fractional-Brownian-Motion-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Fractional-Brownian-Motion-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.FBMKernel" id="KernelFunctions.FBMKernel"><code>KernelFunctions.FBMKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FBMKernel(; h::Real=0.5)</code></pre><p>Fractional Brownian motion kernel with Hurst index <code>h</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the fractional Brownian motion kernel with <a href="https://en.wikipedia.org/wiki/Hurst_exponent#Generalized_exponent">Hurst index</a><span>$h \in [0,1]$</span> is defined as</p><p class="math-container">\[k(x, x'; h) =  \frac{\|x\|_2^{2h} + \|x'\|_2^{2h} - \|x - x'\|^{2h}}{2}.\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/fbm.jl#L1-L14" target="_blank">source</a></section></article><h3 id="Gabor-Kernel"><a class="docs-heading-anchor" href="#Gabor-Kernel">Gabor Kernel</a><a id="Gabor-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Gabor-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.gaborkernel" id="KernelFunctions.gaborkernel"><code>KernelFunctions.gaborkernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gaborkernel(;
    sqexponential_transform=IdentityTransform(), cosine_tranform=IdentityTransform()
)</code></pre><p>Construct a Gabor kernel with transformations <code>sqexponential_transform</code> and <code>cosine_transform</code> of the inputs of the underlying squared exponential and cosine kernel, respectively.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the Gabor kernel with transformations <span>$f$</span> and <span>$g$</span> of the inputs to the squared exponential and cosine kernel, respectively, is defined as</p><p class="math-container">\[k(x, x'; f, g) = \exp\bigg(- \frac{\| f(x) - f(x')\|_2^2}{2}\bigg)
                 \cos\big(\pi \|g(x) - g(x')\|_2 \big).\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/gabor.jl#L1-L19" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.GaborKernel" id="KernelFunctions.GaborKernel"><code>KernelFunctions.GaborKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GaborKernel(; ell::Real=1.0, p::Real=1.0)</code></pre><p>Gabor kernel with lengthscale <code>ell</code> and period <code>p</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the Gabor kernel with lengthscale <span>$l_i &gt; 0$</span> and period <span>$p_i &gt; 0$</span> is defined as</p><p class="math-container">\[k(x, x'; l, p) = \exp\bigg(- \sum_{i=1}^d \frac{(x_i - x'_i)^2}{2l_i^2}\bigg)
                 \cos\bigg(\pi \bigg(\sum_{i=1}^d \frac{(x_i - x'_i)^2}{p_i^2} \bigg)^{1/2}\bigg).\]</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>GaborKernel</code> is deprecated and will be removed. Gabor kernels should be constructed with <a href="#KernelFunctions.gaborkernel"><code>gaborkernel</code></a> instead.</p></div></div></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/gabor.jl#L28-L45" target="_blank">source</a></section></article><h3 id="Matérn-Kernels"><a class="docs-heading-anchor" href="#Matérn-Kernels">Matérn Kernels</a><a id="Matérn-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Matérn-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.MaternKernel" id="KernelFunctions.MaternKernel"><code>KernelFunctions.MaternKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MaternKernel(; ν::Real=1.5)</code></pre><p>Matérn kernel of order <code>ν</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the Matérn kernel of order <span>$\nu &gt; 0$</span> is defined as</p><p class="math-container">\[k(x,x';\nu) = \frac{2^{1-\nu}}{\Gamma(\nu)}\big(\sqrt{2\nu}\|x-x'\|_2\big) K_\nu\big(\sqrt{2\nu}\|x-x'\|_2\big),\]</p><p>where <span>$\Gamma$</span> is the Gamma function and <span>$K_{\nu}$</span> is the modified Bessel function of the second kind of order <span>$\nu$</span>.</p><p>A Gaussian process with a Matérn kernel is <span>$\lceil \nu \rceil - 1$</span>-times differentiable in the mean-square sense.</p><p>See also: <a href="#KernelFunctions.Matern12Kernel"><code>Matern12Kernel</code></a>, <a href="#KernelFunctions.Matern32Kernel"><code>Matern32Kernel</code></a>, <a href="#KernelFunctions.Matern52Kernel"><code>Matern52Kernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/matern.jl#L1-L20" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.Matern12Kernel" id="KernelFunctions.Matern12Kernel"><code>KernelFunctions.Matern12Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern12Kernel()</code></pre><p>Alias of <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/exponential.jl#L81-L85" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.Matern32Kernel" id="KernelFunctions.Matern32Kernel"><code>KernelFunctions.Matern32Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern32Kernel()</code></pre><p>Matérn kernel of order <span>$3/2$</span>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the Matérn kernel of order <span>$3/2$</span> is given by</p><p class="math-container">\[k(x, x') = \big(1 + \sqrt{3} \|x - x'\|_2 \big) \exp\big(- \sqrt{3}\|x - x'\|_2\big).\]</p><p>See also: <a href="#KernelFunctions.MaternKernel"><code>MaternKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/matern.jl#L47-L60" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.Matern52Kernel" id="KernelFunctions.Matern52Kernel"><code>KernelFunctions.Matern52Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern52Kernel()</code></pre><p>Matérn kernel of order <span>$5/2$</span>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the Matérn kernel of order <span>$5/2$</span> is given by</p><p class="math-container">\[k(x, x') = \bigg(1 + \sqrt{5} \|x - x'\|_2 + \frac{5}{3}\|x - x'\|_2^2\bigg)
           \exp\big(- \sqrt{5}\|x - x'\|_2\big).\]</p><p>See also: <a href="#KernelFunctions.MaternKernel"><code>MaternKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/matern.jl#L69-L83" target="_blank">source</a></section></article><h3 id="Neural-Network-Kernel"><a class="docs-heading-anchor" href="#Neural-Network-Kernel">Neural Network Kernel</a><a id="Neural-Network-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Network-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.NeuralNetworkKernel" id="KernelFunctions.NeuralNetworkKernel"><code>KernelFunctions.NeuralNetworkKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NeuralNetworkKernel()</code></pre><p>Kernel of a Gaussian process obtained as the limit of a Bayesian neural network with a single hidden layer as the number of units goes to infinity.</p><p><strong>Definition</strong></p><p>Consider the single-layer Bayesian neural network <span>$f \colon \mathbb{R}^d \to \mathbb{R}$</span> with <span>$h$</span> hidden units defined by</p><p class="math-container">\[f(x; b, v, u) = b + \sqrt{\frac{\pi}{2}} \sum_{i=1}^{h} v_i \mathrm{erf}\big(u_i^\top x\big),\]</p><p>where <span>$\mathrm{erf}$</span> is the error function, and with prior distributions</p><p class="math-container">\[\begin{aligned}
b &amp;\sim \mathcal{N}(0, \sigma_b^2),\\
v &amp;\sim \mathcal{N}(0, \sigma_v^2 \mathrm{I}_{h}/h),\\
u_i &amp;\sim \mathcal{N}(0, \mathrm{I}_{d}/2) \qquad (i = 1,\ldots,h).
\end{aligned}\]</p><p>As <span>$h \to \infty$</span>, the neural network converges to the Gaussian process</p><p class="math-container">\[g(\cdot) \sim \mathcal{GP}\big(0, \sigma_b^2 + \sigma_v^2 k(\cdot, \cdot)\big),\]</p><p>where the neural network kernel <span>$k$</span> is given by</p><p class="math-container">\[k(x, x') = \arcsin\left(\frac{x^\top x'}{\sqrt{\big(1 + \|x\|^2_2\big) \big(1 + \|x'\|_2^2\big)}}\right)\]</p><p>for inputs <span>$x, x' \in \mathbb{R}^d$</span>.<sup class="footnote-reference"><a href="#footnote-CW" id="citeref-CW">[CW]</a></sup></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/nn.jl#L1-L33" target="_blank">source</a></section></article><h3 id="Periodic-Kernel"><a class="docs-heading-anchor" href="#Periodic-Kernel">Periodic Kernel</a><a id="Periodic-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Periodic-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.PeriodicKernel" id="KernelFunctions.PeriodicKernel"><code>KernelFunctions.PeriodicKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PeriodicKernel(; r::AbstractVector=ones(Float64, 1))</code></pre><p>Periodic kernel with parameter <code>r</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the periodic kernel with parameter <span>$r_i &gt; 0$</span> is defined<sup class="footnote-reference"><a href="#footnote-DM" id="citeref-DM">[DM]</a></sup> as</p><p class="math-container">\[k(x, x'; r) = \exp\bigg(- \frac{1}{2} \sum_{i=1}^d \bigg(\frac{\sin\big(\pi(x_i - x'_i)\big)}{r_i}\bigg)^2\bigg).\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/periodic.jl#L1-L15" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.PeriodicKernel-Tuple{DataType, Int64}" id="KernelFunctions.PeriodicKernel-Tuple{DataType, Int64}"><code>KernelFunctions.PeriodicKernel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">PeriodicKernel([T=Float64, dims::Int=1])</code></pre><p>Create a <a href="#KernelFunctions.PeriodicKernel"><code>PeriodicKernel</code></a> with parameter <code>r=ones(T, dims)</code>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/periodic.jl#L26-L30" target="_blank">source</a></section></article><h3 id="Piecewise-Polynomial-Kernel"><a class="docs-heading-anchor" href="#Piecewise-Polynomial-Kernel">Piecewise Polynomial Kernel</a><a id="Piecewise-Polynomial-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Piecewise-Polynomial-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.PiecewisePolynomialKernel" id="KernelFunctions.PiecewisePolynomialKernel"><code>KernelFunctions.PiecewisePolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PiecewisePolynomialKernel(; degree::Int=0, dim::Int)
PiecewisePolynomialKernel{degree}(dim::Int)</code></pre><p>Piecewise polynomial kernel of degree <code>degree</code> for inputs of dimension <code>dim</code> with support in the unit ball.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span> of dimension <span>$d$</span>, the piecewise polynomial kernel of degree <span>$v \in \{0,1,2,3\}$</span> is defined as</p><p class="math-container">\[k(x, x'; v) = \max(1 - \|x - x'\|, 0)^{\alpha(v,d)} f_{v,d}(\|x - x'\|),\]</p><p>where <span>$\alpha(v, d) = \lfloor \frac{d}{2}\rfloor + 2v + 1$</span> and <span>$f_{v,d}$</span> are polynomials of degree <span>$v$</span> given by</p><p class="math-container">\[\begin{aligned}
f_{0,d}(r) &amp;= 1, \\
f_{1,d}(r) &amp;= 1 + (j + 1) r, \\
f_{2,d}(r) &amp;= 1 + (j + 2) r + \big((j^2 + 4j + 3) / 3\big) r^2, \\
f_{3,d}(r) &amp;= 1 + (j + 3) r + \big((6 j^2 + 36j + 45) / 15\big) r^2 + \big((j^3 + 9 j^2 + 23j + 15) / 15\big) r^3,
\end{aligned}\]</p><p>where <span>$j = \lfloor \frac{d}{2}\rfloor + v + 1$</span>.</p><p>The kernel is <span>$2v$</span> times continuously differentiable and the corresponding Gaussian process is hence <span>$v$</span> times mean-square differentiable.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/piecewisepolynomial.jl#L1-L29" target="_blank">source</a></section></article><h3 id="Polynomial-Kernels"><a class="docs-heading-anchor" href="#Polynomial-Kernels">Polynomial Kernels</a><a id="Polynomial-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Polynomial-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.LinearKernel" id="KernelFunctions.LinearKernel"><code>KernelFunctions.LinearKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearKernel(; c::Real=0.0)</code></pre><p>Linear kernel with constant offset <code>c</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the linear kernel with constant offset <span>$c \geq 0$</span> is defined as</p><p class="math-container">\[k(x, x'; c) = x^\top x' + c.\]</p><p>See also: <a href="#KernelFunctions.PolynomialKernel"><code>PolynomialKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/polynomial.jl#L1-L15" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.PolynomialKernel" id="KernelFunctions.PolynomialKernel"><code>KernelFunctions.PolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PolynomialKernel(; degree::Int=2, c::Real=0.0)</code></pre><p>Polynomial kernel of degree <code>degree</code> with constant offset <code>c</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the polynomial kernel of degree <span>$\nu \in \mathbb{N}$</span> with constant offset <span>$c \geq 0$</span> is defined as</p><p class="math-container">\[k(x, x'; c, \nu) = (x^\top x' + c)^\nu.\]</p><p>See also: <a href="#KernelFunctions.LinearKernel"><code>LinearKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/polynomial.jl#L33-L47" target="_blank">source</a></section></article><h3 id="Rational-Kernels"><a class="docs-heading-anchor" href="#Rational-Kernels">Rational Kernels</a><a id="Rational-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Rational-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.RationalKernel" id="KernelFunctions.RationalKernel"><code>KernelFunctions.RationalKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RationalKernel(; α::Real=2.0)</code></pre><p>Rational kernel with shape parameter <code>α</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the rational kernel with shape parameter <span>$\alpha &gt; 0$</span> is defined as</p><p class="math-container">\[k(x, x'; \alpha) = \bigg(1 + \frac{\|x - x'\|_2}{\alpha}\bigg)^{-\alpha}.\]</p><p>The <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a> is recovered in the limit as <span>$\alpha \to \infty$</span>.</p><p>See also: <a href="#KernelFunctions.GammaRationalKernel"><code>GammaRationalKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/rational.jl#L1-L17" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.RationalQuadraticKernel" id="KernelFunctions.RationalQuadraticKernel"><code>KernelFunctions.RationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RationalQuadraticKernel(; α::Real=2.0)</code></pre><p>Rational-quadratic kernel with shape parameter <code>α</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the rational-quadratic kernel with shape parameter <span>$\alpha &gt; 0$</span> is defined as</p><p class="math-container">\[k(x, x'; \alpha) = \bigg(1 + \frac{\|x - x'\|_2^2}{2\alpha}\bigg)^{-\alpha}.\]</p><p>The <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> is recovered in the limit as <span>$\alpha \to \infty$</span>.</p><p>See also: <a href="#KernelFunctions.GammaRationalKernel"><code>GammaRationalKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/rational.jl#L38-L54" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.GammaRationalKernel" id="KernelFunctions.GammaRationalKernel"><code>KernelFunctions.GammaRationalKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GammaRationalKernel(; α::Real=2.0, γ::Real=2.0)</code></pre><p>γ-rational kernel with shape parameters <code>α</code> and <code>γ</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the γ-rational kernel with shape parameters <span>$\alpha &gt; 0$</span> and <span>$\gamma \in (0, 2]$</span> is defined as</p><p class="math-container">\[k(x, x'; \alpha, \gamma) = \bigg(1 + \frac{\|x - x'\|_2^{\gamma}}{\alpha}\bigg)^{-\alpha}.\]</p><p>The <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a> is recovered in the limit as <span>$\alpha \to \infty$</span>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>The default value of parameter <code>γ</code> will be changed to <code>1.0</code> in the next breaking release of KernelFunctions.</p></div></div><p>See also: <a href="#KernelFunctions.RationalKernel"><code>RationalKernel</code></a>, <a href="#KernelFunctions.RationalQuadraticKernel"><code>RationalQuadraticKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/rational.jl#L75-L95" target="_blank">source</a></section></article><h3 id="Spectral-Mixture-Kernels"><a class="docs-heading-anchor" href="#Spectral-Mixture-Kernels">Spectral Mixture Kernels</a><a id="Spectral-Mixture-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Spectral-Mixture-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.spectral_mixture_kernel" id="KernelFunctions.spectral_mixture_kernel"><code>KernelFunctions.spectral_mixture_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spectral_mixture_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractVector{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (A, ), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><p>Generalised Spectral Mixture kernel function. This family of functions is  dense in the family of stationary real-valued kernels with respect to the pointwise convergence.[1]</p><p class="math-container">\[   κ(x, y) = αs' (h(-(γs' * t)^2) .* cos(π * ωs' * t), t = x - y\]</p><p><strong>References:</strong></p><pre><code class="language-none">[1] Generalized Spectral Kernels, by Yves-Laurent Kom Samo and Stephen J. Roberts
[2] SM: Gaussian Process Kernels for Pattern Discovery and Extrapolation,
        ICML, 2013, by Andrew Gordon Wilson and Ryan Prescott Adams,
[3] Covariance kernels for fast automatic pattern discovery and extrapolation
    with Gaussian processes, Andrew Gordon Wilson, PhD Thesis, January 2014.
    http://www.cs.cmu.edu/~andrewgw/andrewgwthesis.pdf
[4] http://www.cs.cmu.edu/~andrewgw/pattern/.</code></pre></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/sm.jl#L1-L31" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.spectral_mixture_product_kernel" id="KernelFunctions.spectral_mixture_product_kernel"><code>KernelFunctions.spectral_mixture_product_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spectral_mixture_product_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractMatrix{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (D, A), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p>Spectral Mixture Product Kernel. With enough components A, the SMP kernel can model any product kernel to arbitrary precision, and is flexible even with a small number of components [1]</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><p class="math-container">\[   κ(x, y) = Πᵢ₌₁ᴷ Σ(αsᵢᵀ .* (h(-(γsᵢᵀ * tᵢ)²) .* cos(ωsᵢᵀ * tᵢ))), tᵢ = xᵢ - yᵢ\]</p><p><strong>References:</strong></p><pre><code class="language-none">[1] GPatt: Fast Multidimensional Pattern Extrapolation with GPs,
    arXiv 1310.5288, 2013, by Andrew Gordon Wilson, Elad Gilboa,
    Arye Nehorai and John P. Cunningham</code></pre></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/sm.jl#L58-L85" target="_blank">source</a></section></article><h3 id="Wiener-Kernel"><a class="docs-heading-anchor" href="#Wiener-Kernel">Wiener Kernel</a><a id="Wiener-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Wiener-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.WienerKernel" id="KernelFunctions.WienerKernel"><code>KernelFunctions.WienerKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WienerKernel(; i::Int=0)
WienerKernel{i}()</code></pre><p>The <code>i</code>-times integrated Wiener process kernel function.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x' \in \mathbb{R}^d$</span>, the <span>$i$</span>-times integrated Wiener process kernel with <span>$i \in \{-1, 0, 1, 2, 3\}$</span> is defined<sup class="footnote-reference"><a href="#footnote-SDH" id="citeref-SDH">[SDH]</a></sup> as</p><p class="math-container">\[k_i(x, x') = \begin{cases}
    \delta(x, x') &amp; \text{if } i=-1,\\
    \min\big(\|x\|_2, \|x'\|_2\big) &amp; \text{if } i=0,\\
    a_{i1}^{-1} \min\big(\|x\|_2, \|x'\|_2\big)^{2i + 1}
    + a_{i2}^{-1} \|x - x'\|_2 r_i\big(\|x\|_2, \|x'\|_2\big) \min\big(\|x\|_2, \|x'\|_2\big)^{i + 1}
    &amp; \text{otherwise},
\end{cases}\]</p><p>where the coefficients <span>$a$</span> are given by</p><p class="math-container">\[a = \begin{bmatrix}
3 &amp; 2 \\
20 &amp; 12 \\
252 &amp; 720
\end{bmatrix}\]</p><p>and the functions <span>$r_i$</span> are defined as</p><p class="math-container">\[\begin{aligned}
r_1(t, t') &amp;= 1,\\
r_2(t, t') &amp;= t + t' - \frac{\min(t, t')}{2},\\
r_3(t, t') &amp;= 5 \max(t, t')^2 + 2 tt' + 3 \min(t, t')^2.
\end{aligned}\]</p><p>The <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a> is recovered for <span>$i = -1$</span>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/basekernels/wiener.jl#L1-L40" target="_blank">source</a></section></article><h2 id="Composite-Kernels"><a class="docs-heading-anchor" href="#Composite-Kernels">Composite Kernels</a><a id="Composite-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Composite-Kernels" title="Permalink"></a></h2><p>The modular design of KernelFunctions uses <a href="#base_kernels">base kernels</a> as building blocks for more complex kernels. There are a variety of composite kernels implemented, including those which <a href="../transform/#input_transforms">transform the inputs</a> to a wrapped kernel to implement length scales, scale the variance of a kernel, and sum or multiply collections of kernels together.</p><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.TransformedKernel" id="KernelFunctions.TransformedKernel"><code>KernelFunctions.TransformedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TransformedKernel(k::Kernel, t::Transform)</code></pre><p>Kernel derived from <code>k</code> for which inputs are transformed via a <a href="../transform/#KernelFunctions.Transform"><code>Transform</code></a><code>t</code>.</p><p>The preferred way to create kernels with input transformations is to use the composition operator <a href="#Base.:∘-Tuple{Kernel, Transform}"><code>∘</code></a> or its alias <code>compose</code> instead of <code>TransformedKernel</code> directly since this allows optimized implementations for specific kernels and transformations.</p><p>See also: <a href="#Base.:∘-Tuple{Kernel, Transform}"><code>∘</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/transformedkernel.jl#L1-L11" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#Base.:∘-Tuple{Kernel, Transform}" id="Base.:∘-Tuple{Kernel, Transform}"><code>Base.:∘</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">kernel ∘ transform
∘(kernel, transform)
compose(kernel, transform)</code></pre><p>Compose a <code>kernel</code> with a transformation <code>transform</code> of its inputs.</p><p>The prefix forms support chains of multiple transformations: <code>∘(kernel, transform1, transform2) = kernel ∘ transform1 ∘ transform2</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span>, the transformed kernel <span>$\widetilde{k}$</span> derived from kernel <span>$k$</span> by input transformation <span>$t$</span> is defined as</p><p class="math-container">\[\widetilde{k}(x, x'; k, t) = k\big(t(x), t(x')\big).\]</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; (SqExponentialKernel() ∘ ScaleTransform(0.5))(0, 2) == exp(-0.5)
true

julia&gt; ∘(ExponentialKernel(), ScaleTransform(2), ScaleTransform(0.5))(1, 2) == exp(-1)
true</code></pre><p>See also: <a href="#KernelFunctions.TransformedKernel"><code>TransformedKernel</code></a></p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/transformedkernel.jl#L38-L67" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.ScaledKernel" id="KernelFunctions.ScaledKernel"><code>KernelFunctions.ScaledKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ScaledKernel(k::Kernel, σ²::Real=1.0)</code></pre><p>Scaled kernel derived from <code>k</code> by multiplication with variance <code>σ²</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span>, the scaled kernel <span>$\widetilde{k}$</span> derived from kernel <span>$k$</span> by multiplication with variance <span>$\sigma^2 &gt; 0$</span> is defined as</p><p class="math-container">\[\widetilde{k}(x, x'; k, \sigma^2) = \sigma^2 k(x, x').\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/scaledkernel.jl#L1-L13" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.KernelSum" id="KernelFunctions.KernelSum"><code>KernelFunctions.KernelSum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelSum &lt;: Kernel</code></pre><p>Create a sum of kernels. One can also use the operator <code>+</code>.</p><p>There are various ways in which you create a <code>KernelSum</code>:</p><p>The simplest way to specify a <code>KernelSum</code> would be to use the overloaded <code>+</code> operator. This is  equivalent to creating a <code>KernelSum</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 + k2) == KernelSum(k1, k2)
true

julia&gt; kernelmatrix(k1 + k2, X) == kernelmatrix(k1, X) .+ kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 + k2, X)
true</code></pre><p>You could also specify a <code>KernelSum</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be summed. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl">julia&gt; KernelSum((k1, k2)) == k1 + k2
true

julia&gt; KernelSum([k1, k2]) == KernelSum((k1, k2)) == k1 + k2
true</code></pre></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/kernelsum.jl#L1-L33" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.KernelProduct" id="KernelFunctions.KernelProduct"><code>KernelFunctions.KernelProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelProduct &lt;: Kernel</code></pre><p>Create a product of kernels. One can also use the overloaded operator <code>*</code>.</p><p>There are various ways in which you create a <code>KernelProduct</code>:</p><p>The simplest way to specify a <code>KernelProduct</code> would be to use the overloaded <code>*</code> operator. This is  equivalent to creating a <code>KernelProduct</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 * k2) == KernelProduct(k1, k2)
true

julia&gt; kernelmatrix(k1 * k2, X) == kernelmatrix(k1, X) .* kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 * k2, X)
true</code></pre><p>You could also specify a <code>KernelProduct</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be multiplied. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl">julia&gt; KernelProduct((k1, k2)) == k1 * k2
true

julia&gt; KernelProduct([k1, k2]) == KernelProduct((k1, k2)) == k1 * k2
true</code></pre></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/kernelproduct.jl#L1-L33" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.KernelTensorProduct" id="KernelFunctions.KernelTensorProduct"><code>KernelFunctions.KernelTensorProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelTensorProduct</code></pre><p>Tensor product of kernels.</p><p><strong>Definition</strong></p><p>For inputs <span>$x = (x_1, \ldots, x_n)$</span> and <span>$x' = (x'_1, \ldots, x'_n)$</span>, the tensor product of kernels <span>$k_1, \ldots, k_n$</span> is defined as</p><p class="math-container">\[k(x, x'; k_1, \ldots, k_n) = \Big(\bigotimes_{i=1}^n k_i\Big)(x, x') = \prod_{i=1}^n k_i(x_i, x'_i).\]</p><p><strong>Construction</strong></p><p>The simplest way to specify a <code>KernelTensorProduct</code> is to use the overloaded <code>tensor</code> operator or its alias <code>⊗</code> (can be typed by <code>\otimes&lt;tab&gt;</code>).</p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5, 2);

julia&gt; kernelmatrix(k1 ⊗ k2, RowVecs(X)) == kernelmatrix(k1, X[:, 1]) .* kernelmatrix(k2, X[:, 2])
true</code></pre><p>You can also specify a <code>KernelTensorProduct</code> by providing kernels as individual arguments or as an iterable data structure such as a <code>Tuple</code> or a <code>Vector</code>. Using a tuple or individual arguments guarantees that <code>KernelTensorProduct</code> is concretely typed but might lead to large compilation times if the number of kernels is large.</p><pre><code class="language-julia-repl">julia&gt; KernelTensorProduct(k1, k2) == k1 ⊗ k2
true

julia&gt; KernelTensorProduct((k1, k2)) == k1 ⊗ k2
true

julia&gt; KernelTensorProduct([k1, k2]) == k1 ⊗ k2
true</code></pre></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/kerneltensorproduct.jl#L1-L39" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.NormalizedKernel" id="KernelFunctions.NormalizedKernel"><code>KernelFunctions.NormalizedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NormalizedKernel(k::Kernel)</code></pre><p>A normalized kernel derived from <code>k</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span>, the normalized kernel <span>$\widetilde{k}$</span> derived from kernel <span>$k$</span> is defined as</p><p class="math-container">\[\widetilde{k}(x, x'; k) = \frac{k(x, x')}{\sqrt{k(x, x) k(x', x')}}.\]</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/kernels/normalizedkernel.jl#L1-L13" target="_blank">source</a></section></article><h2 id="Multi-output-Kernels"><a class="docs-heading-anchor" href="#Multi-output-Kernels">Multi-output Kernels</a><a id="Multi-output-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-output-Kernels" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.MOKernel" id="KernelFunctions.MOKernel"><code>KernelFunctions.MOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MOKernel</code></pre><p>Abstract type for kernels with multiple outpus.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/mokernels/mokernel.jl#L1-L5" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.IndependentMOKernel" id="KernelFunctions.IndependentMOKernel"><code>KernelFunctions.IndependentMOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">IndependentMOKernel(k::Kernel)</code></pre><p>Kernel for multiple independent outputs with kernel <code>k</code> each.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span> and output dimensions <span>$p_x, p_{x'}'$</span>, the kernel <span>$\widetilde{k}$</span> for independent outputs with kernel <span>$k$</span> each is defined as</p><p class="math-container">\[\widetilde{k}\big((x, p_x), (x', p_{x'})\big) = \begin{cases}
    k(x, x') &amp; \text{if } p_x = p_{x'}, \\
    0 &amp; \text{otherwise}.
\end{cases}\]</p><p>Mathematically, it is equivalent to a matrix-valued kernel defined as</p><p class="math-container">\[\widetilde{K}(x, x') = \mathrm{diag}\big(k(x, x'), \ldots, k(x, x')\big) \in \mathbb{R}^{m \times m},\]</p><p>where <span>$m$</span> is the number of outputs.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/mokernels/independent.jl#L1-L21" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#KernelFunctions.LatentFactorMOKernel" id="KernelFunctions.LatentFactorMOKernel"><code>KernelFunctions.LatentFactorMOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LatentFactorMOKernel(g, e::MOKernel, A::AbstractMatrix)</code></pre><p>Kernel associated with the semiparametric latent factor model.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x'$</span> and output dimensions <span>$p_x, p_{x'}'$</span>, the kernel is defined as<sup class="footnote-reference"><a href="#footnote-STJ" id="citeref-STJ">[STJ]</a></sup></p><p class="math-container">\[k\big((x, p_x), (x, p_{x'})\big) = \sum^{Q}_{q=1} A_{p_xq}g_q(x, x')A_{p_{x'}q}
                                   + e\big((x, p_x), (x', p_{x'})\big),\]</p><p>where <span>$g_1, \ldots, g_Q$</span> are <span>$Q$</span> kernels, one for each latent process, <span>$e$</span> is a multi-output kernel for <span>$m$</span> outputs, and <span>$A$</span> is a matrix of weights for the kernels of size <span>$m \times Q$</span>.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/a99a3e7b1a5c3cbfb328e0e98e8b94ffa9331c6f/src/mokernels/slfm.jl#L1-L18" target="_blank">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-RW"><a class="tag is-link" href="#citeref-RW">RW</a>C. E. Rasmussen &amp; C. K. I. Williams (2006). Gaussian Processes for Machine Learning.</li><li class="footnote" id="footnote-CW"><a class="tag is-link" href="#citeref-CW">CW</a>C. K. I. Williams (1998). Computation with infinite neural networks.</li><li class="footnote" id="footnote-DM"><a class="tag is-link" href="#citeref-DM">DM</a>D. J. C. MacKay (1998). Introduction to Gaussian Processes.</li><li class="footnote" id="footnote-SDH"><a class="tag is-link" href="#citeref-SDH">SDH</a>Schober, Duvenaud &amp; Hennig (2014). Probabilistic ODE Solvers with Runge-Kutta Means.</li><li class="footnote" id="footnote-STJ"><a class="tag is-link" href="#citeref-STJ">STJ</a>M. Seeger, Y. Teh, &amp; M. I. Jordan (2005). <a href="https://infoscience.epfl.ch/record/161465/files/slfm-long.pdf">Semiparametric Latent Factor Models</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../userguide/">« User guide</a><a class="docs-footer-nextpage" href="../transform/">Input Transforms »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 7 May 2021 14:33">Friday 7 May 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>